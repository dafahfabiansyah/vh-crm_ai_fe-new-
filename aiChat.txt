package aiChat

import (
	"bytes"
	"context"
	"crypto/rand"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"image"
	"image/jpeg"
	"image/png"
	"io"
	"math"
	mathrand "math/rand"
	"net/http"
	"os"
	"path/filepath"
	"regexp"
	"strconv"

	"strings"
	"sync"
	"time"

	dbx "github.com/go-ozzo/ozzo-dbx"
	"github.com/google/uuid"
	"github.com/qiangxue/go-rest-api/internal/aiKnowledge"
	"github.com/qiangxue/go-rest-api/internal/contact"
	"github.com/qiangxue/go-rest-api/internal/custom_integration"
	"github.com/qiangxue/go-rest-api/internal/entity"
	"github.com/qiangxue/go-rest-api/internal/lead"
	"github.com/qiangxue/go-rest-api/internal/limit_checker"
	"github.com/qiangxue/go-rest-api/internal/pipeline"
	"github.com/qiangxue/go-rest-api/internal/platform"
	platformmapping "github.com/qiangxue/go-rest-api/internal/platform_mapping"
	"github.com/qiangxue/go-rest-api/internal/product"
	"github.com/qiangxue/go-rest-api/internal/rajaongkir"
	"github.com/qiangxue/go-rest-api/internal/s3"
	"github.com/qiangxue/go-rest-api/internal/stages"

	"github.com/qiangxue/go-rest-api/internal/token"
	"github.com/qiangxue/go-rest-api/internal/usage_tracking"
	"github.com/qiangxue/go-rest-api/pkg/accesslog"
	"github.com/qiangxue/go-rest-api/pkg/dbcontext"
	"github.com/qiangxue/go-rest-api/pkg/log"
)

// Constants for configuration
const (
	// Image processing constants
	MaxImageSize      = 10 * 1024 * 1024 // 10MB
	ImageQuality      = 85               // JPEG quality
	MaxImageDimension = 2048             // Max width/height

	// Payment detection constants
	PaymentDetectionCooldown = 5 * time.Second
	MaxPaymentKeywords       = 50

	// API retry constants
	MaxAPIRetries  = 3
	BaseRetryDelay = 1 * time.Second
	MaxRetryDelay  = 60 * time.Second

	// WhatsApp API timeouts
	WhatsAppTextTimeout  = 10 * time.Second // Timeout for text messages
	WhatsAppMediaTimeout = 60 * time.Second // Timeout for media messages
	ProductSendDelay     = 2 * time.Second  // Delay between product sends

	// Session management
	MaxSessionHistory      = 20
	SessionCleanupInterval = 1 * time.Hour
)

// PaymentDetectionConfig holds configuration for payment detection
type PaymentDetectionConfig struct {
	Enabled           bool
	Sensitivity       string // "high", "medium", "low"
	RequiredKeywords  int
	VisionModelForced bool
}

// CircuitBreaker represents a simple circuit breaker for external services
type CircuitBreaker struct {
	FailureCount    int
	LastFailureTime time.Time
	State           string // "closed", "open", "half-open"
	Threshold       int
	Timeout         time.Duration
	mutex           sync.RWMutex
}

// BehaviorCacheEntry represents a cached behavior with metadata
type BehaviorCacheEntry struct {
	OriginalBehavior string    // Original full behavior text
	UltraCompressed  string    // Ultra compressed version for low complexity
	Compressed       string    // Compressed version for medium complexity
	Optimized        string    // Optimized version for high complexity
	CachedAt         time.Time // When this entry was cached
	LastAccessed     time.Time // Last time this entry was accessed
	AccessCount      int       // Number of times this entry was accessed
}

// SessionBehaviorCache represents cached behavior for a specific session/agent combination
type SessionBehaviorCache struct {
	AgentID          uuid.UUID // Agent ID this behavior belongs to
	BehaviorHash     string    // Hash of the original behavior for validation
	UltraCompressed  string    // Ultra compressed version for low complexity
	Compressed       string    // Compressed version for medium complexity
	Optimized        string    // Optimized version for high complexity
	OriginalBehavior string    // Full original behavior (kept for reference)
	CachedAt         time.Time // When this entry was cached
	LastAccessed     time.Time // Last time this entry was accessed
	AccessCount      int       // Number of times this entry was accessed
}

// Service encapsulates the business logic for AI chat
type Service interface {
	SendMessage(ctx context.Context, agentID uuid.UUID, req ChatRequest) (*ChatResponse, error)
	SendMessageToWhatsApp(ctx context.Context, agentID uuid.UUID, req WhatsAppChatRequest) (*ChatResponse, error)
	UploadImageFromWhatsApp(ctx context.Context, agentID uuid.UUID, req WhatsAppImageRequest) (*ChatResponse, error)
	ResetSession(ctx context.Context, sessionID string) error
	SendWelcomeMessage(ctx context.Context, agentID uuid.UUID, req ChatRequest) (*ChatResponse, error)
}

type service struct {
	repo                     Repository
	platformMappingRepo      platformmapping.Repository
	platformService          platform.Service
	leadService              lead.Service
	contactService           contact.Service
	stagesService            stages.Service
	pipelineService          pipeline.Service
	s3Service                s3.Service
	usageTrackingService     usage_tracking.Service
	limitCheckerService      limit_checker.Service
	rajaOngkirService        *rajaongkir.Service
	customIntegrationService custom_integration.Service
	aiKnowledgeService       aiKnowledge.Service
	dbManager                *dbcontext.MultiTenantManager
	logger                   log.Logger
	openAIKey                string
	whatsappServiceURL       string
	// Enhanced session management with field state tracking
	sessions         sync.Map // map[string][]OpenAIMessage (legacy support)
	enhancedSessions sync.Map // map[string]*EnhancedSession (new enhanced sessions)
	// Image analysis results storage
	imageAnalysisResults sync.Map // map[string]*ImageAnalysisResult
	// Transfer cooldown to prevent rapid successive transfers
	transferCooldown sync.Map // map[string]time.Time (sessionID -> last transfer time)
	// Payment detection cooldown
	paymentDetectionCooldown sync.Map // map[string]time.Time
	// Image processing metrics
	imageProcessingMetrics sync.Map // map[string]int64
	// Circuit breaker for external services
	circuitBreaker sync.Map // map[string]*CircuitBreaker
	// Payment detection configuration
	paymentConfig PaymentDetectionConfig
	// Behavior cache to avoid loading large behavior text on every request
	behaviorCache sync.Map // map[string]*BehaviorCacheEntry
	// Session-based behavior cache to avoid processing behaviors for every message
	sessionBehaviorCache sync.Map // map[string]*SessionBehaviorCache (sessionID+agentID -> cached behavior)
	// Field state and coordination tracking
	fieldStateCache       sync.Map // map[string]*SessionFieldState
	integrationStateCache sync.Map // map[string]map[string]*IntegrationState
	conversationSummaries sync.Map // map[string]*ConversationSummary
}

// ImageAnalysisResult stores image analysis data for a session
type ImageAnalysisResult struct {
	Analysis  string
	Timestamp time.Time
	TTL       time.Duration
}

// SessionFieldState tracks extracted field data across conversation turns
type SessionFieldState struct {
	ExtractedFields  map[string]interface{} `json:"extracted_fields"` // Accumulated field data
	FieldSources     map[string]string      `json:"field_sources"`    // Which message provided each field
	LastUpdated      time.Time              `json:"last_updated"`
	RequiredFields   []string               `json:"required_fields"` // What's still needed
	OptionalFields   []string               `json:"optional_fields"`
	ConfidenceScores map[string]float64     `json:"confidence_scores"` // Confidence for each extracted field
}

// IntegrationState tracks the status of each integration
type IntegrationState struct {
	ID             uuid.UUID              `json:"id"`
	Name           string                 `json:"name"`
	LastTriggered  *time.Time             `json:"last_triggered"`
	TriggerCount   int                    `json:"trigger_count"`
	LastResult     map[string]interface{} `json:"last_result"`
	ReadyToTrigger bool                   `json:"ready_to_trigger"`
	MissingFields  []string               `json:"missing_fields"`
}

// ConversationSummary provides intelligent context for AI coordination
type ConversationSummary struct {
	FieldExtractions map[string]string `json:"field_extractions"` // All extracted fields with sources
	KeyTopics        []string          `json:"key_topics"`        // Important conversation topics
	UserIntents      []string          `json:"user_intents"`      // Identified user intentions
	CompletionStatus map[string]bool   `json:"completion_status"` // Integration readiness status
}

// FlowTracker monitors conversation flow and prevents redundant questions
type FlowTracker struct {
	AskedQuestions  []string  `json:"asked_questions"`  // Questions already asked
	ProvidedAnswers []string  `json:"provided_answers"` // Information already provided
	CurrentStage    string    `json:"current_stage"`    // Current conversation stage
	LastActivity    time.Time `json:"last_activity"`
}

// EnhancedSession contains all session data including field state and coordination info
type EnhancedSession struct {
	ConversationHistory []OpenAIMessage             `json:"conversation_history"`
	FieldState          SessionFieldState           `json:"field_state"`
	IntegrationStatus   map[string]IntegrationState `json:"integration_status"`
	ConversationFlow    FlowTracker                 `json:"conversation_flow"`
	LastAI2Evaluation   time.Time                   `json:"last_ai2_evaluation"`
	SessionID           string                      `json:"session_id"`
	CreatedAt           time.Time                   `json:"created_at"`
	LastUpdated         time.Time                   `json:"last_updated"`
	// Sequential integration processing state
	CurrentIntegrationIndex int                    `json:"current_integration_index"`
	IntegrationResults      map[string]interface{} `json:"integration_results"`
	WaitingForSatisfaction  bool                   `json:"waiting_for_satisfaction"`
	LastExecutedIntegration *uuid.UUID             `json:"last_executed_integration"`
}

// Enhanced Session Management Functions

// getOrCreateEnhancedSession retrieves or creates an enhanced session with field state tracking
func (s *service) getOrCreateEnhancedSession(sessionID string) *EnhancedSession {
	if sessionData, exists := s.enhancedSessions.Load(sessionID); exists {
		if session, ok := sessionData.(*EnhancedSession); ok {
			session.LastUpdated = time.Now()
			return session
		}
	}

	// Create new enhanced session
	now := time.Now()
	session := &EnhancedSession{
		ConversationHistory: []OpenAIMessage{},
		FieldState: SessionFieldState{
			ExtractedFields:  make(map[string]interface{}),
			FieldSources:     make(map[string]string),
			LastUpdated:      now,
			RequiredFields:   []string{},
			OptionalFields:   []string{},
			ConfidenceScores: make(map[string]float64),
		},
		IntegrationStatus: make(map[string]IntegrationState),
		ConversationFlow: FlowTracker{
			AskedQuestions:  []string{},
			ProvidedAnswers: []string{},
			CurrentStage:    "initial",
			LastActivity:    now,
		},
		SessionID:   sessionID,
		CreatedAt:   now,
		LastUpdated: now,
		// Initialize sequential processing state
		CurrentIntegrationIndex: 0,
		IntegrationResults:      make(map[string]interface{}),
		WaitingForSatisfaction:  false,
		LastExecutedIntegration: nil,
	}

	s.enhancedSessions.Store(sessionID, session)
	return session
}

// updateFieldState updates the field state with new extracted data
func (s *service) updateFieldState(sessionID string, fieldName string, value interface{}, source string, confidence float64) {
	session := s.getOrCreateEnhancedSession(sessionID)

	// Update field data
	session.FieldState.ExtractedFields[fieldName] = value
	session.FieldState.FieldSources[fieldName] = source
	session.FieldState.ConfidenceScores[fieldName] = confidence
	session.FieldState.LastUpdated = time.Now()

	// Store updated session
	s.enhancedSessions.Store(sessionID, session)
	s.logger.Info("Field state updated", "session_id", sessionID, "field", fieldName, "confidence", confidence)
}

// getFieldState retrieves the current field state for a session
func (s *service) getFieldState(sessionID string) SessionFieldState {
	session := s.getOrCreateEnhancedSession(sessionID)
	return session.FieldState
}

// updateIntegrationState updates the status of an integration
func (s *service) updateIntegrationState(sessionID string, integrationID uuid.UUID, name string, readyToTrigger bool, missingFields []string) {
	session := s.getOrCreateEnhancedSession(sessionID)

	integrationKey := integrationID.String()
	state := IntegrationState{
		ID:             integrationID,
		Name:           name,
		ReadyToTrigger: readyToTrigger,
		MissingFields:  missingFields,
	}

	if existingState, exists := session.IntegrationStatus[integrationKey]; exists {
		state.LastTriggered = existingState.LastTriggered
		state.TriggerCount = existingState.TriggerCount
		state.LastResult = existingState.LastResult
	}

	session.IntegrationStatus[integrationKey] = state
	s.enhancedSessions.Store(sessionID, session)
}

// markIntegrationTriggered marks an integration as triggered
func (s *service) markIntegrationTriggered(sessionID string, integrationID uuid.UUID, result map[string]interface{}) {
	session := s.getOrCreateEnhancedSession(sessionID)

	integrationKey := integrationID.String()
	if state, exists := session.IntegrationStatus[integrationKey]; exists {
		now := time.Now()
		state.LastTriggered = &now
		state.TriggerCount++
		state.LastResult = result
		state.ReadyToTrigger = false // Reset after triggering

		session.IntegrationStatus[integrationKey] = state
		s.enhancedSessions.Store(sessionID, session)
	}
}

// Sequential Integration Processing Functions

// markIntegrationExecuted marks an integration as executed and sets up waiting for customer satisfaction
func (s *service) markIntegrationExecuted(sessionID string, integrationID uuid.UUID, integrationName string, result map[string]interface{}) {
	session := s.getOrCreateEnhancedSession(sessionID)

	// Store the integration result
	session.IntegrationResults[integrationName] = result
	session.LastExecutedIntegration = &integrationID
	session.WaitingForSatisfaction = true

	// Mark the integration as triggered in the status
	s.markIntegrationTriggered(sessionID, integrationID, result)

	s.enhancedSessions.Store(sessionID, session)
	s.logger.Info("Integration executed, waiting for customer satisfaction", "session_id", sessionID, "integration", integrationName)
}

// checkCustomerSatisfaction determines if customer is satisfied with the last integration result
func (s *service) checkCustomerSatisfaction(ctx context.Context, userMessage, sessionID string) bool {
	session := s.getOrCreateEnhancedSession(sessionID)

	if !session.WaitingForSatisfaction || session.LastExecutedIntegration == nil {
		return false
	}

	// Use AI to determine if customer is satisfied
	prompt := fmt.Sprintf(`Analyze the user's message to determine if they are satisfied with the previous integration result and ready to proceed to the next step.

User message: "%s"

Return "SATISFIED" if the user:
- Confirms they are happy with the result
- Says "yes", "ok", "good", "proceed", "next", "continue"
- Expresses satisfaction or approval
- Asks to move forward or proceed

Return "NOT_SATISFIED" if the user:
- Expresses dissatisfaction or concerns
- Asks questions about the result
- Wants to change something
- Says "no", "wait", "hold on"
- Needs clarification

Return only "SATISFIED" or "NOT_SATISFIED".`, userMessage)

	// Make AI call to determine satisfaction
	messages := []OpenAIMessage{
		{Role: "user", Content: prompt},
	}

	// Create AI settings for satisfaction check
	settings := &entity.AISettings{
		Model: "gpt-4.1-nano",
	}

	response, err := s.callOpenAI(ctx, messages, settings, userMessage, len(prompt), nil, "satisfaction_check")
	if err != nil {
		s.logger.With(ctx).Error("Failed to check customer satisfaction", "error", err)
		return false
	}

	var responseText string
	if len(response.Choices) > 0 {
		responseText = response.Choices[0].Message.Content
	}

	isSatisfied := strings.Contains(strings.ToUpper(responseText), "SATISFIED")
	s.logger.With(ctx).Info("Customer satisfaction check", "session_id", sessionID, "satisfied", isSatisfied, "response", responseText)

	return isSatisfied
}

// proceedToNextIntegration moves to the next integration in sequence
func (s *service) proceedToNextIntegration(sessionID string) {
	session := s.getOrCreateEnhancedSession(sessionID)

	// Move to next integration
	session.CurrentIntegrationIndex++
	session.WaitingForSatisfaction = false
	session.LastExecutedIntegration = nil

	s.enhancedSessions.Store(sessionID, session)
	s.logger.Info("Proceeding to next integration", "session_id", sessionID, "next_index", session.CurrentIntegrationIndex)
}

// resetIntegrationSequence resets the integration sequence to start from the beginning
func (s *service) resetIntegrationSequence(sessionID string) {
	session := s.getOrCreateEnhancedSession(sessionID)

	session.CurrentIntegrationIndex = 0
	session.WaitingForSatisfaction = false
	session.LastExecutedIntegration = nil
	session.IntegrationResults = make(map[string]interface{})

	s.enhancedSessions.Store(sessionID, session)
	s.logger.Info("Integration sequence reset", "session_id", sessionID)
}

// updateEnhancedSession updates the enhanced session data
func (s *service) updateEnhancedSession(sessionID string, session *EnhancedSession) {
	s.enhancedSessions.Store(sessionID, session)
}

// extractAndPreserveKeyConversationElements extracts and preserves critical conversation elements
func (s *service) extractAndPreserveKeyConversationElements(sessionID string) {
	// Get conversation history
	var conversationHistory []OpenAIMessage
	if history, exists := s.sessions.Load(sessionID); exists {
		if historyMessages, ok := history.([]OpenAIMessage); ok {
			conversationHistory = historyMessages
		}
	}

	if len(conversationHistory) == 0 {
		return
	}

	// Get or create enhanced session
	session := s.getOrCreateEnhancedSession(sessionID)

	// Extract key conversation elements from all user messages
	serviceRequests := make(map[string]string)
	userIntents := make(map[string]string)
	importantDetails := make(map[string]string)

	for i, msg := range conversationHistory {
		if msg.Role == "user" {
			if content, ok := msg.Content.(string); ok {
				contentLower := strings.ToLower(content)

				// Extract service requests using generic patterns
				// Look for action verbs + nouns that indicate service requests
				servicePatterns := []string{
					"mau", "ingin", "butuh", "perlu", "request", "need", "want",
					"service", "perbaikan", "maintenance", "cleaning", "repair",
					"install", "pasang", "bongkar", "relokasi", "move",
				}

				for _, pattern := range servicePatterns {
					if strings.Contains(contentLower, pattern) {
						// Extract the full context around the pattern
						words := strings.Fields(content)
						for j, word := range words {
							if strings.Contains(strings.ToLower(word), pattern) {
								// Capture context: 2 words before and 3 words after
								start := j - 2
								if start < 0 {
									start = 0
								}
								end := j + 4
								if end > len(words) {
									end = len(words)
								}
								context := strings.Join(words[start:end], " ")
								serviceRequests[fmt.Sprintf("msg_%d", i+1)] = context
								importantDetails["service_request"] = fmt.Sprintf("User mentioned service/request in message %d: %s", i+1, context)
								break
							}
						}
						break
					}
				}

				// Extract user intents using generic intent patterns
				intentPatterns := []string{"help", "assist", "support", "solve", "fix", "handle"}
				for _, pattern := range intentPatterns {
					if strings.Contains(contentLower, pattern) {
						userIntents[fmt.Sprintf("intent_msg_%d", i+1)] = content
						importantDetails["user_intent"] = fmt.Sprintf("User expressed intent in message %d: %s", i+1, content)
						break
					}
				}

				// Extract problem descriptions using generic problem indicators
				problemPatterns := []string{"problem", "issue", "error", "broken", "not working", "rusak", "bermasalah", "tidak"}
				for _, pattern := range problemPatterns {
					if strings.Contains(contentLower, pattern) {
						importantDetails["problem_description"] = fmt.Sprintf("User described issue in message %d: %s", i+1, content)
						break
					}
				}
			}
		}
	}

	// Store key elements in session for preservation
	if session.FieldState.ExtractedFields == nil {
		session.FieldState.ExtractedFields = make(map[string]interface{})
	}
	if session.FieldState.FieldSources == nil {
		session.FieldState.FieldSources = make(map[string]string)
	}
	if session.FieldState.ConfidenceScores == nil {
		session.FieldState.ConfidenceScores = make(map[string]float64)
	}

	// Preserve service requests with high confidence
	for _, serviceContext := range serviceRequests {
		session.FieldState.ExtractedFields["preserved_service_request"] = serviceContext
		session.FieldState.FieldSources["preserved_service_request"] = importantDetails["service_request"]
		session.FieldState.ConfidenceScores["preserved_service_request"] = 0.95
		break // Only preserve the first/most relevant service request
	}

	// Preserve user intents
	for _, intentContext := range userIntents {
		session.FieldState.ExtractedFields["preserved_user_intent"] = intentContext
		session.FieldState.FieldSources["preserved_user_intent"] = importantDetails["user_intent"]
		session.FieldState.ConfidenceScores["preserved_user_intent"] = 0.90
		break // Only preserve the first/most relevant intent
	}

	// Preserve problem descriptions
	if problemDesc, exists := importantDetails["problem_description"]; exists {
		session.FieldState.ExtractedFields["preserved_problem_description"] = problemDesc
		session.FieldState.FieldSources["preserved_problem_description"] = problemDesc
		session.FieldState.ConfidenceScores["preserved_problem_description"] = 0.85
	}

	session.LastUpdated = time.Now()
	s.enhancedSessions.Store(sessionID, session)
}

// buildFieldStateContext creates enhanced context for AI about current field state with intelligence
func (s *service) buildFieldStateContext(sessionID string) string {
	session := s.getOrCreateEnhancedSession(sessionID)

	if len(session.FieldState.ExtractedFields) == 0 {
		return ""
	}

	var context strings.Builder
	context.WriteString("\n\n=== ENHANCED FIELD STATE CONTEXT ===\n")
	context.WriteString("Previously extracted and validated information from this conversation:\n")

	// Add preserved key conversation elements section
	if preservedService, exists := session.FieldState.ExtractedFields["preserved_service_request"]; exists {
		context.WriteString("\nðŸ”‘ PRESERVED KEY CONVERSATION ELEMENTS:\n")
		context.WriteString(fmt.Sprintf("  âœ“ Service Request: %v (source: %s)\n", preservedService, session.FieldState.FieldSources["preserved_service_request"]))
	}
	if preservedIntent, exists := session.FieldState.ExtractedFields["preserved_user_intent"]; exists {
		context.WriteString(fmt.Sprintf("  âœ“ User Intent: %v (source: %s)\n", preservedIntent, session.FieldState.FieldSources["preserved_user_intent"]))
	}
	if preservedProblem, exists := session.FieldState.ExtractedFields["preserved_problem_description"]; exists {
		context.WriteString(fmt.Sprintf("  âœ“ Problem Description: %v\n", preservedProblem))
	}

	// Group fields by confidence level for better AI understanding
	highConfidenceFields := make(map[string]interface{})
	mediumConfidenceFields := make(map[string]interface{})
	lowConfidenceFields := make(map[string]interface{})

	for field, value := range session.FieldState.ExtractedFields {
		confidence := session.FieldState.ConfidenceScores[field]
		if confidence >= 0.8 {
			highConfidenceFields[field] = value
		} else if confidence >= 0.6 {
			mediumConfidenceFields[field] = value
		} else {
			lowConfidenceFields[field] = value
		}
	}

	// Display high confidence fields first
	if len(highConfidenceFields) > 0 {
		context.WriteString("\nðŸŸ¢ HIGH CONFIDENCE FIELDS (reliable data):\n")
		for field, value := range highConfidenceFields {
			source := session.FieldState.FieldSources[field]
			confidence := session.FieldState.ConfidenceScores[field]
			context.WriteString(fmt.Sprintf("  âœ“ %s: %v (source: %s, confidence: %.2f)\n", field, value, source, confidence))
		}
	}

	// Display medium confidence fields
	if len(mediumConfidenceFields) > 0 {
		context.WriteString("\nðŸŸ¡ MEDIUM CONFIDENCE FIELDS (may need verification):\n")
		for field, value := range mediumConfidenceFields {
			source := session.FieldState.FieldSources[field]
			confidence := session.FieldState.ConfidenceScores[field]
			context.WriteString(fmt.Sprintf("  ? %s: %v (source: %s, confidence: %.2f)\n", field, value, source, confidence))
		}
	}

	// Display low confidence fields
	if len(lowConfidenceFields) > 0 {
		context.WriteString("\nðŸ”´ LOW CONFIDENCE FIELDS (require confirmation):\n")
		for field, value := range lowConfidenceFields {
			source := session.FieldState.FieldSources[field]
			confidence := session.FieldState.ConfidenceScores[field]
			context.WriteString(fmt.Sprintf("  âš  %s: %v (source: %s, confidence: %.2f)\n", field, value, source, confidence))
		}
	}

	// Enhanced missing fields analysis
	if len(session.FieldState.RequiredFields) > 0 {
		context.WriteString("\nðŸ” STILL NEEDED (required fields):\n")
		for _, field := range session.FieldState.RequiredFields {
			context.WriteString(fmt.Sprintf("  - %s (required for integration completion)\n", field))
		}
		context.WriteString("\nðŸ’¡ STATUS: Required fields pending.\n")
	}

	return context.String()
}

// buildIntegrationStateContext creates enhanced context for AI about integration readiness with flow intelligence
func (s *service) buildIntegrationStateContext(sessionID string) string {
	session := s.getOrCreateEnhancedSession(sessionID)

	if len(session.IntegrationStatus) == 0 {
		return ""
	}

	var context strings.Builder
	context.WriteString("\n\n=== ENHANCED INTEGRATION STATUS & FLOW INTELLIGENCE ===\n")

	// Categorize integrations by readiness status
	readyIntegrations := []IntegrationState{}
	pendingIntegrations := []IntegrationState{}
	blockedIntegrations := []IntegrationState{}

	for _, state := range session.IntegrationStatus {
		if state.ReadyToTrigger {
			readyIntegrations = append(readyIntegrations, state)
		} else if len(state.MissingFields) > 0 {
			pendingIntegrations = append(pendingIntegrations, state)
		} else {
			blockedIntegrations = append(blockedIntegrations, state)
		}
	}

	// Display ready integrations first
	if len(readyIntegrations) > 0 {
		context.WriteString("\nðŸŸ¢ READY TO TRIGGER (all requirements met):\n")
		for _, state := range readyIntegrations {
			context.WriteString(fmt.Sprintf("  âœ… %s", state.Name))
			if state.LastTriggered != nil {
				context.WriteString(fmt.Sprintf(" (last triggered: %s, count: %d)", state.LastTriggered.Format("2006-01-02 15:04"), state.TriggerCount))
			}
			// Include last result data if available
			if state.LastResult != nil && len(state.LastResult) > 0 {
				context.WriteString("\n    ðŸ“Š Last Result Data: ")
				if resultJSON, err := json.Marshal(state.LastResult); err == nil {
					context.WriteString(string(resultJSON))
				} else {
					context.WriteString(fmt.Sprintf("%+v", state.LastResult))
				}
			}
			context.WriteString("\n")
		}
		context.WriteString("\nðŸ’¡ STATUS: Ready integrations available.\n")
	}

	// Display pending integrations
	if len(pendingIntegrations) > 0 {
		context.WriteString("\nðŸŸ¡ PENDING (missing required data):\n")
		for _, state := range pendingIntegrations {
			context.WriteString(fmt.Sprintf("  â³ %s\n", state.Name))
			context.WriteString(fmt.Sprintf("    Missing: %s\n", strings.Join(state.MissingFields, ", ")))
			if state.LastTriggered != nil {
				context.WriteString(fmt.Sprintf("    Previous triggers: %d (last: %s)\n", state.TriggerCount, state.LastTriggered.Format("2006-01-02 15:04")))
			}
			// Include last result data if available
			if state.LastResult != nil && len(state.LastResult) > 0 {
				context.WriteString("    ðŸ“Š Last Result Data: ")
				if resultJSON, err := json.Marshal(state.LastResult); err == nil {
					context.WriteString(string(resultJSON))
				} else {
					context.WriteString(fmt.Sprintf("%+v", state.LastResult))
				}
				context.WriteString("\n")
			}
		}
		context.WriteString("\nðŸ’¡ STATUS: Pending integrations available.\n")
	}

	// Display blocked integrations
	if len(blockedIntegrations) > 0 {
		context.WriteString("\nðŸ”´ BLOCKED (configuration issues):\n")
		for _, state := range blockedIntegrations {
			context.WriteString(fmt.Sprintf("  âŒ %s (check configuration)\n", state.Name))
			// Include last result data if available
			if state.LastResult != nil && len(state.LastResult) > 0 {
				context.WriteString("    ðŸ“Š Last Result Data: ")
				if resultJSON, err := json.Marshal(state.LastResult); err == nil {
					context.WriteString(string(resultJSON))
				} else {
					context.WriteString(fmt.Sprintf("%+v", state.LastResult))
				}
				context.WriteString("\n")
			}
		}
	}

	return context.String()
}

// checkMissingFields determines which required fields are still missing
func (s *service) checkMissingFields(session *EnhancedSession, fields []entity.CustomIntegrationField) []string {
	var missingFields []string
	for _, field := range fields {
		if field.IsRequired {
			if _, exists := session.FieldState.ExtractedFields[field.FieldName]; !exists {
				missingFields = append(missingFields, field.FieldName)
			}
		}
	}
	return missingFields
}

// evaluateTriggerConditionPreProcessEnhanced evaluates trigger with enhanced field context
// Creates a dedicated AI instance for each integration with its specific field configuration
func (s *service) evaluateTriggerConditionPreProcessEnhanced(ctx context.Context, triggerCondition, userMessage, sessionID string, integrationID uuid.UUID, enhancedSession *EnhancedSession) (bool, map[string]interface{}, string, error) {
	// Get integration details for this specific integration
	integrationEntity, err := s.customIntegrationService.GetCustomIntegrationByID(ctx, integrationID)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to get integration details:", err)
		return false, nil, "", fmt.Errorf("failed to get integration details: %w", err)
	}

	// Get integration fields specific to this integration
	fields, err := s.customIntegrationService.GetCustomIntegrationFieldsByIntegrationID(ctx, integrationID)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to get integration fields:", err)
		return false, nil, "", fmt.Errorf("failed to get integration fields: %w", err)
	}

	s.logger.With(ctx).Info("ðŸŽ¯ Creating dedicated AI instance for integration:", integrationEntity.Name, "with", len(fields), "fields")

	// Build field descriptions specific to this integration
	fieldDescriptions := make([]string, 0, len(fields))
	for _, field := range fields {
		desc := fmt.Sprintf("%s (%s)", field.FieldName, field.FieldType)
		if field.Description != nil {
			desc += ": " + *field.Description
		}
		if field.FieldType == "enum" && field.EnumValues != nil {
			desc += " [Options: " + *field.EnumValues + "]"
		}
		if field.IsRequired {
			desc += " (Required)"
		}
		fieldDescriptions = append(fieldDescriptions, desc)
	}

	// Build conversation context
	conversationHistory := s.getConversationHistory(sessionID)

	// Build comprehensive field analysis for better extraction
	requiredFields := make([]string, 0)
	optionalFields := make([]string, 0)
	for _, field := range fields {
		if field.IsRequired {
			requiredFields = append(requiredFields, field.FieldName)
		} else {
			optionalFields = append(optionalFields, field.FieldName)
		}
	}

	// Build field formatting rules dynamically based on actual field configurations
	// Use field descriptions as behavior guides for this specific AI instance
	fieldFormattingRules := make([]string, 0)

	for _, field := range fields {
		if field.FieldType == "enum" && field.EnumValues != nil {
			// Parse enum values
			enumOptions := strings.Split(*field.EnumValues, ",")
			for i, option := range enumOptions {
				enumOptions[i] = strings.TrimSpace(option)
			}

			// Enhanced enum field rule with intelligent matching
			rule := fmt.Sprintf("   - For %s field: Use intelligent fuzzy matching to find the best match from available enum options [%s].", field.FieldName, strings.Join(enumOptions, ", "))

			// CRITICAL: Use field description as formatting behavior guide for this specific AI instance
			if field.Description != nil && *field.Description != "" {
				rule += fmt.Sprintf(" FORMATTING BEHAVIOR: %s", *field.Description)
				// Log the formatting behavior for debugging
				s.logger.With(ctx).Info("ðŸŽ¯ Field formatting behavior for", field.FieldName, ":", *field.Description)
			} else {
				rule += " If uncertain or no close match found, return to main AI with clarificationSuggestion asking user to choose from available options."
			}

			fieldFormattingRules = append(fieldFormattingRules, rule)

		} else if field.FieldType != "enum" {
			// Add rules for non-enum fields with description-based behavior
			var fieldRule string
			switch field.FieldType {
			case "text":
				fieldRule = fmt.Sprintf("   - For %s field: Extract relevant text information from user message", field.FieldName)
			case "email":
				fieldRule = fmt.Sprintf("   - For %s field: Extract valid email address from user message", field.FieldName)
			case "number":
				fieldRule = fmt.Sprintf("   - For %s field: Extract numeric value from user message", field.FieldName)
			case "boolean":
				fieldRule = fmt.Sprintf("   - For %s field: Determine true/false based on user intent", field.FieldName)
			case "date":
				fieldRule = fmt.Sprintf("   - For %s field: Extract date information in YYYY-MM-DD format", field.FieldName)
			case "url":
				fieldRule = fmt.Sprintf("   - For %s field: Extract valid URL from user message", field.FieldName)
			default:
				fieldRule = fmt.Sprintf("   - For %s field: Extract relevant information from user message", field.FieldName)
			}

			// CRITICAL: Use field description as formatting behavior guide for this specific AI instance
			if field.Description != nil && *field.Description != "" {
				fieldRule += fmt.Sprintf(" FORMATTING BEHAVIOR: %s", *field.Description)
				// Log the formatting behavior for debugging
				s.logger.With(ctx).Info("ðŸŽ¯ Field formatting behavior for", field.FieldName, ":", *field.Description)
			}

			fieldFormattingRules = append(fieldFormattingRules, fieldRule)
		}
	}

	// Build webhook payload structure information for better field validation
	webhookPayloadInfo := s.buildWebhookPayloadStructure(integrationEntity, fields)

	// Add current date context for accurate date processing
	currentTime := time.Now()
	dateContext := fmt.Sprintf(`

=== CURRENT DATE CONTEXT ===
Today's date: %s
Current year: %d
Current month: %02d
Current day: %02d

IMPORTANT DATE FORMATTING RULES:
- When user says 'tanggal 18' format it as: %d-%02d-18
- When user says '18 agustus' format it as: %d-08-18
- When user says 'besok' (tomorrow) format it as: %s
- When user says 'lusa' (day after tomorrow) format it as: %s
- Always use the current year (%d) unless explicitly specified otherwise
- For relative dates like 'besok' or 'lusa', calculate from today's date`,
		currentTime.Format("2006-01-02"),
		currentTime.Year(),
		int(currentTime.Month()),
		currentTime.Day(),
		currentTime.Year(),
		int(currentTime.Month()),
		currentTime.Year(),
		currentTime.AddDate(0, 0, 1).Format("2006-01-02"),
		currentTime.AddDate(0, 0, 2).Format("2006-01-02"),
		currentTime.Year())

	// Create dedicated AI prompt for this specific integration
	prompt := fmt.Sprintf(`You are a specialized data extraction AI dedicated EXCLUSIVELY to the "%s" integration. Your ONLY responsibility is to analyze conversations for this specific integration's trigger condition and extract its specific field data.%s

=== YOUR DEDICATED INTEGRATION CONFIGURATION ===
Integration Name: %s
Integration ID: %s
Trigger Condition: %s
Webhook URL: %s
HTTP Method: %s
Content Type: %s
Timeout: %d seconds
Integration Description: %s

=== WEBHOOK PAYLOAD STRUCTURE ===
%s

=== YOUR SPECIFIC FIELD RESPONSIBILITIES ===
%s

=== CONVERSATION CONTEXT ===%s

Current User Message: %s

=== YOUR FIELD EXTRACTION STRATEGY ===
Required Fields: [%s]
Optional Fields: [%s]

=== YOUR SPECIALIZED FIELD FORMATTING RULES ===
%s

=== YOUR ANALYSIS INSTRUCTIONS ===

1. INTEGRATION-SPECIFIC FOCUS:
   - You are ONLY responsible for the "%s" integration
   - Ignore any other integrations or unrelated data
   - Focus exclusively on your trigger condition and field requirements
   - Apply your specific field descriptions and enum values

2. INTELLIGENT FIELD MATCHING:
   - Use your specific field descriptions as behavior guides
   - For enum fields, apply intelligent fuzzy matching with your specific enum options
   - Follow your field-specific formatting instructions precisely
   - Prioritize current message content over conversation history

3. TRIGGER EVALUATION LOGIC:
   - Evaluate ONLY your specific trigger condition
   - Extract ONLY your specific fields
   - Set trigger_met = true if ALL your required fields can be found
   - Use conversation history for additional context

Respond ONLY with a JSON object:
{
  "trigger_met": true/false,
  "extracted_data": {
    "field_name": "extracted_value",
    ...
  },
  "field_sources": {
    "field_name": "source description",
    ...
  },
  "reasoning": "detailed explanation focusing on your specific integration and fields"
}

CRITICAL RULES:
- This is INTERNAL PROCESSING - do NOT generate user-facing responses
- ONLY output the JSON object above
- Focus EXCLUSIVELY on your assigned integration: "%s"
- Apply your specific field descriptions and enum values
- Use intelligent fuzzy matching for your enum fields
- NEVER assume field values not explicitly mentioned in the conversation`,
		integrationEntity.Name,
		dateContext,
		integrationEntity.Name,
		integrationEntity.ID,
		triggerCondition,
		integrationEntity.WebhookURL,
		integrationEntity.HTTPMethod,
		integrationEntity.ContentType,
		integrationEntity.TimeoutSeconds,
		integrationEntity.Description,
		webhookPayloadInfo,
		strings.Join(fieldDescriptions, "\n"),
		conversationHistory,
		userMessage,
		strings.Join(requiredFields, ", "),
		strings.Join(optionalFields, ", "),
		strings.Join(fieldFormattingRules, "\n"),
		integrationEntity.Name,
		integrationEntity.Name)

	s.logger.With(ctx).Info("ðŸ¤– Sending dedicated AI evaluation for integration:", integrationEntity.Name)

	// Call OpenAI for trigger evaluation with dedicated AI instance
	messages := []OpenAIMessage{
		{
			Role:    "system",
			Content: fmt.Sprintf("You are AI 2.%s - a specialized data extraction system dedicated EXCLUSIVELY to the '%s' integration. Your ONLY job is to analyze text for this specific integration and return JSON data. You MUST NOT generate any user-facing responses, conversational text, or waiting messages. ONLY return the requested JSON object for your assigned integration.", integrationID.String()[:8], integrationEntity.Name),
		},
		{
			Role:    "user",
			Content: prompt,
		},
	}

	// Use a powerful model for comprehensive trigger evaluation
	settings := &entity.AISettings{
		Model: "gpt-4.1-nano",
	}

	// Get token tracker from context or create a new one for tracking this evaluation
	tokenTracker := accesslog.GetTokenTrackerFromContext(ctx)
	if tokenTracker == nil {
		requestID := uuid.New().String()
		tokenTracker = accesslog.NewTokenTracker(requestID)
		s.logger.With(ctx).Infof("ðŸ”¢ Created token tracker for dedicated trigger evaluation: %s", requestID)
	}

	resp, err := s.callOpenAI(ctx, messages, settings, "dedicated_trigger_evaluation", len(prompt), tokenTracker, fmt.Sprintf("trigger_evaluation_%s", integrationEntity.Name))

	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to call OpenAI for dedicated trigger evaluation:", err)
		return false, nil, "", fmt.Errorf("failed to evaluate trigger condition: %w", err)
	}

	// Log AI usage for trigger evaluation (specific operation, separate from main conversation flow)
	s.logAIUsage(ctx, settings.Model, resp.Usage.TotalTokens, "dedicated_trigger_evaluation", sessionID, uuid.Nil, "", "internal")

	// NOTE: Model usage tracking is handled by the main conversation flow to avoid double tracking

	if len(resp.Choices) == 0 {
		s.logger.With(ctx).Error("âŒ No response from OpenAI for dedicated trigger evaluation")
		return false, nil, "", fmt.Errorf("no response from OpenAI")
	}

	responseContent := resp.Choices[0].Message.Content
	s.logger.With(ctx).Info("ðŸ¤– AI dedicated trigger evaluation response for", integrationEntity.Name, ":", responseContent)

	// Clean and validate the response content
	responseContent = strings.TrimSpace(responseContent)

	// Validate JSON structure before unmarshaling
	if !json.Valid([]byte(responseContent)) {
		s.logger.With(ctx).Error("âŒ Invalid JSON structure detected, attempting to extract JSON from response")

		// Try to extract JSON from the response if it's wrapped in other text
		jsonStart := strings.Index(responseContent, "{")
		jsonEnd := strings.LastIndex(responseContent, "}")

		if jsonStart != -1 && jsonEnd != -1 && jsonEnd > jsonStart {
			extractedJSON := responseContent[jsonStart : jsonEnd+1]
			if json.Valid([]byte(extractedJSON)) {
				s.logger.With(ctx).Info("âœ… Successfully extracted valid JSON from response")
				responseContent = extractedJSON
			} else {
				s.logger.With(ctx).Error("âŒ Extracted JSON is still invalid")
				return false, nil, "", fmt.Errorf("invalid JSON structure in AI response")
			}
		} else {
			s.logger.With(ctx).Error("âŒ No JSON structure found in response")
			return false, nil, "", fmt.Errorf("no valid JSON found in AI response")
		}
	}

	// Parse the JSON response
	var result struct {
		TriggerMet    bool                   `json:"trigger_met"`
		ExtractedData map[string]interface{} `json:"extracted_data"`
		FieldSources  map[string]string      `json:"field_sources"`
		Reasoning     string                 `json:"reasoning"`
	}

	if err := json.Unmarshal([]byte(responseContent), &result); err != nil {
		s.logger.With(ctx).Error("âŒ Failed to parse JSON response:", err)
		s.logger.With(ctx).Error("âŒ Response content:", responseContent)
		return false, nil, "", fmt.Errorf("failed to parse AI response: %w", err)
	}

	s.logger.With(ctx).Info("âœ… Dedicated AI evaluation completed for", integrationEntity.Name, "- Trigger met:", result.TriggerMet)
	if len(result.ExtractedData) > 0 {
		s.logger.With(ctx).Info("ðŸ“Š Extracted data:", result.ExtractedData)
	}

	// Generate clarification suggestion if needed
	clarificationSuggestion := ""
	if !result.TriggerMet {
		if strings.Contains(result.Reasoning, "missing") || strings.Contains(result.Reasoning, "not found") {
			clarificationSuggestion = "Bisa diperjelas maksudnya?"
			s.logger.With(ctx).Info("ðŸ’¬ Generic clarification suggestion generated:", clarificationSuggestion)
		} else if strings.Contains(result.Reasoning, "not supported in available options") || strings.Contains(result.Reasoning, "not listed among the supported options") {
			clarificationSuggestion = "Maaf, lokasi tersebut belum tersedia dalam jangkauan layanan kami. Bisa coba lokasi lain?"
			s.logger.With(ctx).Info("ðŸš« Unsupported location detected, clarification suggestion generated:", clarificationSuggestion)
		}
	}

	return result.TriggerMet, result.ExtractedData, clarificationSuggestion, nil
}

// getConversationHistory retrieves conversation history for context
func (s *service) getConversationHistory(sessionID string) string {
	if value, ok := s.sessions.Load(sessionID); ok {
		if messages, ok := value.([]OpenAIMessage); ok {
			var history strings.Builder
			history.WriteString("\n\n=== CONVERSATION HISTORY ===\n")
			// Get last 6 messages for context
			start := 0
			if len(messages) > 6 {
				start = len(messages) - 6
			}
			for i := start; i < len(messages); i++ {
				msg := messages[i]
				history.WriteString(fmt.Sprintf("%s: %s\n", msg.Role, msg.Content))
			}
			return history.String()
		}
	}
	return ""
}

// updateConversationSummary creates a summary of the conversation for better context management
func (s *service) updateConversationSummary(sessionID string, history []OpenAIMessage) {
	if len(history) < 4 {
		return // Not enough messages to summarize
	}

	// Create an enhanced summary of the last 10 messages with intelligent analysis
	start := 0
	if len(history) > 10 {
		start = len(history) - 10
	}

	var summaryBuilder strings.Builder
	summaryBuilder.WriteString("Enhanced conversation summary with flow intelligence:\n")

	// Analyze conversation patterns
	userQuestions := 0
	aiResponses := 0
	keywords := make(map[string]int)
	topics := []string{}
	userIntents := []string{}

	for i := start; i < len(history); i++ {
		msg := history[i]
		if msg.Role == "user" {
			if content, ok := msg.Content.(string); ok {
				summaryBuilder.WriteString(fmt.Sprintf("Customer: %s\n", s.truncateMessage(content, 100)))

				// Analyze user message patterns
				if strings.Contains(content, "?") {
					userQuestions++
				}

				// Extract keywords and potential intents
				words := strings.Fields(strings.ToLower(content))
				for _, word := range words {
					if len(word) > 3 {
						keywords[word]++
					}
				}

				// Detect user intents
				contentLower := strings.ToLower(content)
				if strings.Contains(contentLower, "help") || strings.Contains(contentLower, "bantuan") {
					userIntents = append(userIntents, "seeking_help")
				}
				if strings.Contains(contentLower, "buy") || strings.Contains(contentLower, "beli") || strings.Contains(contentLower, "order") {
					userIntents = append(userIntents, "purchase_intent")
				}
				if strings.Contains(contentLower, "price") || strings.Contains(contentLower, "harga") || strings.Contains(contentLower, "cost") {
					userIntents = append(userIntents, "price_inquiry")
				}
				if strings.Contains(contentLower, "complaint") || strings.Contains(contentLower, "problem") || strings.Contains(contentLower, "issue") {
					userIntents = append(userIntents, "complaint")
				}
			}
		} else if msg.Role == "assistant" {
			if content, ok := msg.Content.(string); ok {
				summaryBuilder.WriteString(fmt.Sprintf("AI: %s\n", s.truncateMessage(content, 100)))
				aiResponses++
			}
		}
	}

	// Extract top keywords as topics
	type keywordCount struct {
		word  string
		count int
	}
	var sortedKeywords []keywordCount
	for word, count := range keywords {
		if count > 1 { // Only include words mentioned multiple times
			sortedKeywords = append(sortedKeywords, keywordCount{word, count})
		}
	}

	// Sort by frequency and take top 5
	for i := 0; i < len(sortedKeywords)-1; i++ {
		for j := i + 1; j < len(sortedKeywords); j++ {
			if sortedKeywords[i].count < sortedKeywords[j].count {
				sortedKeywords[i], sortedKeywords[j] = sortedKeywords[j], sortedKeywords[i]
			}
		}
	}

	for i, kw := range sortedKeywords {
		if i >= 5 {
			break
		}
		topics = append(topics, kw.word)
	}

	// Add conversation flow analysis to summary
	summaryBuilder.WriteString(fmt.Sprintf("\n=== CONVERSATION ANALYSIS ===\n"))
	summaryBuilder.WriteString(fmt.Sprintf("User questions: %d, AI responses: %d\n", userQuestions, aiResponses))
	if len(topics) > 0 {
		summaryBuilder.WriteString(fmt.Sprintf("Key topics: %s\n", strings.Join(topics, ", ")))
	}
	if len(userIntents) > 0 {
		summaryBuilder.WriteString(fmt.Sprintf("Detected intents: %s\n", strings.Join(userIntents, ", ")))
	}

	// Determine conversation stage
	messageCount := len(history)
	var conversationStage string
	if messageCount <= 3 {
		conversationStage = "opening"
	} else if messageCount <= 10 {
		conversationStage = "information_gathering"
	} else if messageCount <= 20 {
		conversationStage = "problem_solving"
	} else {
		conversationStage = "extended_engagement"
	}
	summaryBuilder.WriteString(fmt.Sprintf("Conversation stage: %s\n", conversationStage))

	// Create enhanced summary object
	summary := &ConversationSummary{
		FieldExtractions: make(map[string]string),
		KeyTopics:        topics,
		UserIntents:      userIntents,
		CompletionStatus: map[string]bool{
			"has_questions":      userQuestions > 0,
			"engagement_high":    float64(userQuestions)/float64(len(history)) > 0.3,
			"purchase_intent":    contains(userIntents, "purchase_intent"),
			"needs_assistance":   contains(userIntents, "seeking_help"),
			"conversation_stage": true, // Store stage in separate field if needed
		},
	}

	s.conversationSummaries.Store(sessionID, summary)
	s.logger.Info("ðŸ“Š Enhanced conversation summary updated", "session_id", sessionID, "stage", conversationStage, "topics", len(topics), "intents", len(userIntents))
}

// Helper function to check if slice contains string
func contains(slice []string, item string) bool {
	for _, s := range slice {
		if s == item {
			return true
		}
	}
	return false
}

// truncateMessage truncates a message to a specified length
func (s *service) truncateMessage(message string, maxLength int) string {
	if len(message) <= maxLength {
		return message
	}
	return message[:maxLength] + "..."
}

// NewService creates a new AI chat service with enhanced monitoring and configuration
func NewService(repo Repository, platformMappingRepo platformmapping.Repository, platformService platform.Service, leadService lead.Service, contactService contact.Service, stagesService stages.Service, pipelineService pipeline.Service, s3Service s3.Service, rajaOngkirService *rajaongkir.Service, customIntegrationService custom_integration.Service, aiKnowledgeService aiKnowledge.Service, dbManager *dbcontext.MultiTenantManager, logger log.Logger, openAIKey string, whatsappServiceURL string, usageTrackingService usage_tracking.Service, limitCheckerService limit_checker.Service) Service {
	svc := &service{
		repo:                     repo,
		platformMappingRepo:      platformMappingRepo,
		platformService:          platformService,
		leadService:              leadService,
		contactService:           contactService,
		stagesService:            stagesService,
		pipelineService:          pipelineService,
		s3Service:                s3Service,
		usageTrackingService:     usageTrackingService,
		limitCheckerService:      limitCheckerService,
		rajaOngkirService:        rajaOngkirService,
		customIntegrationService: customIntegrationService,
		aiKnowledgeService:       aiKnowledgeService,
		dbManager:                dbManager,
		logger:                   logger,
		openAIKey:                openAIKey,
		whatsappServiceURL:       whatsappServiceURL,
		// Enhanced session management initialization
		sessions:                 sync.Map{},
		enhancedSessions:         sync.Map{},
		fieldStateCache:          sync.Map{},
		integrationStateCache:    sync.Map{},
		conversationSummaries:    sync.Map{},
		transferCooldown:         sync.Map{},
		paymentDetectionCooldown: sync.Map{},
		imageProcessingMetrics:   sync.Map{},
		circuitBreaker:           sync.Map{},
		behaviorCache:            sync.Map{},
		paymentConfig: PaymentDetectionConfig{
			Enabled:           true,
			Sensitivity:       "medium",
			RequiredKeywords:  2,
			VisionModelForced: false,
		},
	}

	// Start background maintenance tasks
	ctx := context.Background()
	svc.startBackgroundTasks(ctx)

	logger.Info("ðŸš€ AI Chat Service initialized with enhanced monitoring and payment detection")
	return svc
}

// SendMessage processes a chat message and returns AI response
func (s *service) SendMessage(ctx context.Context, agentID uuid.UUID, req ChatRequest) (*ChatResponse, error) {
	// Get token tracker from context (set by accesslog middleware)
	tokenTracker := accesslog.GetTokenTrackerFromContext(ctx)
	if tokenTracker == nil {
		s.logger.With(ctx).Error("âŒ No token tracker found in context - middleware may not be properly configured")
		return nil, fmt.Errorf("token tracker not found in context")
	}
	s.logger.With(ctx).Infof("ðŸ”¢ Using token tracker from context: %s", tokenTracker.RequestID)

	// Get tenant database early to check for welcome message
	var tenantDB *dbcontext.DB
	var agent *entity.AIAgent
	var settings *entity.AISettings
	var err error

	tenantDB, _, err = dbcontext.GetTenantDB(ctx, s.dbManager)
	if err != nil {
		return nil, fmt.Errorf("failed to get tenant database: %w", err)
	}

	// Get AI agent and settings
	agent, err = s.repo.GetAIAgentByID(ctx, tenantDB, agentID)
	if err != nil {
		return nil, fmt.Errorf("failed to get AI agent: %w", err)
	}

	settings, err = s.repo.GetAISettingsByID(ctx, tenantDB, agent.IDSettings)
	if err != nil {
		return nil, fmt.Errorf("failed to get AI settings: %w", err)
	}

	// Pre-validation: Check AI response limits
	tenantID := token.GetTenantID(ctx)
	if tenantID != uuid.Nil {
		err := s.limitCheckerService.CheckAIResponseLimit(ctx, tenantID)
		if err != nil {
			s.logger.With(ctx).Errorf("AI response limit check failed for tenant %s: %v", tenantID, err)
			return nil, fmt.Errorf("limit exceeded: %w", err)
		}
		s.logger.With(ctx).Infof("AI response limit check passed for tenant %s", tenantID)
	} else {
		s.logger.With(ctx).Info("Unable to check limits: tenant ID is nil")
	}

	// Preserve context across model switches to maintain conversation continuity
	s.preserveContextAcrossModelSwitch(ctx, req.SessionID, settings)

	// Use AI 3 (Knowledge Service) to retrieve relevant knowledge
	s.logger.With(ctx).Info("ðŸ¤– Processing chat request for agent:", agentID)
	s.logger.With(ctx).Info("ðŸ§  Using AI 3 knowledge service for message:", req.Message[:min(50, len(req.Message))])

	// Call AI 3 knowledge service to extract specific information (librarian function)
	specificKnowledge, err := s.aiKnowledgeService.ExtractSpecificInformation(ctx, agentID, req.Message)
	if err != nil {
		s.logger.With(ctx).Error("âŒ AI 3 librarian extraction failed:", err)
		// Continue without specific knowledge
		specificKnowledge = ""
	} else {
		s.logger.With(ctx).Info("âœ… AI 3 librarian extraction completed successfully")
		if specificKnowledge != "" {
			s.logger.With(ctx).Info("ðŸ“š Specific knowledge extracted length:", len(specificKnowledge), "characters")
		} else {
			s.logger.With(ctx).Info("ðŸ“‹ No specific information found for this message")
		}
	}

	// Check for stored image analysis and integrate payment validation
	var imageAnalysisContext string
	var shouldAnalyzePayment bool

	if req.SessionID != "" {
		if storedResult, exists := s.imageAnalysisResults.Load(req.SessionID); exists {
			if analysisResult, ok := storedResult.(*ImageAnalysisResult); ok {
				// Check if the analysis result is still valid (not expired)
				if time.Since(analysisResult.Timestamp) <= analysisResult.TTL {
					imageAnalysisContext = analysisResult.Analysis
					s.logger.With(ctx).Info("ðŸ“¸ Found stored image analysis for payment validation", "session_id", req.SessionID, "age", time.Since(analysisResult.Timestamp))

					// Check if this looks like a payment validation scenario
					analysisLower := strings.ToLower(imageAnalysisContext)
					shouldAnalyzePayment = strings.Contains(analysisLower, "payment") ||
						strings.Contains(analysisLower, "transfer") ||
						strings.Contains(analysisLower, "bank") ||
						strings.Contains(analysisLower, "receipt") ||
						strings.Contains(analysisLower, "slip") ||
						strings.Contains(analysisLower, "pembayaran") ||
						strings.Contains(analysisLower, "bukti")

					if shouldAnalyzePayment {
						s.logger.With(ctx).Info("ðŸ’³ Payment validation context detected - integrating analysis")

						// Add payment validation instructions to the system behavior
						paymentInstructions := "\n\nPAYMENT VALIDATION CONTEXT:\n"
						paymentInstructions += "Based on the recent image analysis, determine if this is a valid payment proof.\n"
						paymentInstructions += "- If the analysis shows a valid Indonesian bank transfer (BCA, BNI, BRI, Mandiri, DANA, OVO, GoPay), respond: 'âœ… Pembayaran diterima'\n"
						paymentInstructions += "- If the analysis shows it's NOT a valid payment proof, respond: 'âŒ Bukan bukti pembayaran valid. Kirim screenshot transfer yang jelas.'\n"
						paymentInstructions += "- Consider the image analysis context when making this determination.\n"

						settings.Behaviour += paymentInstructions
					}
				} else {
					// Remove expired analysis result
					s.imageAnalysisResults.Delete(req.SessionID)
					s.logger.With(ctx).Info("ðŸ—‘ï¸ Removed expired image analysis for session", "session_id", req.SessionID)
				}
			}
		}
	}

	// PRE-PROCESS CUSTOM INTEGRATIONS BEFORE AI RESPONSE
	// This allows the AI to have access to integration results when generating its response
	s.logger.With(ctx).Info("ðŸ”„ Starting custom integration pre-processing for agent:", agentID, "message:", req.Message)
	integrationResults, err := s.preProcessCustomIntegrations(ctx, tenantDB, agentID, req.Message, "", req.SessionID)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Custom integration pre-processing failed:", err)
		// Continue without integration results
		integrationResults = nil
	} else {
		s.logger.With(ctx).Info("âœ… Custom integration pre-processing completed. Results count:", len(integrationResults))
		if len(integrationResults) > 0 {
			s.logger.With(ctx).Info("ðŸ“Š Integration results summary:", integrationResults)
		} else {
			s.logger.With(ctx).Info("ðŸ“‹ No integration results to include in AI context")
		}
	}
	// Build OpenAI messages with conversation history and integration results if session ID is provided
	s.logger.With(ctx).Info("ðŸ”¨ Building OpenAI messages...")
	s.logger.With(ctx).Info("ðŸ”§ Integration results being passed to message builder:", len(integrationResults), "results")
	messages := s.buildOpenAIMessagesWithContext(ctx, settings, specificKnowledge, req.Message, req.SessionID, "", agentID.String(), integrationResults, "")

	// Call OpenAI API with optimization
	s.logger.With(ctx).Info("ðŸš€ Calling OpenAI API with model:", settings.Model)
	// Calculate system content length for optimization
	systemContentLength := 0
	if len(messages) > 0 && messages[0].Role == "system" {
		if content, ok := messages[0].Content.(string); ok {
			systemContentLength = len(content)
		}
	}
	openAIResp, err := s.callOpenAI(ctx, messages, settings, req.Message, systemContentLength, tokenTracker, "main_conversation")
	if err != nil {
		s.logger.With(ctx).Error("âŒ OpenAI API call failed:", err)
		return nil, fmt.Errorf("failed to call OpenAI: %w", err)
	}

	// Extract response
	if len(openAIResp.Choices) == 0 {
		s.logger.With(ctx).Error("âŒ No response choices from OpenAI")
		return nil, fmt.Errorf("no response from OpenAI")
	}

	aiResponse := openAIResp.Choices[0].Message.Content
	tokensUsed := openAIResp.Usage.TotalTokens
	s.logger.With(ctx).Info("âœ… OpenAI response received - Response length:", len(aiResponse), "characters, Tokens used:", tokensUsed)

	// POST-PROCESS CUSTOM INTEGRATIONS AFTER AI RESPONSE
	// This handles sequential integration execution with customer satisfaction checks
	if req.SessionID != "" {
		s.logger.With(ctx).Info("ðŸ”„ Starting post-processing custom integrations for agent:", agentID, "with AI response")
		err = s.processCustomIntegrations(ctx, tenantDB, agentID, req.Message, aiResponse, req.SessionID, "")
		if err != nil {
			s.logger.With(ctx).Error("âŒ Custom integration post-processing failed:", err)
			// Continue with response even if integration processing fails
		}
	}

	// Log credit usage with detailed information
	tenantID = token.GetTenantID(ctx)
	userID := token.GetUserID(ctx)

	// Use the actual model that was used in the request
	actualModel := openAIResp.Model
	// If the model is empty in the response, use the optimal model
	if actualModel == "" {
		// The model used is determined by selectOptimalModel in callOpenAI
		// We need to get that model based on the same logic
		systemContentLength := 0
		if len(messages) > 0 && messages[0].Role == "system" {
			if content, ok := messages[0].Content.(string); ok {
				systemContentLength = len(content)
			}
		}
		actualModel = s.selectOptimalModel(settings, req.Message, systemContentLength)
	}

	s.logger.With(ctx).Infof("ðŸ’³ Credit Usage - Tenant: %s, User: %s, Agent: %s, Model: %s, Tokens: %d, Session: %s",
		tenantID, userID, agentID, actualModel, tokensUsed, req.SessionID)

	// Track model-specific token usage (AI response credits are calculated automatically)
	if tenantID == uuid.Nil {
		s.logger.With(ctx).Error("âŒ Failed to get tenant ID for usage tracking: tenant ID is nil")
	} else {
		// Use the actual model that was used in the request instead of settings.Model
		actualModel := openAIResp.Model
		// If the model is empty in the response, fall back to the request model from callOpenAI
		if actualModel == "" {
			// The model used is determined by selectOptimalModel in callOpenAI
			// We need to get that model based on the same logic
			systemContentLength := 0
			if len(messages) > 0 && messages[0].Role == "system" {
				if content, ok := messages[0].Content.(string); ok {
					systemContentLength = len(content)
				}
			}
			actualModel = s.selectOptimalModel(settings, req.Message, systemContentLength)
		}

		// Track model-specific token usage (this automatically calculates and tracks AI response credits)
		err = s.usageTrackingService.TrackModelUsage(ctx, tenantID, actualModel, openAIResp.Usage.PromptTokens+openAIResp.Usage.CompletionTokens)
		if err != nil {
			s.logger.With(ctx).Error("âŒ Failed to track model usage:", err)
		} else {
			s.logger.With(ctx).Info("ðŸ“Š Model usage tracked successfully for tenant:", tenantID, "model:", actualModel, "tokens:", openAIResp.Usage.PromptTokens+openAIResp.Usage.CompletionTokens)
		}
	}

	// Evaluate transfer conditions if agent has transfer settings
	if req.SessionID != "" {
		// For regular chat, we don't have phone number, so pass empty string
		err = s.evaluateAndHandleTransferConditions(ctx, tenantDB, agentID, settings, req.Message, aiResponse, req.SessionID, "")
		if err != nil {
			s.logger.With(ctx).Error("âŒ Transfer condition evaluation failed:", err)
			// Continue with response even if transfer evaluation fails
		}
	}

	// Store conversation in session if session ID is provided
	if req.SessionID != "" {
		s.logger.With(ctx).Info("ðŸ’¾ Storing conversation in session:", req.SessionID)
		s.storeConversationInSession(req.SessionID, req.Message, aiResponse)
	} else {
		s.logger.With(ctx).Info("ðŸ’¾ No session ID provided - conversation not stored")
	}

	// Log final token usage summary for the entire request
	tokenSummary := tokenTracker.GetSummary()
	s.logger.With(ctx).Infof("ðŸŽ¯ REQUEST COMPLETE - Total AI Credit Used: %d tokens in %d ms", tokenSummary["total_tokens"], tokenSummary["duration_ms"])
	for _, op := range tokenSummary["operations"].([]accesslog.TokenOperation) {
		s.logger.With(ctx).Infof("  - Operation: %s, Model: %s, Input: %d, Output: %d, Total: %d", op.Operation, op.Model, op.InputTokens, op.OutputTokens, op.TotalTokens)
	}

	// Note: AI usage is already tracked by the TokenTracker in callOpenAI with 'main_conversation' operation

	// Build integration execution info for response
	var integrationExecutions []IntegrationExecutionInfo
	if integrationResults != nil {
		for integrationName, result := range integrationResults {
			resultMap, ok := result.(map[string]interface{})
			if !ok {
				continue
			}

			execInfo := IntegrationExecutionInfo{
				IntegrationName: integrationName,
			}

			if success, exists := resultMap["success"]; exists {
				if successBool, ok := success.(bool); ok {
					execInfo.Success = successBool

					if successBool {
						if responseBody, exists := resultMap["responseBody"]; exists && responseBody != nil {
							execInfo.ResponseBody = responseBody
						}
					} else {
						errorMsg := "Error Occurred"
						execInfo.ErrorMessage = &errorMsg
					}
				}
			}

			integrationExecutions = append(integrationExecutions, execInfo)
		}
	}

	// Create message bubbles
	var chatMessages []ChatMessage
	createdAt := time.Now()

	// Add AI response as message bubble
	chatMessages = append(chatMessages, ChatMessage{
		ID:        uuid.New(),
		Content:   aiResponse,
		Sender:    "ai",
		CreatedAt: createdAt,
	})

	// Use AI response as the main response
	finalResponse := aiResponse

	return &ChatResponse{
		ID:                    uuid.New(),
		AgentID:               agentID,
		SessionID:             req.SessionID,
		Message:               req.Message,
		Response:              finalResponse,
		Messages:              chatMessages,
		CreatedAt:             createdAt,
		TokensUsed:            tokensUsed,
		IntegrationExecutions: integrationExecutions,
	}, nil
}

// sendMessageInternalWithPhone handles the core message processing logic with phone number for WhatsApp
func (s *service) sendMessageInternalWithPhone(ctx context.Context, agentID uuid.UUID, sessionID, message, phoneNumber, platform string) (*ChatResponse, error) {
	// Get token tracker from context (set by accesslog middleware)
	tokenTracker := accesslog.GetTokenTrackerFromContext(ctx)
	if tokenTracker == nil {
		s.logger.With(ctx).Error("âŒ No token tracker found in context - middleware may not be properly configured")
		return nil, fmt.Errorf("token tracker not found in context")
	}
	s.logger.With(ctx).Infof("ðŸ”¢ Using token tracker from context for WhatsApp: %s", tokenTracker.RequestID)

	req := ChatRequest{
		Message:   message,
		SessionID: sessionID,
	}

	// Pre-validation: Check AI response limits
	tenantID := token.GetTenantID(ctx)
	if tenantID != uuid.Nil {
		err := s.limitCheckerService.CheckAIResponseLimit(ctx, tenantID)
		if err != nil {
			s.logger.With(ctx).Errorf("AI response limit check failed for tenant %s: %v", tenantID, err)
			return nil, fmt.Errorf("limit exceeded: %w", err)
		}
		s.logger.With(ctx).Infof("AI response limit check passed for tenant %s", tenantID)
	} else {
		s.logger.With(ctx).Info("Unable to check limits: tenant ID is nil")
	}

	// Get tenant database
	tenantDB, _, err := dbcontext.GetTenantDB(ctx, s.dbManager)
	if err != nil {
		return nil, fmt.Errorf("failed to get tenant database: %w", err)
	}

	// OPTIMIZATION: Check if lead has assigned AI agent to prevent rate limiting
	// This prioritizes the assigned AI agent over platform mapping
	assignedAgentID := s.getAssignedAIAgent(ctx, tenantDB, phoneNumber, platform)
	if assignedAgentID != uuid.Nil && assignedAgentID != agentID {
		s.logger.With(ctx).Infof("ðŸŽ¯ Using assigned AI agent %s instead of platform agent %s for phone %s", assignedAgentID, agentID, phoneNumber)
		agentID = assignedAgentID
	}

	// Get AI agent directly using the agentID (which is ai_agents.id)
	// The agentID parameter is actually an ai_agents.id, not agents.id
	agent, err := s.repo.GetAIAgentByID(ctx, tenantDB, agentID)
	if err != nil {
		return nil, fmt.Errorf("failed to get AI agent: %w", err)
	}

	s.logger.With(ctx).Infof("ðŸ¤– Processing with AI agent %s for phone %s", agentID, phoneNumber)

	// Get the corresponding agent record from agents table where agents.identifier = ai_agents.id
	var agentRecord entity.Agents
	err = tenantDB.With(ctx).Select().From("agents").Where(dbx.HashExp{"identifier": agent.ID}).One(&agentRecord)
	if err != nil {
		return nil, fmt.Errorf("failed to get agent record: %w", err)
	}

	// Get AI settings
	settings, err := s.repo.GetAISettingsByID(ctx, tenantDB, agent.IDSettings)
	if err != nil {
		return nil, fmt.Errorf("failed to get AI settings: %w", err)
	}

	// Preserve context across model switches to maintain conversation continuity
	s.preserveContextAcrossModelSwitch(ctx, sessionID, settings)

	// Use AI 3 (Knowledge Service) to retrieve relevant knowledge for WhatsApp
	s.logger.With(ctx).Info("ðŸ¤– Processing WhatsApp chat request for agent:", agentRecord.Identifier)
	s.logger.With(ctx).Info("ðŸ§  Using AI 3 knowledge service for WhatsApp message:", message[:min(50, len(message))])

	// Call AI 3 librarian service to extract specific information
	specificKnowledge, err := s.aiKnowledgeService.ExtractSpecificInformation(ctx, agentID, message)
	if err != nil {
		s.logger.With(ctx).Error("âŒ AI 3 librarian information extraction failed for WhatsApp:", err)
		// Continue without specific knowledge
		specificKnowledge = ""
	} else {
		s.logger.With(ctx).Info("âœ… AI 3 librarian information extraction completed successfully for WhatsApp")
		if specificKnowledge != "" {
			s.logger.With(ctx).Info("ðŸ“š Specific information extracted length:", len(specificKnowledge), "characters")
		} else {
			s.logger.With(ctx).Info("ðŸ“‹ No specific information extracted for this WhatsApp message")
		}
	}

	// Build lead context separately for better visibility
	leadContext := s.buildLeadKnowledgeContextWithPlatform(ctx, tenantDB, phoneNumber, platform)
	if leadContext != "" {
		s.logger.With(ctx).Info("âœ… Lead context built successfully - Length:", len(leadContext), "characters")
	} else {
		s.logger.With(ctx).Info("ðŸ“‹ No lead context available for phone number:", phoneNumber)
	}

	// PRE-PROCESS CUSTOM INTEGRATIONS BEFORE AI RESPONSE
	// This allows the AI to have access to integration results when generating its response
	s.logger.With(ctx).Info("ðŸ”„ Starting custom integration pre-processing for agent:", agentID, "message:", message)
	integrationResults, err := s.preProcessCustomIntegrations(ctx, tenantDB, agentID, message, phoneNumber, sessionID)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Custom integration pre-processing failed:", err)
		// Continue without integration results
		integrationResults = nil
	} else {
		s.logger.With(ctx).Info("âœ… Custom integration pre-processing completed. Results count:", len(integrationResults))
		if len(integrationResults) > 0 {
			s.logger.With(ctx).Info("ðŸ“Š Integration results summary:", integrationResults)
		} else {
			s.logger.With(ctx).Info("ðŸ“‹ No integration results to include in AI context")
		}
	}

	// Build OpenAI messages with conversation history and integration results if session ID is provided
	s.logger.With(ctx).Info("ðŸ”¨ Building OpenAI messages...")
	s.logger.With(ctx).Info("ðŸ”§ Integration results being passed to message builder:", len(integrationResults), "results")
	messages := s.buildOpenAIMessagesWithContext(ctx, settings, specificKnowledge, req.Message, req.SessionID, leadContext, agentID.String(), integrationResults, "")

	// Call OpenAI API with optimization
	s.logger.With(ctx).Info("ðŸš€ Calling OpenAI API with model:", settings.Model)
	// Calculate system content length for optimization
	systemContentLength := 0
	if len(messages) > 0 && messages[0].Role == "system" {
		if content, ok := messages[0].Content.(string); ok {
			systemContentLength = len(content)
		}
	}
	openAIResp, err := s.callOpenAI(ctx, messages, settings, req.Message, systemContentLength, tokenTracker, "whatsapp_conversation")
	if err != nil {
		s.logger.With(ctx).Error("âŒ OpenAI API call failed:", err)
		return nil, fmt.Errorf("failed to call OpenAI: %w", err)
	}

	// Extract response
	if len(openAIResp.Choices) == 0 {
		s.logger.With(ctx).Error("âŒ No response choices from OpenAI")
		return nil, fmt.Errorf("no response from OpenAI")
	}

	aiResponse := openAIResp.Choices[0].Message.Content
	tokensUsed := openAIResp.Usage.TotalTokens
	s.logger.With(ctx).Info("âœ… OpenAI response received - Response length:", len(aiResponse), "characters, Tokens used:", tokensUsed)
	// Validate response consistency and fix any issues
	validatedResponse, isConsistent := s.validateResponseConsistency(aiResponse, settings)
	if !isConsistent {
		s.logger.With(ctx).Error("âš ï¸ Response consistency issues detected and fixed")
		aiResponse = validatedResponse
	} else {
		s.logger.With(ctx).Info("âœ… Response passed consistency validation")
	}

	// POST-PROCESS CUSTOM INTEGRATIONS AFTER AI RESPONSE
	// This handles sequential integration execution with customer satisfaction checks
	if sessionID != "" {
		s.logger.With(ctx).Info("ðŸ”„ Starting post-processing custom integrations for WhatsApp agent:", agentID, "with AI response")
		err = s.processCustomIntegrations(ctx, tenantDB, agentID, message, aiResponse, sessionID, phoneNumber)
		if err != nil {
			s.logger.With(ctx).Error("âŒ Custom integration post-processing failed for WhatsApp:", err)
			// Continue with response even if integration processing fails
		}
	}

	// Log credit usage with detailed information
	tenantID = token.GetTenantID(ctx)
	userID := token.GetUserID(ctx)
	s.logger.With(ctx).Infof("ðŸ’³ Credit Usage - Tenant: %s, User: %s, Agent: %s, Model: %s, Tokens: %d, Phone: %s, Platform: %s, Session: %s",
		tenantID, userID, agentID, settings.Model, tokensUsed, phoneNumber, platform, sessionID)

	// Track model-specific token usage (AI response credits are calculated automatically)
	if tenantID == uuid.Nil {
		s.logger.With(ctx).Error("âŒ Failed to get tenant ID for usage tracking: tenant ID is nil")
	} else {
		// Track model-specific token usage (this automatically calculates and tracks AI response credits)
		err = s.usageTrackingService.TrackModelUsage(ctx, tenantID, settings.Model, tokensUsed)
		if err != nil {
			s.logger.With(ctx).Error("âŒ Failed to track model usage:", err)
		} else {
			s.logger.With(ctx).Info("ðŸ“Š Model usage tracked successfully for tenant:", tenantID, "model:", settings.Model, "tokens:", tokensUsed)
		}
	}

	// Store conversation in session if session ID is provided
	if req.SessionID != "" {
		s.logger.With(ctx).Info("ðŸ’¾ Storing conversation in session:", req.SessionID)
		s.storeConversationInSession(req.SessionID, req.Message, aiResponse)
	} else {
		s.logger.With(ctx).Info("ðŸ’¾ No session ID provided - conversation not stored")
	}

	// Log detailed token usage breakdown for WhatsApp request
	tokenSummary := tokenTracker.GetSummary()
	s.logger.With(ctx).Infof("ðŸŽ¯ WHATSAPP REQUEST COMPLETE - Detailed Token Breakdown:")
	if operations, ok := tokenSummary["operations"].([]accesslog.TokenOperation); ok {
		s.logger.With(ctx).Infof("ðŸ“Š Total Operations: %d", len(operations))
		for i, op := range operations {
			s.logger.With(ctx).Infof("ðŸ”¸ Operation %d: %s | Model: %s | Tokens: %d (Prompt: %d + Completion: %d)",
				i+1, op.Operation, op.Model, op.TotalTokens, op.InputTokens, op.OutputTokens)
		}
	}
	if totalTokens, ok := tokenSummary["total_tokens"].(int); ok {
		s.logger.With(ctx).Infof("ðŸŽ¯ TOTAL TOKENS USED: %d", totalTokens)
	}

	// Log comprehensive AI usage summary (this is the final authoritative log)
	s.logAIUsage(ctx, settings.Model, tokensUsed, "whatsapp", sessionID, agentID, phoneNumber, platform)

	// Build integration execution info for response
	var integrationExecutions []IntegrationExecutionInfo
	if integrationResults != nil {
		for integrationName, result := range integrationResults {
			resultMap, ok := result.(map[string]interface{})
			if !ok {
				continue
			}

			execInfo := IntegrationExecutionInfo{
				IntegrationName: integrationName,
			}

			if success, exists := resultMap["success"]; exists {
				if successBool, ok := success.(bool); ok {
					execInfo.Success = successBool

					if successBool {
						if responseBody, exists := resultMap["responseBody"]; exists && responseBody != nil {
							execInfo.ResponseBody = responseBody
						}
					} else {
						errorMsg := "Error Occurred"
						execInfo.ErrorMessage = &errorMsg
					}
				}
			}

			integrationExecutions = append(integrationExecutions, execInfo)
		}
	}

	// Create message bubbles
	var chatMessages []ChatMessage
	createdAt := time.Now()

	// Add AI response as message bubble
	chatMessages = append(chatMessages, ChatMessage{
		ID:        uuid.New(),
		Content:   aiResponse,
		Sender:    "ai",
		CreatedAt: createdAt,
	})

	// Use AI response as the response content
	responseContent := aiResponse

	return &ChatResponse{
		ID:                    uuid.New(),
		AgentID:               agentRecord.Identifier,
		SessionID:             req.SessionID,
		Message:               req.Message,
		Response:              responseContent,
		Messages:              chatMessages,
		CreatedAt:             createdAt,
		TokensUsed:            tokensUsed,
		IntegrationExecutions: integrationExecutions,
	}, nil
}

// sendMessageInternal processes a chat message without platform mapping validation (for internal use)
func (s *service) sendMessageInternal(ctx context.Context, agentID uuid.UUID, req ChatRequest) (*ChatResponse, error) {
	// Get token tracker from context (set by accesslog middleware)
	tokenTracker := accesslog.GetTokenTrackerFromContext(ctx)
	if tokenTracker == nil {
		s.logger.With(ctx).Error("âŒ No token tracker found in context - middleware may not be properly configured")
		return nil, fmt.Errorf("token tracker not found in context")
	}
	s.logger.With(ctx).Infof("ðŸ”¢ Using token tracker from context for internal request: %s", tokenTracker.RequestID)

	// Pre-validation: Check AI response limits
	tenantID := token.GetTenantID(ctx)
	if tenantID != uuid.Nil {
		err := s.limitCheckerService.CheckAIResponseLimit(ctx, tenantID)
		if err != nil {
			s.logger.With(ctx).Errorf("AI response limit check failed for tenant %s: %v", tenantID, err)
			return nil, fmt.Errorf("limit exceeded: %w", err)
		}
		s.logger.With(ctx).Infof("AI response limit check passed for tenant %s", tenantID)
	} else {
		s.logger.With(ctx).Info("Unable to check limits: tenant ID is nil")
	}

	// Get tenant database
	tenantDB, _, err := dbcontext.GetTenantDB(ctx, s.dbManager)
	if err != nil {
		return nil, fmt.Errorf("failed to get tenant database: %w", err)
	}

	// Get AI agent directly using the agentID (which is ai_agents.id)
	// The agentID parameter is actually an ai_agents.id, not agents.id
	agent, err := s.repo.GetAIAgentByID(ctx, tenantDB, agentID)
	if err != nil {
		return nil, fmt.Errorf("failed to get AI agent: %w", err)
	}

	// Get the corresponding agent record from agents table where agents.identifier = ai_agents.id
	var agentRecord entity.Agents
	err = tenantDB.With(ctx).Select().From("agents").Where(dbx.HashExp{"identifier": agent.ID}).One(&agentRecord)
	if err != nil {
		return nil, fmt.Errorf("failed to get agent record: %w", err)
	}

	// Get AI settings
	settings, err := s.repo.GetAISettingsByID(ctx, tenantDB, agent.IDSettings)
	if err != nil {
		return nil, fmt.Errorf("failed to get AI settings: %w", err)
	}

	// Preserve context across model switches to maintain conversation continuity
	s.preserveContextAcrossModelSwitch(ctx, req.SessionID, settings)

	// Load knowledge bases for AI 3 to determine relevance
	s.logger.With(ctx).Info("ðŸ¤– Processing chat request for agent:", agentRecord.Identifier)
	s.logger.With(ctx).Info("ðŸ§  Loading knowledge bases for AI 3 determination")

	var knowledgeBases []entity.Knowledge
	knowledgeBases, err = s.repo.GetKnowledgesByAgentID(ctx, tenantDB, agentRecord.Identifier)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to get knowledge bases for agent:", agentRecord.Identifier, "error:", err)
		return nil, fmt.Errorf("failed to get knowledge bases: %w", err)
	}

	if len(knowledgeBases) == 0 {
		s.logger.With(ctx).Info("âš ï¸ No knowledge bases found for agent:", agentID)
	} else {
		s.logger.With(ctx).Info("âœ… Found", len(knowledgeBases), "knowledge bases for agent")
		for i, kb := range knowledgeBases {
			s.logger.With(ctx).Info(fmt.Sprintf("ðŸ“š Knowledge base %d: %s (ID: %s)", i+1, kb.Name, kb.ID))
		}
	}

	// Build context from all knowledge bases (internal function still uses old approach)
	knowledgeContext := ""
	if len(knowledgeBases) > 0 {
		s.logger.With(ctx).Info("ðŸ”§ Starting knowledge context building for", len(knowledgeBases), "knowledge bases...")
		knowledgeContext, err = s.buildKnowledgeContextFromMultiple(ctx, tenantDB, knowledgeBases, req.SessionID)
		if err != nil {
			s.logger.With(ctx).Error("âŒ Failed to build knowledge context:", err)
			// Continue without knowledge context
		} else {
			s.logger.With(ctx).Info("âœ… Knowledge context building completed successfully")
		}
	} else {
		s.logger.With(ctx).Info("â­ï¸ Skipping knowledge context building - no knowledge bases available")
	}

	// PRE-PROCESS CUSTOM INTEGRATIONS BEFORE AI RESPONSE
	// This allows the AI to have access to integration results when generating its response
	s.logger.With(ctx).Info("ðŸ”„ Starting custom integration pre-processing for agent:", agentID, "message:", req.Message)
	integrationResults, err := s.preProcessCustomIntegrations(ctx, tenantDB, agentID, req.Message, "", req.SessionID)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Custom integration pre-processing failed:", err)
		// Continue without integration results
		integrationResults = nil
	} else {
		s.logger.With(ctx).Info("âœ… Custom integration pre-processing completed. Results count:", len(integrationResults))
		if len(integrationResults) > 0 {
			s.logger.With(ctx).Info("ðŸ“Š Integration results summary:", integrationResults)
		} else {
			s.logger.With(ctx).Info("ðŸ“‹ No integration results to include in AI context")
		}
	}

	// Build OpenAI messages with conversation history and integration results if session ID is provided
	s.logger.With(ctx).Info("ðŸ”¨ Building OpenAI messages...")
	s.logger.With(ctx).Info("ðŸ”§ Integration results being passed to message builder:", len(integrationResults), "results")
	messages := s.buildOpenAIMessagesWithContext(ctx, settings, knowledgeContext, req.Message, req.SessionID, "", agentID.String(), integrationResults, "")

	// Call OpenAI API with optimization
	s.logger.With(ctx).Info("ðŸš€ Calling OpenAI API with model:", settings.Model)
	// Calculate system content length for optimization
	systemContentLength := 0
	if len(messages) > 0 && messages[0].Role == "system" {
		if content, ok := messages[0].Content.(string); ok {
			systemContentLength = len(content)
		}
	}
	openAIResp, err := s.callOpenAI(ctx, messages, settings, req.Message, systemContentLength, tokenTracker, "internal_conversation")
	if err != nil {
		s.logger.With(ctx).Error("âŒ OpenAI API call failed:", err)
		return nil, fmt.Errorf("failed to call OpenAI: %w", err)
	}

	// Extract response
	if len(openAIResp.Choices) == 0 {
		s.logger.With(ctx).Error("âŒ No response choices from OpenAI")
		return nil, fmt.Errorf("no response from OpenAI")
	}

	aiResponse := openAIResp.Choices[0].Message.Content
	tokensUsed := openAIResp.Usage.TotalTokens
	s.logger.With(ctx).Info("âœ… OpenAI response received - Response length:", len(aiResponse), "characters, Tokens used:", tokensUsed)

	// Custom integrations were already processed before AI response generation
	// No need to process them again here

	// Log credit usage with detailed information
	userID := token.GetUserID(ctx)
	s.logger.With(ctx).Infof("ðŸ’³ Credit Usage - Tenant: %s, User: %s, Agent: %s, Model: %s, Tokens: %d, Session: %s",
		tenantID, userID, agentID, settings.Model, tokensUsed, req.SessionID)

	// Track model-specific token usage (AI response credits are calculated automatically)
	if tenantID == uuid.Nil {
		s.logger.With(ctx).Error("âŒ Failed to get tenant ID for usage tracking: tenant ID is nil")
	} else {
		// Track model-specific token usage (this automatically calculates and tracks AI response credits)
		err = s.usageTrackingService.TrackModelUsage(ctx, tenantID, settings.Model, tokensUsed)
		if err != nil {
			s.logger.With(ctx).Error("âŒ Failed to track model usage:", err)
		} else {
			s.logger.With(ctx).Info("ðŸ“Š Model usage tracked successfully for tenant:", tenantID, "model:", settings.Model, "tokens:", tokensUsed)
		}
	}

	// Store conversation in session if session ID is provided
	if req.SessionID != "" {
		s.logger.With(ctx).Info("ðŸ’¾ Storing conversation in session:", req.SessionID)
		s.storeConversationInSession(req.SessionID, req.Message, aiResponse)
	} else {
		s.logger.With(ctx).Info("ðŸ’¾ No session ID provided - conversation not stored")
	}

	// Log detailed token usage breakdown for internal request
	tokenSummary := tokenTracker.GetSummary()
	s.logger.With(ctx).Infof("ðŸŽ¯ INTERNAL REQUEST COMPLETE - Detailed Token Breakdown:")
	if operations, ok := tokenSummary["operations"].([]accesslog.TokenOperation); ok {
		s.logger.With(ctx).Infof("ðŸ“Š Total Operations: %d", len(operations))
		for i, op := range operations {
			s.logger.With(ctx).Infof("ðŸ”¸ Operation %d: %s | Model: %s | Tokens: %d (Prompt: %d + Completion: %d)",
				i+1, op.Operation, op.Model, op.TotalTokens, op.InputTokens, op.OutputTokens)
		}
	}
	if totalTokens, ok := tokenSummary["total_tokens"].(int); ok {
		s.logger.With(ctx).Infof("ðŸŽ¯ TOTAL TOKENS USED: %d", totalTokens)
	}

	// Log comprehensive AI usage summary (this is the final authoritative log)
	s.logAIUsage(ctx, settings.Model, tokensUsed, "internal", req.SessionID, agentID, "", "internal")

	// Build integration execution info for response
	var integrationExecutions []IntegrationExecutionInfo
	if integrationResults != nil {
		for integrationName, result := range integrationResults {
			resultMap, ok := result.(map[string]interface{})
			if !ok {
				continue
			}

			execInfo := IntegrationExecutionInfo{
				IntegrationName: integrationName,
			}

			if success, exists := resultMap["success"]; exists {
				if successBool, ok := success.(bool); ok {
					execInfo.Success = successBool

					if successBool {
						if responseBody, exists := resultMap["responseBody"]; exists && responseBody != nil {
							execInfo.ResponseBody = responseBody
						}
					} else {
						errorMsg := "Error Occurred"
						execInfo.ErrorMessage = &errorMsg
					}
				}
			}

			integrationExecutions = append(integrationExecutions, execInfo)
		}
	}

	// Create message bubbles
	createdAt := time.Now()
	var chatMessages []ChatMessage

	// Add AI response as message bubble
	chatMessages = append(chatMessages, ChatMessage{
		ID:        uuid.New(),
		Content:   aiResponse,
		Sender:    "ai",
		CreatedAt: createdAt,
	})

	// Use AI response as the response content
	finalResponse := aiResponse

	return &ChatResponse{
		ID:                    uuid.New(),
		AgentID:               agentRecord.Identifier,
		SessionID:             req.SessionID,
		Message:               req.Message,
		Response:              finalResponse,
		Messages:              chatMessages,
		CreatedAt:             createdAt,
		TokensUsed:            tokensUsed,
		IntegrationExecutions: integrationExecutions,
	}, nil
}

// getAssignedAIAgent checks if a lead has an assigned AI agent to prevent rate limiting
// Returns the assigned AI agent ID if found, otherwise returns uuid.Nil
func (s *service) getAssignedAIAgent(ctx context.Context, db *dbcontext.DB, phoneNumber, platform string) uuid.UUID {
	// Try to find contact by phone number
	contact, err := s.contactService.GetContactByIdentifier(ctx, phoneNumber)
	if err != nil {
		s.logger.With(ctx).Info("ðŸ“‹ No contact found for phone number:", phoneNumber)
		return uuid.Nil
	}

	// Try to get lead by contact ID (both assigned and unassigned)
	lead, err := s.leadService.GetLeadByIDContact(ctx, contact.ID)
	if err != nil {
		s.logger.With(ctx).Info("ðŸ“‹ No lead found for contact:", contact.ID)
		return uuid.Nil
	}

	// Check if lead is assigned to an AI agent
	if lead.AssignTo == nil {
		s.logger.With(ctx).Info("ðŸ“‹ Lead is unassigned, no specific AI agent")
		return uuid.Nil
	}

	// Verify the assigned agent is an AI agent
	var agentRecord entity.Agents
	err = db.With(ctx).Select().From("agents").Where(dbx.HashExp{"id": *lead.AssignTo, "agent_type": "AI"}).One(&agentRecord)
	if err != nil {
		s.logger.With(ctx).Info("ðŸ“‹ Assigned agent is not an AI agent or not found:", *lead.AssignTo)
		return uuid.Nil
	}

	// Return the AI agent identifier (which corresponds to ai_agents.id)
	s.logger.With(ctx).Infof("âœ… Found assigned AI agent %s for lead %s", agentRecord.Identifier, lead.ID)
	return agentRecord.Identifier
}

// buildLeadContext builds context string from lead information based on session ID (phone number)
// buildLeadKnowledgeContext builds lead information as knowledge context
// This integrates lead information directly into the knowledge base context
func (s *service) buildLeadKnowledgeContext(ctx context.Context, db *dbcontext.DB, identifier string) string {
	// For WhatsApp conversations, identifier should be the phone number
	// Try to find contact and lead information
	s.logger.With(ctx).Info("ðŸ” Looking up contact with identifier:", identifier)
	contact, err := s.contactService.GetContactByIdentifier(ctx, identifier)
	if err != nil {
		s.logger.With(ctx).Info("ðŸ“‹ No contact found for identifier:", identifier, "Error:", err)
		return ""
	}

	s.logger.With(ctx).Info("âœ… Found contact:", contact.ID, "PushName:", contact.PushName, "ContactIdentifier:", contact.ContactIdentifier)

	// Try to get unassigned lead information for this contact (only unresolved leads)
	s.logger.With(ctx).Info("ðŸ” Looking up unassigned lead for contact ID:", contact.ID)
	lead, err := s.leadService.GetUnassignedLeadByIDContact(ctx, contact.ID)
	if err != nil {
		s.logger.With(ctx).Info("ðŸ“‹ No unassigned lead found for contact:", contact.ID, "Error:", err)
		return ""
	}

	s.logger.With(ctx).Info("âœ… Found lead:", lead.ID, "Name:", lead.Name, "Status:", lead.Status, "Notes length:", len(lead.Notes))

	// Build lead context string
	var contextParts []string

	// Note: Customer name is intentionally excluded from lead context
	// The AI should only learn the customer's name when explicitly provided in conversation

	// Add contact information
	if contact.PushName != "" {
		contextParts = append(contextParts, fmt.Sprintf("Contact Display Name: %s", contact.PushName))
	}

	// Add potential value if available
	if lead.PotentialValue > 0 {
		contextParts = append(contextParts, fmt.Sprintf("Potential Value: $%.2f", lead.PotentialValue))
	}

	// Add notes if available - this is the key information for remembering previous conversations
	if lead.Notes != "" {
		contextParts = append(contextParts, fmt.Sprintf("Previous Conversation Notes: %s", lead.Notes))
	}

	// Add lead status and stage information if available
	if lead.Status != "" {
		contextParts = append(contextParts, fmt.Sprintf("Lead Status: %s", lead.Status))
	}

	if len(contextParts) == 0 {
		s.logger.With(ctx).Info("ðŸ“‹ No relevant lead information found")
		return ""
	}

	leadContext := strings.Join(contextParts, "\n")
	s.logger.With(ctx).Info("ðŸ“‹ Built lead knowledge context with", len(contextParts), "pieces of information")
	return leadContext
}

// buildLeadKnowledgeContextWithPlatform builds lead information as knowledge context with platform filtering
func (s *service) buildLeadKnowledgeContextWithPlatform(ctx context.Context, db *dbcontext.DB, identifier string, platform string) string {
	// For WhatsApp conversations, identifier should be the phone number
	// Try to find contact and lead information
	s.logger.With(ctx).Info("ðŸ” Looking up contact with identifier:", identifier, "platform:", platform)
	contact, err := s.contactService.GetContactByIdentifier(ctx, identifier)
	if err != nil {
		s.logger.With(ctx).Info("ðŸ“‹ No contact found for identifier:", identifier, "Error:", err)
		return ""
	}

	// Check if platform matches (if platform is provided)
	if platform != "" && contact.IDPlatform != platform {
		s.logger.With(ctx).Info("âš ï¸ Contact platform mismatch - Expected:", platform, "Found:", contact.IDPlatform, "for identifier:", identifier)
		// Still proceed but log the mismatch for debugging
	}

	s.logger.With(ctx).Info("âœ… Found contact:", contact.ID, "PushName:", contact.PushName, "ContactIdentifier:", contact.ContactIdentifier, "Platform:", contact.IDPlatform)

	// Try to get unassigned lead information for this contact (only unresolved leads)
	s.logger.With(ctx).Info("ðŸ” Looking up unassigned lead for contact ID:", contact.ID)
	lead, err := s.leadService.GetUnassignedLeadByIDContact(ctx, contact.ID)
	if err != nil {
		s.logger.With(ctx).Info("ðŸ“‹ No unassigned lead found for contact:", contact.ID, "Error:", err)
		return ""
	}

	s.logger.With(ctx).Info("âœ… Found lead:", lead.ID, "Name:", lead.Name, "Status:", lead.Status, "Notes length:", len(lead.Notes))

	// Build lead context string
	var contextParts []string

	// Add lead name if available
	if lead.Name != "" {
		contextParts = append(contextParts, fmt.Sprintf("Customer Name: %s", lead.Name))
	}

	// Add contact information
	if contact.PushName != "" {
		contextParts = append(contextParts, fmt.Sprintf("Contact Display Name: %s", contact.PushName))
	}

	// Add platform information for context
	if contact.IDPlatform != "" {
		contextParts = append(contextParts, fmt.Sprintf("Platform: %s", contact.IDPlatform))
	}

	// Add potential value if available
	if lead.PotentialValue > 0 {
		contextParts = append(contextParts, fmt.Sprintf("Potential Value: $%.2f", lead.PotentialValue))
	}

	// Add notes if available - this is the key information for remembering previous conversations
	if lead.Notes != "" {
		contextParts = append(contextParts, fmt.Sprintf("Previous Conversation Notes: %s", lead.Notes))
	}

	// Add lead status and stage information if available
	if lead.Status != "" {
		contextParts = append(contextParts, fmt.Sprintf("Lead Status: %s", lead.Status))
	}

	if len(contextParts) == 0 {
		s.logger.With(ctx).Info("ðŸ“‹ No relevant lead information found")
		return ""
	}

	leadContext := strings.Join(contextParts, "\n")
	s.logger.With(ctx).Info("ðŸ“‹ Built lead knowledge context with", len(contextParts), "pieces of information")
	return leadContext
}

// buildKnowledgeContextFromMultiple builds context string from multiple knowledge bases
func (s *service) buildKnowledgeContextFromMultiple(ctx context.Context, db *dbcontext.DB, knowledgeBases []entity.Knowledge, sessionID string) (string, error) {
	return s.buildKnowledgeContextFromMultipleWithPhone(ctx, db, knowledgeBases, sessionID, "")
}

// buildKnowledgeContextFromMultipleWithPhone builds context string from multiple knowledge bases with optional phone number
func (s *service) buildKnowledgeContextFromMultipleWithPhone(ctx context.Context, db *dbcontext.DB, knowledgeBases []entity.Knowledge, sessionID string, phoneNumber string) (string, error) {
	return s.buildKnowledgeContextFromMultipleWithPhoneAndPlatform(ctx, db, knowledgeBases, sessionID, phoneNumber, "")
}

// buildKnowledgeContextFromMultipleWithPhoneAndPlatform builds context string from multiple knowledge bases with optional phone number and platform
func (s *service) buildKnowledgeContextFromMultipleWithPhoneAndPlatform(ctx context.Context, db *dbcontext.DB, knowledgeBases []entity.Knowledge, sessionID string, phoneNumber string, platform string) (string, error) {
	var allContextParts []string

	// Note: Lead information is now handled separately in sendMessageInternalWithPhone
	// to avoid duplication and provide better control over context structure

	for i, knowledge := range knowledgeBases {
		s.logger.With(ctx).Info(fmt.Sprintf("ðŸ” Processing knowledge base %d/%d: %s (ID: %s)", i+1, len(knowledgeBases), knowledge.Name, knowledge.ID))

		contextPart, err := s.buildKnowledgeContext(ctx, db, &knowledge)
		if err != nil {
			s.logger.With(ctx).Error("âŒ Failed to build context for knowledge base:", knowledge.Name, "error:", err)
			continue
		}

		if contextPart != "" {
			// Add knowledge base name as header
			headerContext := fmt.Sprintf("=== %s ===\n%s", knowledge.Name, contextPart)
			allContextParts = append(allContextParts, headerContext)
			s.logger.With(ctx).Info("âœ… Successfully processed knowledge base:", knowledge.Name, "- Context length:", len(contextPart), "characters")
		}
	}

	finalContext := strings.Join(allContextParts, "\n\n")
	s.logger.With(ctx).Info("ðŸŽ¯ All knowledge bases processed - Total knowledge bases:", len(allContextParts), "Total context length:", len(finalContext), "characters")
	return finalContext, nil
}

// buildKnowledgeContext builds context string from knowledge sources
func (s *service) buildKnowledgeContext(ctx context.Context, db *dbcontext.DB, knowledge *entity.Knowledge) (string, error) {
	s.logger.With(ctx).Info("ðŸ” Building knowledge context for knowledge ID:", knowledge.ID)

	// Get knowledge sources
	sources, err := s.repo.GetKnowledgeSourcesByKnowledgeID(ctx, db, knowledge.ID)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to get knowledge sources:", err)
		return "", err
	}

	s.logger.With(ctx).Info("ðŸ“š Found", len(sources), "knowledge sources")
	var contextParts []string

	for i, source := range sources {
		s.logger.With(ctx).Info(fmt.Sprintf("ðŸ“– Processing source %d/%d - Type: %s, ID: %s", i+1, len(sources), source.SourceType, source.SourceID))

		switch source.SourceType {
		case entity.SourceTypeText:
			text, err := s.repo.GetKnowledgeTextByID(ctx, db, source.SourceID)
			if err != nil {
				s.logger.With(ctx).Error("âŒ Failed to get text content for source:", source.SourceID, "error:", err)
				continue
			}
			s.logger.With(ctx).Info("âœ… Successfully loaded text content, length:", len(text.Content), "characters")
			contextParts = append(contextParts, text.Content)

		case entity.SourceTypeWebsite:
			website, err := s.repo.GetKnowledgeWebsiteByID(ctx, db, source.SourceID)
			if err != nil {
				s.logger.With(ctx).Error("âŒ Failed to get website content for source:", source.SourceID, "error:", err)
				continue
			}
			s.logger.With(ctx).Info("âœ… Successfully loaded website content, HTML length:", len(website.HTML), "characters")

			// Add the main website HTML content
			contextParts = append(contextParts, website.HTML)

			// Get and add content from scraped pages
			scrapedPages, err := s.repo.GetScrapedPagesByWebsiteID(ctx, db, website.ID)
			if err != nil {
				s.logger.With(ctx).Error("âŒ Failed to get scraped pages for website:", website.ID, "error:", err)
			} else {
				s.logger.With(ctx).Info("ðŸ“„ Found", len(scrapedPages), "scraped pages for website", website.ID)
				for _, page := range scrapedPages {
					if page.HTML != "" {
						s.logger.With(ctx).Info("âœ… Adding scraped page content from URL:", page.URL, "HTML length:", len(page.HTML), "characters")
						contextParts = append(contextParts, fmt.Sprintf("Content from page %s:\n%s", page.URL, page.HTML))
					}
				}
			}

		case entity.SourceTypeFile:
			file, err := s.repo.GetKnowledgeFileByID(ctx, db, source.SourceID)
			if err != nil {
				s.logger.With(ctx).Error("âŒ Failed to get file content for source:", source.SourceID, "error:", err)
				continue
			}
			s.logger.With(ctx).Info("âœ… Successfully loaded file content, extracted text length:", len(file.ExtractedText), "characters")
			contextParts = append(contextParts, file.ExtractedText)

		case entity.SourceTypeQA:
			qa, err := s.repo.GetKnowledgeQAByID(ctx, db, source.SourceID)
			if err != nil {
				s.logger.With(ctx).Error("âŒ Failed to get QA content for source:", source.SourceID, "error:", err)
				continue
			}
			s.logger.With(ctx).Info("âœ… Successfully loaded QA content - Question:", qa.Question[:min(50, len(qa.Question))], "...")
			contextParts = append(contextParts, fmt.Sprintf("Q: %s\nA: %s", qa.Question, qa.Answer))

		case entity.SourceTypeProduct:
			s.logger.With(ctx).Info("ðŸ›ï¸ Processing product source, creating product service...")
			// Create product repository and service
			productRepo := product.NewRepository(db)
			productService := product.NewService(productRepo, s.dbManager, s.logger)

			// Get product with category information
			productContent, err := productService.GetProductByID(ctx, source.SourceID)
			if err != nil {
				s.logger.With(ctx).Error("âŒ Failed to get product content for source:", source.SourceID, "error:", err)
				continue
			}

			s.logger.With(ctx).Info("âœ… Successfully loaded product:", productContent.Name, "- Category:", productContent.CategoryName)

			// Format product information for context with clear boundaries
			var description, stock string
			if productContent.Description != nil {
				description = *productContent.Description
			}
			if productContent.Stock != nil {
				stock = *productContent.Stock
			}
			var price float64
			if productContent.Price != nil {
				price = *productContent.Price
			}

			productInfo := fmt.Sprintf("=== PRODUCT START ===\nProduct: %s\nSKU/Code: %s\nCategory: %s\nDescription: %s\nPrice: %.2f\nStock: %s",
				productContent.Name,
				productContent.SKU,
				productContent.CategoryName,
				description,
				price,
				stock)

			// Add image URL with explicit availability status
			if productContent.ImageURL != nil && *productContent.ImageURL != "" {
				productInfo += fmt.Sprintf("\nImage: %s", *productContent.ImageURL)
			} else {
				productInfo += "\nImage: No image available for this product"
			}

			// Add attributes if available
			if len(productContent.Attributes) > 0 {
				productInfo += "\nAttributes:\n"
				for _, attr := range productContent.Attributes {
					productInfo += fmt.Sprintf("- %s: %s\n", attr.AttributeName, attr.Value)
				}
			}

			// Close product boundary
			productInfo += "\n=== PRODUCT END ==="

			s.logger.With(ctx).Info("ðŸ“ Product context formatted, total length:", len(productInfo), "characters")
			contextParts = append(contextParts, productInfo)

		default:
			s.logger.With(ctx).Error("âš ï¸ Unknown source type:", source.SourceType, "for source:", source.SourceID)
		}
	}

	finalContext := strings.Join(contextParts, "\n\n")
	s.logger.With(ctx).Info("ðŸŽ¯ Knowledge context built successfully - Total parts:", len(contextParts), "Total length:", len(finalContext), "characters")
	return finalContext, nil
}

// min helper function
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

func max(a, b int) int {
	if a > b {
		return a
	}
	return b
}

// buildOptimizedSystemContent creates an optimized system message based on message complexity
func (s *service) buildOptimizedSystemContent(ctx context.Context, settings *entity.AISettings, specificKnowledge string, userMessage string, leadContext string, agentID string) string {
	return s.buildOptimizedSystemContentWithIntegrations(ctx, settings, specificKnowledge, userMessage, leadContext, agentID, nil)
}

// buildOptimizedSystemContentWithIntegrations creates an optimized system message with integration results
// Now uses session-based behavior caching to dramatically reduce token usage
func (s *service) buildOptimizedSystemContentWithIntegrations(ctx context.Context, settings *entity.AISettings, specificKnowledge string, userMessage string, leadContext string, agentID string, integrationResults map[string]interface{}) string {
	// Analyze message complexity to determine optimization level
	complexity := s.analyzeMessageComplexity(userMessage)
	s.logger.Info("ðŸ§  Message complexity analysis:", complexity)

	// Extract session ID from context for session-based caching
	sessionID := ""
	if sessionValue := ctx.Value("sessionID"); sessionValue != nil {
		if sessionStr, ok := sessionValue.(string); ok {
			sessionID = sessionStr
		}
	}

	// Extract and preserve key conversation elements before building system content
	if sessionID != "" {
		s.extractAndPreserveKeyConversationElements(sessionID)
	}

	// Parse agent ID for session caching
	var agentUUID uuid.UUID
	var err error
	if agentID != "" {
		agentUUID, err = uuid.Parse(agentID)
		if err != nil {
			s.logger.With(ctx).Error("âŒ Failed to parse agent ID for session caching:", agentID, "Error:", err)
		}
	}

	// Start with streamlined behavior content - keep it simple and focused
	var systemContent string

	// Essential consistency rules (minimal)
	systemContent = "CORE RULES: Stay in character as human sales rep. Never break character. Convert technical data to natural responses. Follow behavior flow exactly.\n\n"

	// Add integration results (minimal processing)
	if len(integrationResults) > 0 {
		systemContent += "INTEGRATION DATA: Use as facts while staying in character.\n"

		// Safely process integration results to avoid JSON marshaling errors
		safeIntegrationResults := make(map[string]interface{})
		for name, result := range integrationResults {
			if resultMap, ok := result.(map[string]interface{}); ok {
				safeResult := make(map[string]interface{})
				for key, value := range resultMap {
					if key == "responseBody" && value != nil {
						// Safely handle response body that might contain invalid JSON
						if responseStr, ok := value.(*string); ok && responseStr != nil {
							// Validate and sanitize the response body
							if json.Valid([]byte(*responseStr)) {
								safeResult[key] = *responseStr
							} else {
								// If response body is not valid JSON, treat it as plain text
								safeResult[key] = *responseStr
								s.logger.With(ctx).Error("âš ï¸ Integration response body is not valid JSON, treating as plain text:", name)
							}
						} else if responseStr, ok := value.(string); ok {
							// Handle direct string values
							safeResult[key] = responseStr
						} else {
							safeResult[key] = value
						}
					} else {
						safeResult[key] = value
					}
				}
				safeIntegrationResults[name] = safeResult
			} else {
				safeIntegrationResults[name] = result
			}
		}

		// Marshal the safe integration results
		integrationResultsJSON, err := json.MarshalIndent(safeIntegrationResults, "", "  ")
		if err != nil {
			s.logger.With(ctx).Error("âŒ Failed to marshal safe integration results to JSON:", err)
			// Fallback: provide a simple text description
			for name, result := range safeIntegrationResults {
				if resultMap, ok := result.(map[string]interface{}); ok {
					if success, exists := resultMap["success"]; exists {
						systemContent += fmt.Sprintf("Integration '%s': Success=%v\n", name, success)
						if responseBody, exists := resultMap["responseBody"]; exists && responseBody != nil {
							systemContent += fmt.Sprintf("Response: %v\n", responseBody)
						}
					}
				}
			}
		} else {
			systemContent += string(integrationResultsJSON)
		}

		// Add contextual interpretation of integration results
		for name, result := range integrationResults {
			if name == "check_covered_area" {
				if resultMap, ok := result.(map[string]interface{}); ok {
					if success, exists := resultMap["success"]; exists && success == true {
						systemContent += "\n\nðŸŸ¢ COVERAGE CONFIRMATION: The area is covered by our service.\n"
						systemContent += "STATUS: Coverage confirmed for service area.\n"
						systemContent += "POSITIVE APPROACH: Acknowledge coverage and continue with your structured service inquiry process.\n"
						systemContent += "STATUS: Ready for next interaction.\n"
					}
				}
			}
		}

		systemContent += "\n\n=== END INTEGRATION RESULTS ===\n\n"
		s.logger.With(ctx).Info("ðŸ”§ System content started with integration results (HIGHEST PRIORITY) - Integration count:", len(integrationResults))
	}

	// Add behavior as secondary context
	var behaviorContent string
	// Use session-based behavior caching for MASSIVE token savings
	if sessionID != "" && err == nil {
		behaviorContent = s.getSessionBehaviorCache(ctx, sessionID, agentUUID, settings.Behaviour, complexity)
		s.logger.With(ctx).Info("ðŸš€ Using session-cached behavior - MASSIVE TOKEN SAVINGS! Length:", len(behaviorContent), "characters")
	} else {
		// Fallback to regular behavior compression
		behaviorContent = s.compressBehaviorPrompt(settings.Behaviour, complexity)
		s.logger.Info("ðŸ“‹ Using regular behavior compression (no session) - Length:", len(behaviorContent), "characters")
	}

	// Add behavior instructions (main content)
	systemContent += "\n" + behaviorContent

	// Add minimal transfer condition if needed
	if settings.TransferCondition != "" {
		systemContent += "\nTRANSFER: " + settings.TransferCondition + "\n"
	}

	// Skip integration trigger conditions to reduce token usage
	// Integration triggers are handled by AI 2, not needed in AI 1 system content

	// Add specific knowledge if available
	if specificKnowledge != "" {
		systemContent += "\n\nKnowledge: " + specificKnowledge
		s.logger.With(ctx).Info("ðŸ“š Added specific knowledge, length:", len(specificKnowledge), "characters")
	}

	// Add minimal lead context if available
	if leadContext != "" {
		systemContent += "\nLead: " + leadContext
	}

	// Add minimal date context
	currentTime := time.Now()
	systemContent += fmt.Sprintf("\nToday: %s", currentTime.Format("2006-01-02"))

	s.logger.Info("ðŸŽ¯ Optimized system content built - Total length:", len(systemContent), "characters")
	return systemContent
}

// analyzeMessageComplexity determines the complexity level of a user message
func (s *service) analyzeMessageComplexity(message string) string {
	messageLower := strings.ToLower(message)

	// Product listing requests - always high complexity due to large response requirements
	productListingKeywords := []string{
		"all products", "semua produk", "all items", "semua item",
		"list all", "show all", "tampilkan semua", "daftar semua",
		"complete catalog", "katalog lengkap", "full catalog",
		"entire collection", "koleksi lengkap", "all available",
		"what products", "produk apa saja", "ada produk apa",
	}

	// Check for product listing requests first
	for _, keyword := range productListingKeywords {
		if strings.Contains(messageLower, keyword) {
			return "high"
		}
	}

	// High complexity indicators
	highComplexityKeywords := []string{
		"compare", "difference", "vs", "versus", "which is better", "recommend", "suggestion",
		"calculate", "price", "cost", "shipping", "delivery", "payment", "order", "buy",
		"specification", "feature", "detail", "technical", "how to", "tutorial",
		"problem", "issue", "error", "not working", "help", "support",
		"image", "photo", "picture", "attachment",
	}

	// Medium complexity indicators
	mediumComplexityKeywords := []string{
		"product", "item", "available", "stock", "catalog", "list",
		"information", "info", "about", "tell me", "what is",
		"contact", "phone", "email", "address", "location",
	}

	// Check for high complexity
	for _, keyword := range highComplexityKeywords {
		if strings.Contains(messageLower, keyword) {
			return "high"
		}
	}

	// Check for medium complexity
	for _, keyword := range mediumComplexityKeywords {
		if strings.Contains(messageLower, keyword) {
			return "medium"
		}
	}

	// OPTIMIZED: More conservative complexity classification to reduce token usage
	// Increased threshold for medium complexity
	if len(message) > 150 { // Increased from 100 to 150
		return "medium"
	}

	return "low"
}

// compressBehaviorPrompt now returns the full behavior without compression, using cache for performance
// This prevents loading and processing behaviors for every single message
func (s *service) compressBehaviorPrompt(behavior string, complexity string) string {
	// For backward compatibility, still support the old caching mechanism
	// but prioritize session-based caching when available
	cacheKey := s.generateBehaviorCacheKey(behavior)

	// Try to get from cache first
	if cachedEntry, ok := s.getBehaviorFromCache(cacheKey); ok {
		// Update access statistics
		cachedEntry.LastAccessed = time.Now()
		cachedEntry.AccessCount++
		s.behaviorCache.Store(cacheKey, cachedEntry)

		// Always return the original behavior (no compression)
		s.logger.Info("ðŸ“‹ Using cached full behavior (no compression)")
		return cachedEntry.OriginalBehavior
	}

	// Cache miss - generate and cache (but all versions are now the same - full behavior)
	s.logger.Info("ðŸ“‹ Behavior cache miss - caching full behavior")
	cacheEntry := &BehaviorCacheEntry{
		OriginalBehavior: behavior,
		UltraCompressed:  behavior, // No compression
		Compressed:       behavior, // No compression
		Optimized:        behavior, // No compression
		CachedAt:         time.Now(),
		LastAccessed:     time.Now(),
		AccessCount:      1,
	}

	// Store in cache
	s.behaviorCache.Store(cacheKey, cacheEntry)
	s.logger.Info("ðŸ“‹ Full behavior cached successfully with key:", cacheKey[:8]+"...")

	// Always return the original behavior
	return behavior
}

// getSessionBehaviorCache retrieves or creates cached behavior for a specific session/agent combination
// Now returns full behavior without compression while maintaining caching benefits
func (s *service) getSessionBehaviorCache(ctx context.Context, sessionID string, agentID uuid.UUID, behavior string, complexity string) string {
	if sessionID == "" {
		// Fallback to regular behavior handling for requests without session
		s.logger.With(ctx).Info("âš ï¸ No session ID provided, using regular behavior handling")
		return s.compressBehaviorPrompt(behavior, complexity)
	}

	// Create session cache key
	sessionCacheKey := fmt.Sprintf("%s_%s", sessionID, agentID.String())

	// Try to get from session cache first
	if cachedEntry, ok := s.getSessionBehaviorFromCache(sessionCacheKey, behavior); ok {
		// Update access statistics
		cachedEntry.LastAccessed = time.Now()
		cachedEntry.AccessCount++
		s.sessionBehaviorCache.Store(sessionCacheKey, cachedEntry)

		// Always return the original behavior (no compression)
		s.logger.With(ctx).Info("ðŸš€ Using session-cached full behavior (no compression) - CACHING BENEFITS!")
		return cachedEntry.OriginalBehavior
	}

	// Session cache miss - generate and cache for this session
	s.logger.With(ctx).Info("ðŸ’¾ Session behavior cache miss - caching full behavior for session:", sessionID, "agent:", agentID)
	behaviorHash := s.generateBehaviorHash(behavior)
	sessionCacheEntry := &SessionBehaviorCache{
		AgentID:          agentID,
		BehaviorHash:     behaviorHash,
		UltraCompressed:  behavior, // No compression
		Compressed:       behavior, // No compression
		Optimized:        behavior, // No compression
		OriginalBehavior: behavior,
		CachedAt:         time.Now(),
		LastAccessed:     time.Now(),
		AccessCount:      1,
	}

	// Store in session cache
	s.sessionBehaviorCache.Store(sessionCacheKey, sessionCacheEntry)
	s.logger.With(ctx).Info("âœ… Session behavior cached successfully for session:", sessionID, "agent:", agentID)

	// Always return the original behavior
	return behavior
}

// getSessionBehaviorFromCache retrieves session behavior from cache with validation
func (s *service) getSessionBehaviorFromCache(sessionCacheKey string, currentBehavior string) (*SessionBehaviorCache, bool) {
	if value, ok := s.sessionBehaviorCache.Load(sessionCacheKey); ok {
		if entry, ok := value.(*SessionBehaviorCache); ok {
			// Check if cache entry is still valid (24 hours) and behavior hasn't changed
			currentHash := s.generateBehaviorHash(currentBehavior)
			if time.Since(entry.CachedAt) < 24*time.Hour && entry.BehaviorHash == currentHash {
				return entry, true
			}
			// Cache expired or behavior changed, remove it
			s.sessionBehaviorCache.Delete(sessionCacheKey)
		}
	}
	return nil, false
}

// generateBehaviorHash creates a hash for behavior validation
func (s *service) generateBehaviorHash(behavior string) string {
	// Create a simple hash of the behavior content for validation
	hash := 0
	for _, char := range behavior {
		hash = hash*31 + int(char)
	}
	return fmt.Sprintf("%d_%d", hash, len(behavior))
}

// generateBehaviorCacheKey creates a cache key from behavior content
func (s *service) generateBehaviorCacheKey(behavior string) string {
	// Create a simple hash of the behavior content
	// Using a basic hash to avoid importing crypto packages
	hash := 0
	for _, char := range behavior {
		hash = hash*31 + int(char)
	}
	return fmt.Sprintf("behavior_%d_%d", hash, len(behavior))
}

// getBehaviorFromCache retrieves behavior from cache
func (s *service) getBehaviorFromCache(cacheKey string) (*BehaviorCacheEntry, bool) {
	if value, ok := s.behaviorCache.Load(cacheKey); ok {
		if entry, ok := value.(*BehaviorCacheEntry); ok {
			// Check if cache entry is still valid (24 hours)
			if time.Since(entry.CachedAt) < 24*time.Hour {
				return entry, true
			}
			// Cache expired, remove it
			s.behaviorCache.Delete(cacheKey)
		}
	}
	return nil, false
}

// generateUltraCompressedBehavior now returns the full original behavior (no compression)
func (s *service) generateUltraCompressedBehavior(originalBehavior string) string {
	// NO COMPRESSION: Always return the full original behavior to preserve sequential flow
	return originalBehavior
}

// generateCompressedBehavior now returns the full original behavior (no compression)
func (s *service) generateCompressedBehavior(originalBehavior string) string {
	// NO COMPRESSION: Always return the full original behavior to preserve sequential flow
	return originalBehavior
}

// generateOptimizedBehavior now returns the full original behavior (no compression)
func (s *service) generateOptimizedBehavior(originalBehavior string) string {
	// NO COMPRESSION: Always return the full original behavior to preserve sequential flow
	return originalBehavior
}

// cleanupBehaviorCache removes old and unused cache entries
func (s *service) cleanupBehaviorCache() {
	cutoffTime := time.Now().Add(-24 * time.Hour)
	var keysToDelete []string

	s.behaviorCache.Range(func(key, value interface{}) bool {
		if entry, ok := value.(*BehaviorCacheEntry); ok {
			// Remove entries older than 24 hours or not accessed in last 6 hours
			if entry.CachedAt.Before(cutoffTime) || entry.LastAccessed.Before(time.Now().Add(-6*time.Hour)) {
				keysToDelete = append(keysToDelete, key.(string))
			}
		}
		return true
	})

	for _, key := range keysToDelete {
		s.behaviorCache.Delete(key)
	}

	if len(keysToDelete) > 0 {
		s.logger.Info("ðŸ§¹ Cleaned up", len(keysToDelete), "expired behavior cache entries")
	}
}

// preserveContextAcrossModelSwitch ensures context continuity when switching between models
// This method maintains session state and behavior consistency regardless of model changes
func (s *service) preserveContextAcrossModelSwitch(ctx context.Context, sessionID string, settings *entity.AISettings) {
	if sessionID == "" {
		return
	}

	// Ensure behavior is cached for consistent context
	cacheKey := s.generateBehaviorCacheKey(settings.Behaviour)
	if _, exists := s.behaviorCache.Load(cacheKey); !exists {
		// Pre-cache behavior to ensure consistency across model switches
		s.compressBehaviorPrompt(settings.Behaviour, "medium")
		s.logger.With(ctx).Info("ðŸ”„ Pre-cached behavior for context preservation", "session_id", sessionID)
	}

	// Update session metadata to track model switches
	if history, exists := s.sessions.Load(sessionID); exists {
		if historyMessages, ok := history.([]OpenAIMessage); ok {
			// Add a system message to maintain context awareness across model switches
			contextMessage := OpenAIMessage{
				Role:    "system",
				Content: "[Context preserved across model optimization - maintaining conversation continuity]",
			}

			// Only add if not already present in recent messages
			recentMessages := len(historyMessages)
			if recentMessages == 0 || historyMessages[recentMessages-1].Content != contextMessage.Content {
				updatedHistory := append(historyMessages, contextMessage)
				s.sessions.Store(sessionID, updatedHistory)
				s.logger.With(ctx).Info("ðŸ”— Behavior consistency reminder added", "session_id", sessionID)
			}
		}
	}
}

// validateResponseConsistency ensures the AI response maintains persona and doesn't contain raw technical data
func (s *service) validateResponseConsistency(response string, settings *entity.AISettings) (string, bool) {
	// Check for raw JSON patterns
	jsonPatterns := []string{
		`{"`, `[{`, `":"`, `},`, `]}`, `"result"`, `"data"`, `"status"`,
		`"error"`, `"message"`, `"response"`, `"success"`, `"failure"`,
	}

	responseLower := strings.ToLower(response)
	for _, pattern := range jsonPatterns {
		if strings.Contains(response, pattern) {
			s.logger.Error("ðŸš¨ Raw JSON detected in response, needs processing")
			return s.processRawDataResponse(response, settings), false
		}
	}

	// Check for technical/system language
	technicalPatterns := []string{
		"system", "error", "failed", "api", "database", "server",
		"function", "method", "parameter", "variable", "null", "undefined",
		"exception", "stack trace", "debug", "log", "console",
	}

	for _, pattern := range technicalPatterns {
		if strings.Contains(responseLower, pattern) {
			s.logger.Error("ðŸš¨ Technical language detected in response")
			// Don't auto-fix technical language, just flag it
			return response, false
		}
	}

	// Check for AI self-identification
	aiPatterns := []string{
		"i am an ai", "i'm an ai", "as an ai", "i am a bot", "i'm a bot",
		"i am artificial", "i'm artificial", "i am a system", "i'm a system",
		"i am automated", "i'm automated", "as a chatbot", "i am a chatbot",
	}

	for _, pattern := range aiPatterns {
		if strings.Contains(responseLower, pattern) {
			s.logger.Error("ðŸš¨ AI self-identification detected in response")
			return s.fixAIIdentification(response), false
		}
	}

	return response, true
}

// processRawDataResponse converts raw JSON/technical data into natural language
func (s *service) processRawDataResponse(rawResponse string, settings *entity.AISettings) string {
	// Return the raw response as-is to let the AI handle it naturally
	// This prevents hardcoded waiting messages that cause double confirmations
	return rawResponse
}

// fixAIIdentification removes AI self-identification and maintains sales persona
func (s *service) fixAIIdentification(response string) string {
	// Replace AI identification with sales persona
	replacePatterns := map[string]string{
		"I am an AI":      "Saya adalah sales assistant",
		"I'm an AI":       "Saya adalah sales assistant",
		"as an AI":        "sebagai sales assistant",
		"I am a bot":      "Saya adalah sales assistant",
		"I'm a bot":       "Saya adalah sales assistant",
		"I am artificial": "Saya adalah sales assistant",
		"I'm artificial":  "Saya adalah sales assistant",
		"I am a system":   "Saya adalah sales assistant",
		"I'm a system":    "Saya adalah sales assistant",
		"I am automated":  "Saya adalah sales assistant",
		"I'm automated":   "Saya adalah sales assistant",
		"as a chatbot":    "sebagai sales assistant",
		"I am a chatbot":  "Saya adalah sales assistant",
	}

	fixedResponse := response
	for pattern, replacement := range replacePatterns {
		fixedResponse = strings.ReplaceAll(fixedResponse, pattern, replacement)
		fixedResponse = strings.ReplaceAll(fixedResponse, strings.ToLower(pattern), strings.ToLower(replacement))
	}

	return fixedResponse
}

// reinforceBehaviorConsistency adds behavior reinforcement for long conversations
func (s *service) reinforceBehaviorConsistency(messages []OpenAIMessage, settings *entity.AISettings) []OpenAIMessage {
	// Count non-system messages to determine conversation length
	conversationLength := 0
	for _, msg := range messages {
		if msg.Role != "system" {
			conversationLength++
		}
	}

	// Only add behavior reinforcement every 10 messages (instead of loading behavior every message)
	if conversationLength > 0 && conversationLength%10 == 0 {
		reinforcement := OpenAIMessage{
			Role:    "system",
			Content: "CRITICAL CONSISTENCY REMINDER: You are a human sales representative. Maintain your sales persona, process all data naturally in conversational language, never output raw JSON or technical information, never break character, and follow the established sales process exactly. Continue the conversation naturally while adhering to all critical consistency rules.",
		}

		// Insert before the last user message
		if len(messages) > 0 {
			messages = append(messages[:len(messages)-1], reinforcement, messages[len(messages)-1])
		} else {
			messages = append(messages, reinforcement)
		}
	}

	return messages
}

// reinforceIntegrationPriority adds integration priority reinforcement for conversations with integration results
func (s *service) reinforceIntegrationPriority(messages []OpenAIMessage, integrationResults map[string]interface{}) []OpenAIMessage {
	if len(integrationResults) == 0 {
		return messages
	}

	// Add integration processing guidance before the last user message
	integrationReinforcement := OpenAIMessage{
		Role: "system",
		Content: "ðŸ”´ INTEGRATION PROCESSING REMINDER:\n" +
			"- Process integration results as factual data while maintaining your sales persona\n" +
			"- If integration shows area coverage, acknowledge naturally: 'Great news! We do service your area.'\n" +
			"- Integration results provide facts to support your conversation flow\n" +
			"- ALWAYS maintain critical consistency rules: stay in character as human sales rep\n" +
			"- Integration results provide context for natural conversation\n" +
			"- Convert all technical data into conversational responses matching your persona",
	}

	// Insert before the last user message
	if len(messages) > 0 {
		messages = append(messages[:len(messages)-1], integrationReinforcement, messages[len(messages)-1])
	} else {
		messages = append(messages, integrationReinforcement)
	}

	return messages
}

// Note: optimizeKnowledgeContext function has been removed as we now include the entire knowledge context without chunking
// This improves the AI's ability to access and utilize the complete knowledge base

// isDirectProductQuery checks if the message is directly asking about products
func (s *service) isDirectProductQuery(message string) bool {
	msgLower := strings.ToLower(message)
	directQueries := []string{
		"produk", "product", "harga", "price", "stok", "stock",
		"katalog", "catalog", "daftar", "list", "tersedia", "available",
		"ukuran", "size", "warna", "color", "model", "type",
	}

	for _, query := range directQueries {
		if strings.Contains(msgLower, query) {
			return true
		}
	}
	return false
}

// isKnowledgeRelevant checks if the message requires knowledge base information
func (s *service) isKnowledgeRelevant(message string) bool {
	messageLower := strings.ToLower(message)
	relevantKeywords := []string{
		// Product related keywords
		"product", "price", "cost", "available", "stock", "catalog", "list",
		"information", "info", "about", "detail", "specification", "feature",
		"what is", "tell me", "how much", "do you have", "can you",
		"compare", "difference", "recommend", "suggest",

		// Contact and service related keywords
		"contact", "kontak", "hubungi", "telepon", "telephone", "phone", "call",
		"email", "alamat", "address", "location", "lokasi", "where", "dimana",
		"service", "layanan", "jasa", "help", "bantuan", "support", "dukungan",

		// General inquiry keywords
		"how to", "cara", "bagaimana", "when", "kapan", "who", "siapa",
		"why", "mengapa", "kenapa", "what", "apa", "which", "mana",

		// Specific service names that might be in knowledge base
		"benerin", "repair", "fix", "perbaiki",
	}

	for _, keyword := range relevantKeywords {
		if strings.Contains(messageLower, keyword) {
			return true
		}
	}

	// Check for question marks as they usually indicate a knowledge-relevant query
	if strings.Contains(message, "?") {
		return true
	}

	// Default to true for messages longer than 15 characters to ensure most queries get knowledge context
	if len(strings.TrimSpace(message)) > 15 {
		return true
	}

	return false
}

// Note: The following functions have been removed as we now include the entire knowledge context without chunking:
// - extractRelevantKnowledgeChunks
// - splitKnowledgeIntoChunks
// - scoreKnowledgeChunks
// - selectTopChunks
//
// This change improves the AI's ability to access and utilize the complete knowledge base without
// losing important context through chunking. The entire knowledge context is now passed directly
// to the AI model, allowing it to perform its own relevance determination.

// isShippingRelated checks if the message is related to shipping
func (s *service) isShippingRelated(message string) bool {
	messageLower := strings.ToLower(message)
	shippingKeywords := []string{
		"shipping", "delivery", "courier", "ongkir", "kirim", "antar",
		"ekspedisi", "jne", "tiki", "pos", "sicepat", "anteraja",
		"cost", "biaya", "tarif", "calculate", "hitung",
	}

	for _, keyword := range shippingKeywords {
		if strings.Contains(messageLower, keyword) {
			return true
		}
	}
	return false
}

// applyHistoryLimit limits conversation history based on settings
func (s *service) applyHistoryLimit(history []OpenAIMessage, limit int) []OpenAIMessage {
	if limit <= 0 || len(history) <= limit {
		return history
	}

	// Keep the most recent messages within the limit
	// Always keep pairs (user + assistant) together
	startIndex := len(history) - limit
	if startIndex < 0 {
		startIndex = 0
	}

	// Ensure we start with a user message if possible
	for startIndex < len(history) && history[startIndex].Role != "user" {
		startIndex++
	}

	return history[startIndex:]
}

// buildControlledRajaOngkirContext creates a controlled RajaOngkir context for shipping queries

// selectOptimalModel chooses the best model based on message complexity and context size
func (s *service) selectOptimalModel(settings *entity.AISettings, userMessage string, systemContentLength int) string {
	// Analyze message complexity
	complexity := s.analyzeMessageComplexity(userMessage)

	// Check if message contains images (requires vision model)
	if strings.Contains(userMessage, "Image URL:") || strings.Contains(userMessage, "image") {
		// For vision tasks, use gpt-4o-mini or gpt-4o for vision capabilities
		if systemContentLength > 3000 {
			s.logger.Info("ðŸ¤– Selected GPT-4.1-nano for vision task with large context")
			return "gpt-4.1-mini"
		}
		s.logger.Info("ðŸ¤– Selected GPT-4.1-nano for vision task")
		return "gpt-4.1-mini"
	}

	// Use GPT-4.1 models based on complexity
	switch complexity {
	case "low":
		// Use gpt-4.1-nano for low complexity messages
		s.logger.Info("ðŸ¤– Selected GPT-4.1-nano for low complexity")
		return "gpt-4.1-nano"

	case "medium":
		// Use gpt-4.1-mini for medium complexity messages
		s.logger.Info("ðŸ¤– Selected GPT-4.1-mini for medium complexity")
		return "gpt-4.1-mini"

	case "high":
		// Use gpt-4.1-mini for high complexity messages
		s.logger.Info("ðŸ¤– Selected GPT-4.1-mini for high complexity")
		return "gpt-4.1-mini"

	default:
		// Default to gpt-4.1-nano for unknown complexity
		s.logger.Info("ðŸ¤– Using GPT-4.1-nano as default")
		return "gpt-4.1-nano"
	}
}

// buildOpenAIMessages builds the message array for OpenAI API with token optimization
func (s *service) buildOpenAIMessages(ctx context.Context, settings *entity.AISettings, specificKnowledge string, userMessage string, sessionID string, leadContext string, agentID string) []OpenAIMessage {
	return s.buildOpenAIMessagesWithContext(ctx, settings, specificKnowledge, userMessage, sessionID, leadContext, agentID, nil, "")
}

// buildOpenAIMessagesWithContext creates OpenAI messages with support for integration results and image analysis
// This function combines the functionality of the previous buildOpenAIMessagesWithIntegrationResults and buildOpenAIMessagesWithImageAnalysis functions
func (s *service) buildOpenAIMessagesWithContext(ctx context.Context, settings *entity.AISettings, specificKnowledge string, userMessage string, sessionID string, leadContext string, agentID string, integrationResults map[string]interface{}, imageAnalysis string) []OpenAIMessage {
	s.logger.With(ctx).Info("ðŸ”§ buildOpenAIMessagesWithContext called with", len(integrationResults), "integration results and image analysis:", imageAnalysis != "")

	// Get enhanced session context for field state and integration tracking
	var fieldStateContext, integrationStateContext string
	if sessionID != "" {
		fieldStateContext = s.buildFieldStateContext(sessionID)
		integrationStateContext = s.buildIntegrationStateContext(sessionID)
		s.logger.With(ctx).Info("ðŸ” Enhanced session context loaded for session:", sessionID)
	}

	// Build system content based on whether we have integration results or not
	var systemContent string
	if len(integrationResults) > 0 {
		// Build system content WITH integration results included directly
		systemContent = s.buildOptimizedSystemContentWithIntegrations(ctx, settings, specificKnowledge, userMessage, leadContext, agentID, integrationResults)
	} else {
		// Build standard optimized system content
		systemContent = s.buildOptimizedSystemContent(ctx, settings, specificKnowledge, userMessage, leadContext, agentID)
	}

	// Add enhanced session context to system content
	if fieldStateContext != "" || integrationStateContext != "" {
		systemContent += "\n\n=== ENHANCED SESSION CONTEXT ===\n"
		if fieldStateContext != "" {
			systemContent += fieldStateContext
		}
		if integrationStateContext != "" {
			systemContent += integrationStateContext
		}
		systemContent += "\n\nIMPORTANT: Use the above field state and integration context to:\n"
		systemContent += "- Avoid asking for information already collected\n"
		systemContent += "- Reference previously provided data when relevant\n"
		systemContent += "- Maintain conversation continuity and context awareness\n"
		systemContent += "- Integration status available in context\n"
	}

	// Handle image analysis context
	var hasImageAnalysis bool = false
	var imageAnalysisContext string

	// Check for direct image analysis parameter
	if imageAnalysis != "" {
		// Use direct image analysis as context
		imageAnalysisContext = imageAnalysis
		hasImageAnalysis = true
		s.logger.With(ctx).Info("ðŸ“¸ Using direct image analysis as context")
	} else if sessionID != "" {
		// Try to retrieve stored image analysis result for this session
		if storedResult, exists := s.imageAnalysisResults.Load(sessionID); exists {
			if analysisResult, ok := storedResult.(*ImageAnalysisResult); ok {
				// Check if the analysis result is still valid (not expired)
				if time.Since(analysisResult.Timestamp) <= analysisResult.TTL {
					// Use stored image analysis as context
					imageAnalysisContext = analysisResult.Analysis
					hasImageAnalysis = true
					s.logger.With(ctx).Info("ðŸ“¸ Using stored image analysis as context for session", "session_id", sessionID, "age", time.Since(analysisResult.Timestamp))
				} else {
					// Remove expired analysis result
					s.imageAnalysisResults.Delete(sessionID)
					s.logger.With(ctx).Info("ðŸ—‘ï¸ Removed expired image analysis for session", "session_id", sessionID)
				}
			}
		}
	}

	// Add image analysis context if available
	if hasImageAnalysis {
		systemContent += "\n\nðŸ” IMAGE ANALYSIS CONTEXT:\nThe user has previously shared an image. Here is the detailed analysis of that image:\n\n" + imageAnalysisContext + "\n\nPlease use this image analysis to inform your response to the user's current question. Reference specific details from the image analysis when relevant."
	}

	// Add bank transfer slip detection instructions if analyzing images in payment context
	if sessionID != "" && strings.Contains(userMessage, "Image URL:") && strings.Contains(userMessage, "bank transfer slip") {
		systemContent += "\n\nBANK TRANSFER SLIP DETECTION INSTRUCTIONS:\n"
		systemContent += "You are analyzing an image that might be a bank transfer slip (bukti pembayaran). Please:\n"
		systemContent += "1. Carefully examine the image to determine if it's a valid bank transfer receipt\n"
		systemContent += "2. Look for key elements: bank name, transfer amount, date/time, reference number, recipient details\n"
		systemContent += "3. If it's a valid transfer slip, confirm the payment and proceed to the next stage\n"
		systemContent += "4. If it's not a transfer slip or invalid, politely ask for a proper payment proof\n"
		systemContent += "5. Be thorough but friendly in your analysis and response\n"
		systemContent += "6. If the transfer is confirmed, thank the customer and inform them about next steps\n"
	}

	// Create system message
	messages := []OpenAIMessage{
		{
			Role:    "system",
			Content: systemContent,
		},
	}

	// Add conversation history if session ID is provided
	if sessionID != "" {
		if history, exists := s.sessions.Load(sessionID); exists {
			if historyMessages, ok := history.([]OpenAIMessage); ok {
				if len(integrationResults) > 0 {
					// For integration results, use limited history to avoid token overflow
					maxHistory := 10
					startIdx := len(historyMessages) - maxHistory
					if startIdx < 0 {
						startIdx = 0
					}
					messages = append(messages, historyMessages[startIdx:]...)
					s.logger.With(ctx).Info("ðŸ’­ Found session history for", sessionID, ":", len(historyMessages), "messages, limited to:", len(historyMessages[startIdx:]), "messages for integration context")
				} else {
					// For image analysis, apply history limit from settings
					limitedHistory := s.applyHistoryLimit(historyMessages, settings.HistoryLimit)
					messages = append(messages, limitedHistory...)
					s.logger.With(ctx).Info("ðŸ’­ Found session history for", sessionID, ":", len(historyMessages), "messages, limited to:", len(limitedHistory), "messages for image analysis context")
				}
			}
		} else {
			s.logger.With(ctx).Info("ðŸ’­ No session history found for", sessionID)
		}
	} else {
		s.logger.With(ctx).Info("ðŸ’­ No session ID provided - starting fresh conversation")
	}

	// Add current user message
	messages = append(messages, OpenAIMessage{
		Role:    "user",
		Content: userMessage,
	})

	// Apply behavior reinforcement for long conversations (from integration results function)
	if len(integrationResults) > 0 {
		messages = s.reinforceBehaviorConsistency(messages, settings)
		// Add integration priority reinforcement to ensure integration results override chat history
		messages = s.reinforceIntegrationPriority(messages, integrationResults)
	}

	s.logger.With(ctx).Info("ðŸ“¤ Final message array prepared with", len(messages), "messages for OpenAI API")
	return messages
}

// buildVisionMessage creates a vision-enabled message for image analysis
func (s *service) buildVisionMessage(text string, imageURL string, detail string) OpenAIMessage {
	if detail == "" {
		detail = "high" // Use high detail for payment slip analysis
	}

	content := []OpenAIContent{
		{
			Type: "text",
			Text: text,
		},
		{
			Type: "image_url",
			ImageURL: &OpenAIImageURL{
				URL:    imageURL,
				Detail: detail,
			},
		},
	}

	return OpenAIMessage{
		Role:    "user",
		Content: content,
	}
}

// callOpenAI makes a request to OpenAI API with retry logic and rate limiting
func (s *service) callOpenAI(ctx context.Context, messages []OpenAIMessage, settings *entity.AISettings, userMessage string, systemContentLength int, tokenTracker *accesslog.TokenTracker, operation string) (*OpenAIResponse, error) {
	// Select optimal model based on message complexity and context size
	// For transfer evaluation, use the specified model directly without optimization
	var optimalModel string
	if operation == "transfer_evaluation" {
		optimalModel = settings.Model
	} else {
		optimalModel = s.selectOptimalModel(settings, userMessage, systemContentLength)
	}

	// OPTIMIZED: Aggressive token limits to achieve max 5000 tokens per request
	// Reduced all limits significantly while maintaining functionality
	var maxTokens int
	switch operation {
	case "transfer_evaluation":
		maxTokens = 300 // Reduced from 500 - minimal evaluation needed
	case "trigger_evaluation_preprocess":
		maxTokens = 3000 // Reduced from 2000 - focus on essential analysis only
	case "image_analysis":
		maxTokens = 9000 // Keep high for image analysis (excluded from 5000 limit)
	default:
		complexity := s.analyzeMessageComplexity(userMessage)
		maxTokens = 600 // Reduced from 1000 - ultra-conservative default
		switch complexity {
		case "low":
			maxTokens = 7000 // Reduced from 3000 - concise responses
		case "medium":
			maxTokens = 12000 // Reduced from 5000 - focused responses
		case "high":
			maxTokens = 15000 // Reduced from 7000 - essential info only
		}
	}

	request := OpenAIRequest{
		Model:       optimalModel,
		Messages:    messages,
		MaxTokens:   maxTokens,
		Temperature: 0,
		TopP:        1.0,
		Stream:      false,
	}

	// Log optimization details
	s.logger.With(ctx).Infof("ðŸŽ¯ Token Optimization - Original Model: %s, Selected Model: %s, System Content: %d chars, Messages: %d",
		settings.Model, optimalModel, systemContentLength, len(messages))

	// Add RajaOngkir tools if enabled
	if settings.RajaOngkirEnabled {
		s.logger.With(ctx).Info("ðŸšš RajaOngkir enabled - adding function tools")
		request.Tools = s.buildRajaOngkirTools()
		request.ToolChoice = "auto"
	}

	jsonData, err := json.Marshal(request)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal request: %w", err)
	}

	// Retry configuration
	maxRetries := 3
	baseDelay := 1 * time.Second
	maxDelay := 60 * time.Second

	for attempt := 0; attempt <= maxRetries; attempt++ {
		// Create new request for each attempt
		req, err := http.NewRequestWithContext(ctx, "POST", "https://api.openai.com/v1/chat/completions", bytes.NewBuffer(jsonData))
		if err != nil {
			return nil, fmt.Errorf("failed to create request: %w", err)
		}

		req.Header.Set("Content-Type", "application/json")
		req.Header.Set("Authorization", "Bearer "+s.openAIKey)

		client := &http.Client{Timeout: 30 * time.Second}
		resp, err := client.Do(req)
		if err != nil {
			if attempt == maxRetries {
				return nil, fmt.Errorf("failed to make request after %d attempts: %w", maxRetries+1, err)
			}
			s.logger.With(ctx).Infof("ðŸ”„ OpenAI request failed (attempt %d/%d): %v", attempt+1, maxRetries+1, err)
			continue
		}

		body, err := io.ReadAll(resp.Body)
		resp.Body.Close()
		if err != nil {
			if attempt == maxRetries {
				return nil, fmt.Errorf("failed to read response after %d attempts: %w", maxRetries+1, err)
			}
			s.logger.With(ctx).Infof("ðŸ”„ Failed to read OpenAI response (attempt %d/%d): %v", attempt+1, maxRetries+1, err)
			continue
		}

		// Handle successful response
		if resp.StatusCode == http.StatusOK {
			var openAIResp OpenAIResponse
			if err := json.Unmarshal(body, &openAIResp); err != nil {
				return nil, fmt.Errorf("failed to unmarshal response: %w", err)
			}

			// Log token usage for monitoring
			s.logger.With(ctx).Infof("ðŸ”¢ Token Usage - Model: %s, Prompt: %d, Completion: %d, Total: %d",
				request.Model,
				openAIResp.Usage.PromptTokens,
				openAIResp.Usage.CompletionTokens,
				openAIResp.Usage.TotalTokens)

			// Track tokens in the request tracker if provided
			if tokenTracker != nil {
				tokenTracker.AddOperation(
					operation,
					request.Model,
					openAIResp.Usage.PromptTokens,
					openAIResp.Usage.CompletionTokens,
					openAIResp.Usage.TotalTokens,
				)
			}

			// NOTE: usageTrackingService.TrackModelUsage is called in the main SendMessage functions
			// to avoid double tracking. This callOpenAI function only handles token tracker operations.

			// Handle function calls if present
			if len(openAIResp.Choices) > 0 && len(openAIResp.Choices[0].Message.ToolCalls) > 0 {
				s.logger.With(ctx).Infof("ðŸ”§ Processing %d function calls", len(openAIResp.Choices[0].Message.ToolCalls))

				// Process function calls and get updated response
				updatedResp, err := s.handleFunctionCalls(ctx, &openAIResp, messages, settings)
				if err != nil {
					s.logger.With(ctx).Errorf("âŒ Function call handling failed: %v", err)
					// Return original response if function handling fails
				} else {
					openAIResp = *updatedResp
				}
			}

			if attempt > 0 {
				s.logger.With(ctx).Infof("âœ… OpenAI request succeeded on attempt %d/%d", attempt+1, maxRetries+1)
			}
			return &openAIResp, nil
		}

		// Handle rate limiting (429) and server errors (5xx)
		if resp.StatusCode == 429 || (resp.StatusCode >= 500 && resp.StatusCode < 600) {
			if attempt == maxRetries {
				return nil, fmt.Errorf("OpenAI API error after %d attempts: %s - %s", maxRetries+1, resp.Status, string(body))
			}

			// Calculate exponential backoff delay
			delay := time.Duration(float64(baseDelay) * math.Pow(2, float64(attempt)))
			if delay > maxDelay {
				delay = maxDelay
			}

			// Add jitter to prevent thundering herd
			jitter := time.Duration(mathrand.Float64() * float64(delay) * 0.1)
			delay += jitter

			s.logger.With(ctx).Infof("â³ OpenAI rate limited/server error (attempt %d/%d): %s. Retrying in %v", attempt+1, maxRetries+1, resp.Status, delay)

			// Wait before retrying
			select {
			case <-ctx.Done():
				return nil, ctx.Err()
			case <-time.After(delay):
				continue
			}
		}

		// Handle other client errors (4xx) - don't retry
		return nil, fmt.Errorf("OpenAI API client error: %s - %s", resp.Status, string(body))
	}

	return nil, fmt.Errorf("unexpected error: exceeded retry loop")
}

// buildControlledRajaOngkirContext creates a controlled context for RajaOngkir that guides AI through simplified process
func (s *service) buildControlledRajaOngkirContext(settings *entity.AISettings) string {
	// Ultra-compressed RajaOngkir context to save tokens
	context := "SHIPPING: Use calculate_shipping_cost function when customer asks ongkir.\n"
	context += "Need: Province, City, District. Default weight: 1000g.\n"

	if settings.RajaOngkirCouriers != "" {
		context += "Couriers: " + settings.RajaOngkirCouriers + "\n"
	}

	return context
}

// buildRajaOngkirTools creates the function definitions for RajaOngkir API calls
func (s *service) buildRajaOngkirTools() []OpenAITool {
	return []OpenAITool{
		{
			Type: "function",
			Function: OpenAIFunction{
				Name:        "calculate_shipping_cost",
				Description: "Calculate shipping cost to customer's location. When customer asks about shipping cost, use this function directly. If you don't have their complete address (province, city, district), ask for it first, then call this function with the location details. The function will handle finding the correct district ID and calculating the cost.",
				Parameters: map[string]interface{}{
					"type": "object",
					"properties": map[string]interface{}{
						"province": map[string]interface{}{
							"type":        "string",
							"description": "Customer's province name (e.g., 'Jawa Barat', 'DKI Jakarta')",
						},
						"city": map[string]interface{}{
							"type":        "string",
							"description": "Customer's city name (e.g., 'Bandung', 'Jakarta Selatan')",
						},
						"district": map[string]interface{}{
							"type":        "string",
							"description": "Customer's district/kecamatan name (e.g., 'Coblong', 'Kebayoran Baru')",
						},
						"weight": map[string]interface{}{
							"type":        "integer",
							"description": "Weight in grams (default: 1000)",
							"default":     1000,
						},
					},
					"required": []string{"province", "city", "district"},
				},
			},
		},
	}
}

// executeRajaOngkirFunction executes a RajaOngkir function call and returns the result
func (s *service) executeRajaOngkirFunction(ctx context.Context, settings *entity.AISettings, functionName string, arguments map[string]interface{}) (string, error) {
	s.logger.With(ctx).Infof("ðŸšš Executing RajaOngkir function: %s with arguments: %+v", functionName, arguments)

	switch functionName {
	case "calculate_shipping_cost":
		return s.executeCalculateShippingCost(ctx, settings, arguments)
	default:
		return "", fmt.Errorf("unknown function: %s", functionName)
	}
}

// executeCalculateShippingCost calculates shipping cost to destination using location names
func (s *service) executeCalculateShippingCost(ctx context.Context, settings *entity.AISettings, arguments map[string]interface{}) (string, error) {
	// Extract location parameters
	provinceName, ok := arguments["province"].(string)
	if !ok {
		return "", fmt.Errorf("province is required and must be a string")
	}
	cityName, ok := arguments["city"].(string)
	if !ok {
		return "", fmt.Errorf("city is required and must be a string")
	}
	districtName, ok := arguments["district"].(string)
	if !ok {
		return "", fmt.Errorf("district is required and must be a string")
	}

	// Get weight, default to 1000 grams
	weight := 1000
	if w, exists := arguments["weight"]; exists {
		if weightFloat, ok := w.(float64); ok {
			weight = int(weightFloat)
		} else if weightInt, ok := w.(int); ok {
			weight = weightInt
		}
	}

	s.logger.With(ctx).Infof("ðŸšš Starting shipping cost calculation for: %s, %s, %s (weight: %d grams)", provinceName, cityName, districtName, weight)

	// Step 1: Find province ID
	s.logger.With(ctx).Info("ðŸ“ Step 1: Finding province ID")
	provinces, err := s.rajaOngkirService.GetProvinces()
	if err != nil {
		s.logger.With(ctx).Errorf("âŒ Failed to get provinces: %v", err)
		return "", fmt.Errorf("failed to get provinces: %w", err)
	}

	var provinceID string
	for _, province := range provinces.Data {
		if strings.EqualFold(strings.TrimSpace(province.Name), strings.TrimSpace(provinceName)) {
			provinceID = fmt.Sprintf("%d", province.ID)
			break
		}
	}
	if provinceID == "" {
		s.logger.With(ctx).Errorf("âŒ Province '%s' not found", provinceName)
		return "", fmt.Errorf("province '%s' not found. Please check the spelling", provinceName)
	}
	s.logger.With(ctx).Infof("âœ… Found province ID: %s for '%s'", provinceID, provinceName)

	// Step 2: Find city ID
	s.logger.With(ctx).Info("ðŸ™ï¸ Step 2: Finding city ID")
	cities, err := s.rajaOngkirService.GetCities(provinceID)
	if err != nil {
		s.logger.With(ctx).Errorf("âŒ Failed to get cities for province %s: %v", provinceID, err)
		return "", fmt.Errorf("failed to get cities: %w", err)
	}

	var cityID string
	for _, city := range cities.Data {
		// Check both "Type Name" and just "Name" formats
		fullCityName := fmt.Sprintf("%s %s", city.Type, city.Name)
		if strings.EqualFold(strings.TrimSpace(fullCityName), strings.TrimSpace(cityName)) ||
			strings.EqualFold(strings.TrimSpace(city.Name), strings.TrimSpace(cityName)) {
			cityID = fmt.Sprintf("%d", city.ID)
			break
		}
	}
	if cityID == "" {
		s.logger.With(ctx).Errorf("âŒ City '%s' not found in province '%s'", cityName, provinceName)
		return "", fmt.Errorf("city '%s' not found in province '%s'. Please check the spelling", cityName, provinceName)
	}
	s.logger.With(ctx).Infof("âœ… Found city ID: %s for '%s'", cityID, cityName)

	// Step 3: Find district ID
	s.logger.With(ctx).Info("ðŸ˜ï¸ Step 3: Finding district ID")
	districts, err := s.rajaOngkirService.GetDistricts(cityID)
	if err != nil {
		s.logger.With(ctx).Errorf("âŒ Failed to get districts for city %s: %v", cityID, err)
		return "", fmt.Errorf("failed to get districts: %w", err)
	}

	var districtID string
	for _, district := range districts.Data {
		if strings.EqualFold(strings.TrimSpace(district.Name), strings.TrimSpace(districtName)) {
			districtID = fmt.Sprintf("%d", district.ID)
			break
		}
	}
	if districtID == "" {
		s.logger.With(ctx).Errorf("âŒ District '%s' not found in city '%s'", districtName, cityName)
		return "", fmt.Errorf("district '%s' not found in city '%s'. Please check the spelling", districtName, cityName)
	}
	s.logger.With(ctx).Infof("âœ… Found district ID: %s for '%s'", districtID, districtName)

	// Step 4: Calculate shipping cost
	s.logger.With(ctx).Infof("ðŸ’° Step 4: Calculating shipping cost to district ID: %s, weight: %d grams", districtID, weight)
	s.logger.With(ctx).Infof("ðŸ“¦ Request body will be: origin=%s&destination=%s&weight=%d&courier=%s", settings.RajaOngkirOriginDistrict, districtID, weight, settings.RajaOngkirCouriers)

	results, err := s.rajaOngkirService.CalculateShippingCost(settings, districtID, weight)
	if err != nil {
		s.logger.With(ctx).Errorf("âŒ Failed to calculate shipping cost: %v", err)
		return "", fmt.Errorf("failed to calculate shipping cost: %w", err)
	}

	s.logger.With(ctx).Infof("âœ… Retrieved %d shipping options for %s, %s, %s", len(results), provinceName, cityName, districtName)

	// Format results for AI
	return s.rajaOngkirService.FormatShippingCostForAI(results), nil
}

// handleFunctionCalls processes function calls from OpenAI and returns updated response
func (s *service) handleFunctionCalls(ctx context.Context, initialResp *OpenAIResponse, originalMessages []OpenAIMessage, settings *entity.AISettings) (*OpenAIResponse, error) {
	// Create a new message list with the original messages plus the assistant's response with tool calls
	messages := make([]OpenAIMessage, len(originalMessages))
	copy(messages, originalMessages)

	// Add the assistant's message with tool calls
	messages = append(messages, OpenAIMessage{
		Role:      "assistant",
		Content:   initialResp.Choices[0].Message.Content,
		ToolCalls: initialResp.Choices[0].Message.ToolCalls,
	})

	// Process each function call
	for _, toolCall := range initialResp.Choices[0].Message.ToolCalls {
		if toolCall.Type == "function" {
			s.logger.With(ctx).Infof("ðŸ”§ Executing function: %s", toolCall.Function.Name)

			// Parse function arguments
			var arguments map[string]interface{}
			if err := json.Unmarshal([]byte(toolCall.Function.Arguments), &arguments); err != nil {
				s.logger.With(ctx).Errorf("âŒ Failed to parse function arguments: %v", err)
				continue
			}

			// Execute the function
			result, err := s.executeRajaOngkirFunction(ctx, settings, toolCall.Function.Name, arguments)
			if err != nil {
				s.logger.With(ctx).Errorf("âŒ Function execution failed: %v", err)
				result = fmt.Sprintf("Error executing function: %v", err)
			}

			// Add function result as a tool message
			messages = append(messages, OpenAIMessage{
				Role:       "tool",
				Content:    result,
				ToolCallId: toolCall.ID,
			})

			s.logger.With(ctx).Infof("âœ… Function %s executed successfully, result length: %d", toolCall.Function.Name, len(result))
		}
	}

	// Make a follow-up request to OpenAI with the function results
	s.logger.With(ctx).Info("ðŸ”„ Making follow-up request to OpenAI with function results")

	request := OpenAIRequest{
		Model:       settings.Model,
		Messages:    messages,
		MaxTokens:   1000,
		Temperature: 0.7,
		TopP:        1.0,
		Stream:      false,
		// Don't include tools in follow-up request to prevent infinite loops
	}

	jsonData, err := json.Marshal(request)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal follow-up request: %w", err)
	}

	req, err := http.NewRequestWithContext(ctx, "POST", "https://api.openai.com/v1/chat/completions", bytes.NewBuffer(jsonData))
	if err != nil {
		return nil, fmt.Errorf("failed to create follow-up request: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+s.openAIKey)

	client := &http.Client{Timeout: 30 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return nil, fmt.Errorf("failed to make follow-up request: %w", err)
	}
	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("failed to read follow-up response: %w", err)
	}

	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("follow-up request failed: %s - %s", resp.Status, string(body))
	}

	var finalResp OpenAIResponse
	if err := json.Unmarshal(body, &finalResp); err != nil {
		return nil, fmt.Errorf("failed to unmarshal follow-up response: %w", err)
	}

	// Log token usage for monitoring
	s.logger.With(ctx).Infof("ðŸ”¢ Function Call Token Usage - Model: %s, Prompt: %d, Completion: %d, Total: %d",
		request.Model,
		finalResp.Usage.PromptTokens,
		finalResp.Usage.CompletionTokens,
		finalResp.Usage.TotalTokens)

	// NOTE: Function call tokens are included in the main response token count
	// and tracked via the main SendMessage flow to avoid double counting

	s.logger.With(ctx).Info("âœ… Follow-up request completed successfully")
	return &finalResp, nil
}

// calculateShippingCostInternal calculates shipping cost using RajaOngkir service
func (s *service) calculateShippingCostInternal(ctx context.Context, settings *entity.AISettings, destinationCityID int, weight int) ([]rajaongkir.ShippingCostResult, error) {
	if !settings.RajaOngkirEnabled {
		return nil, fmt.Errorf("RajaOngkir integration is not enabled")
	}

	if settings.RajaOngkirOriginDistrict == "" {
		return nil, fmt.Errorf("origin district is not configured")
	}

	if settings.RajaOngkirCouriers == "" {
		return nil, fmt.Errorf("couriers are not configured")
	}

	// Parse couriers from settings
	couriers, err := s.rajaOngkirService.ParseCouriers(settings.RajaOngkirCouriers)
	if err != nil {
		return nil, fmt.Errorf("failed to parse couriers: %w", err)
	}

	// Convert district IDs to strings for API call
	originDistrictStr := settings.RajaOngkirOriginDistrict
	destinationDistrictStr := fmt.Sprintf("%d", destinationCityID)

	s.logger.With(ctx).Infof("ðŸšš Calculating shipping cost: origin=%s, destination=%s, weight=%dg, couriers=%v",
		originDistrictStr, destinationDistrictStr, weight, couriers)

	// Use the RajaOngkir service to get shipping costs
	results, err := s.rajaOngkirService.CalculateShippingCost(settings, destinationDistrictStr, weight)
	if err != nil {
		return nil, fmt.Errorf("failed to get shipping costs: %w", err)
	}

	s.logger.With(ctx).Infof("âœ… Found %d shipping options", len(results))
	return results, nil
}

// storeConversationInSession stores the user message and AI response in session history
func (s *service) storeConversationInSession(sessionID string, userMessage string, aiResponse string) {
	// Load existing history or create new
	var history []OpenAIMessage
	if existingHistory, exists := s.sessions.Load(sessionID); exists {
		if historyMessages, ok := existingHistory.([]OpenAIMessage); ok {
			history = historyMessages
			s.logger.Info("ðŸ“œ Loaded existing history for", sessionID, ":", len(history), "messages")
		}
	} else {
		s.logger.Info("ðŸ“œ Creating new session history for", sessionID)
	}

	// Add user message and AI response to history
	history = append(history, OpenAIMessage{
		Role:    "user",
		Content: userMessage,
	})
	history = append(history, OpenAIMessage{
		Role:    "assistant",
		Content: aiResponse,
	})

	// Update enhanced session with conversation tracking
	enhancedSession := s.getOrCreateEnhancedSession(sessionID)
	enhancedSession.LastUpdated = time.Now()
	enhancedSession.ConversationHistory = history

	// Update conversation summary for better context management
	if len(enhancedSession.ConversationHistory)%6 == 0 { // Update summary every 6 messages
		s.updateConversationSummary(sessionID, history)
	}

	s.logger.Info("ðŸ’¾ Storing", len(history), "messages for session", sessionID)
	// Store updated history back to session
	s.sessions.Store(sessionID, history)
}

// SendMessageToWhatsApp processes a chat message, gets AI response, and sends it to WhatsApp
func (s *service) SendMessageToWhatsApp(ctx context.Context, agentID uuid.UUID, req WhatsAppChatRequest) (*ChatResponse, error) {
	// First, get the AI response using the WhatsApp-specific logic that includes phone number
	chatResponse, err := s.sendMessageInternalWithPhone(ctx, agentID, req.SessionID, req.Message, req.WhatsApp.Number, req.WhatsApp.IDPlatform)
	if err != nil {
		// Check if this is a platform mapping error and try fallback
		if strings.Contains(err.Error(), "failed to get platform mapping for agent identifier") {
			s.logger.With(ctx).Info("Platform mapping failed, attempting stage-based fallback")

			// First, find the contact by phone number
			contact, contactErr := s.contactService.GetContactByIdentifier(ctx, req.WhatsApp.Number)
			if contactErr != nil {
				s.logger.With(ctx).Errorf("Fallback failed: could not find contact for number %s: %v", req.WhatsApp.Number, contactErr)
				return nil, fmt.Errorf("failed to get AI response: %w", err)
			}

			// Try to find lead by contact ID (both assigned and unassigned)
			lead, leadErr := s.leadService.GetLeadByIDContact(ctx, contact.ID)
			if leadErr != nil {
				s.logger.With(ctx).Errorf("Fallback failed: could not find lead for contact %s: %v", contact.ID, leadErr)
				return nil, fmt.Errorf("failed to get AI response: %w", err)
			}

			s.logger.With(ctx).Infof("Found lead %s with stage %v, assigned_to %v", lead.ID, lead.IDStage, lead.AssignTo)

			// Check if lead has a stage assigned
			if lead.IDStage == nil {
				s.logger.With(ctx).Errorf("Fallback failed: lead %s has no stage assigned", lead.ID)
				return nil, fmt.Errorf("failed to get AI response: %w", err)
			}

			// Get the stage information
			stage, stageErr := s.stagesService.GetByID(ctx, *lead.IDStage)
			if stageErr != nil {
				s.logger.With(ctx).Errorf("Fallback failed: could not find stage %s: %v", *lead.IDStage, stageErr)
				return nil, fmt.Errorf("failed to get AI response: %w", err)
			}

			// Check if stage has an agent assigned
			if stage.IDAgent == nil {
				s.logger.With(ctx).Errorf("Fallback failed: stage %s has no agent assigned", stage.ID)
				return nil, fmt.Errorf("failed to get AI response: %w", err)
			}

			// Check if lead is assigned to a human agent that doesn't match the stage's AI agent
			if lead.AssignTo != nil && *lead.AssignTo != *stage.IDAgent {
				s.logger.With(ctx).Infof("Lead %s is assigned to human agent %s, but stage %s has AI agent %s. Skipping AI response.", lead.ID, *lead.AssignTo, stage.ID, *stage.IDAgent)
				// Don't generate AI response if lead is assigned to a different human agent
				return nil, fmt.Errorf("lead is assigned to human agent, not generating AI response")
			}

			// Only proceed with AI response if:
			// 1. Lead is unassigned (AssignTo is nil), OR
			// 2. Lead is assigned to the same agent as the stage's AI agent
			if lead.AssignTo == nil {
				s.logger.With(ctx).Infof("Lead is unassigned, proceeding with AI response using stage agent %s", *stage.IDAgent)
			} else {
				s.logger.With(ctx).Infof("Lead is assigned to AI agent %s which matches stage agent, proceeding with AI response", *lead.AssignTo)
			}

			s.logger.With(ctx).Infof("Stage-based fallback: using agent %s from stage %s", *stage.IDAgent, stage.ID)

			// Try to get AI response using the stage's assigned agent (bypass platform mapping validation)
			fallbackChatResponse, fallbackErr := s.sendMessageInternalWithPhone(ctx, *stage.IDAgent, req.SessionID, req.Message, req.WhatsApp.Number, req.WhatsApp.IDPlatform)
			if fallbackErr == nil {
				s.logger.With(ctx).Info("Successfully got AI response using stage's assigned agent")

				// Send the AI response to WhatsApp
				err = s.sendToWhatsApp(ctx, req.WhatsApp.IDPlatform, req.WhatsApp.Number, fallbackChatResponse.Response)
				if err != nil {
					s.logger.With(ctx).Errorf("Failed to send AI message to WhatsApp: %v", err)
				}

				return fallbackChatResponse, nil
			} else {
				s.logger.With(ctx).Errorf("Failed to get AI response using stage's assigned agent %s: %v", *stage.IDAgent, fallbackErr)
			}

			// If we still can't get an AI response, return a generic acknowledgment
			s.logger.With(ctx).Info("Unable to get AI response, returning generic acknowledgment")
			fallbackResponse := &ChatResponse{
				ID:         uuid.New(),
				AgentID:    agentID,
				SessionID:  req.SessionID,
				Message:    req.Message,
				Response:   "Thank you for your message. We have received it and will get back to you soon.",
				CreatedAt:  time.Now(),
				TokensUsed: 0,
			}

			// Send the fallback response to WhatsApp
			err = s.sendToWhatsApp(ctx, req.WhatsApp.IDPlatform, req.WhatsApp.Number, fallbackResponse.Response)
			if err != nil {
				s.logger.With(ctx).Errorf("Failed to send fallback message to WhatsApp: %v", err)
			}

			return fallbackResponse, nil
		}

		return nil, fmt.Errorf("failed to get AI response: %w", err)
	}

	// Evaluate transfer conditions after getting AI response but before sending to WhatsApp
	if req.SessionID != "" {
		// Get tenant database for transfer evaluation
		tenantDB, _, dbErr := dbcontext.GetTenantDB(ctx, s.dbManager)
		if dbErr == nil {
			// Get AI agent and settings for transfer evaluation
			agent, agentErr := s.repo.GetAIAgentByID(ctx, tenantDB, agentID)
			if agentErr == nil {
				settings, settingsErr := s.repo.GetAISettingsByID(ctx, tenantDB, agent.IDSettings)
				if settingsErr == nil {
					// Evaluate transfer conditions
					transferErr := s.evaluateAndHandleTransferConditions(ctx, tenantDB, agentID, settings, req.Message, chatResponse.Response, req.SessionID, req.WhatsApp.Number)
					if transferErr != nil {
						s.logger.With(ctx).Error("âŒ Transfer condition evaluation failed:", transferErr)
						// Continue with message sending even if transfer evaluation fails
					}
				} else {
					s.logger.With(ctx).Error("âŒ Failed to get AI settings for transfer evaluation:", settingsErr)
				}
			} else {
				s.logger.With(ctx).Error("âŒ Failed to get AI agent for transfer evaluation:", agentErr)
			}
		} else {
			s.logger.With(ctx).Error("âŒ Failed to get tenant DB for transfer evaluation:", dbErr)
		}
	}

	// Get tenant database for placeholder processing
	tenantDBForPlaceholders, _, dbErr := dbcontext.GetTenantDB(ctx, s.dbManager)
	if dbErr != nil {
		s.logger.With(ctx).Errorf("Failed to get tenant DB for placeholder processing: %v", dbErr)
		processedResponse := chatResponse.Response
		// Send the original AI response to WhatsApp
		err = s.sendToWhatsApp(ctx, req.WhatsApp.IDPlatform, req.WhatsApp.Number, processedResponse)
		if err != nil {
			s.logger.With(ctx).Errorf("Failed to send message to WhatsApp: %v", err)
		}
		return chatResponse, nil
	}

	// Process placeholders in the AI response before sending to WhatsApp
	processedResponse, err := s.processResponsePlaceholders(ctx, tenantDBForPlaceholders, chatResponse.Response, req.SessionID)
	if err != nil {
		s.logger.With(ctx).Errorf("Failed to process response placeholders: %v", err)
		// Continue with original response if placeholder processing fails
		processedResponse = chatResponse.Response
	}

	// Update the response with processed content
	chatResponse.Response = processedResponse

	// Send the processed AI response to WhatsApp
	err = s.sendToWhatsApp(ctx, req.WhatsApp.IDPlatform, req.WhatsApp.Number, processedResponse)
	if err != nil {
		s.logger.With(ctx).Errorf("Failed to send message to WhatsApp: %v", err)
		// Don't return error here - we still want to return the chat response
		// The WhatsApp sending failure is logged but doesn't affect the AI response
	}

	return chatResponse, nil
}

// sendToWhatsApp sends a message to the WhatsApp API with post-processing for image URLs
// Behavior: Single image with caption, multiple images uploaded first then text
func (s *service) sendToWhatsApp(ctx context.Context, session, number, message string) error {
	// Check if the message contains image URLs
	imageURLs := s.extractImageURLs(message)

	if len(imageURLs) == 1 {
		// Single image: send with caption (cleaned message)
		imageURL := imageURLs[0]

		// Remove image URL from message to create caption
		caption := message
		caption = strings.ReplaceAll(caption, "`"+imageURL+"`", "")
		caption = strings.ReplaceAll(caption, imageURL, "")

		// Remove "Gambar:" lines and clean up
		caption = regexp.MustCompile(`(?i)\s*gambar:\s*`).ReplaceAllString(caption, "")
		caption = strings.TrimSpace(caption)
		caption = regexp.MustCompile(`\n\s*\n`).ReplaceAllString(caption, "\n\n")

		// Send image with caption
		err := s.sendMediaToWhatsApp(ctx, session, number, caption, imageURL)
		if err != nil {
			s.logger.With(ctx).Errorf("Failed to send image with caption, falling back to text: %v", err)
			return s.sendTextToWhatsApp(ctx, session, number, message)
		}
		s.logger.With(ctx).Infof("Successfully sent single image with caption to WhatsApp - Session: %s, Number: %s, URL: %s", session, number, imageURL)
		return nil

	} else if len(imageURLs) > 1 {
		// Multiple images: send each image with its corresponding product detail as caption
		return s.sendMultipleImagesWithDetails(ctx, session, number, message, imageURLs)
	} else {
		// No image URLs found, send as regular text message (still remove "Gambar:" lines)
		cleanedMessage := regexp.MustCompile(`(?i)\s*gambar:\s*`).ReplaceAllString(message, "")
		cleanedMessage = strings.TrimSpace(cleanedMessage)
		cleanedMessage = regexp.MustCompile(`\n\s*\n`).ReplaceAllString(cleanedMessage, "\n\n")
		return s.sendTextToWhatsApp(ctx, session, number, cleanedMessage)
	}
}

// sendTextToWhatsApp sends a text message to the WhatsApp API
func (s *service) sendTextToWhatsApp(ctx context.Context, session, number, message string) error {
	// Prepare the request payload for WhatsApp API
	payload := map[string]string{
		"session": session,
		"number":  number,
		"message": message,
	}

	jsonData, err := json.Marshal(payload)
	if err != nil {
		return fmt.Errorf("failed to marshal WhatsApp request: %w", err)
	}

	// Create HTTP request to WhatsApp API
	req, err := http.NewRequestWithContext(ctx, "POST", s.whatsappServiceURL+"/send-message", bytes.NewBuffer(jsonData))
	if err != nil {
		return fmt.Errorf("failed to create WhatsApp request: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")

	// Send the request
	client := &http.Client{Timeout: WhatsAppTextTimeout}
	resp, err := client.Do(req)
	if err != nil {
		return fmt.Errorf("failed to send WhatsApp request: %w", err)
	}
	defer resp.Body.Close()

	// Check response status
	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("WhatsApp API error: %s - %s", resp.Status, string(body))
	}

	s.logger.With(ctx).Infof("Successfully sent text message to WhatsApp - Session: %s, Number: %s", session, number)
	return nil
}

// SendWelcomeMessage sends an instant welcome message without AI processing
func (s *service) SendWelcomeMessage(ctx context.Context, agentID uuid.UUID, req ChatRequest) (*ChatResponse, error) {
	// Get tenant database
	db, _, err := dbcontext.GetTenantDB(ctx, s.dbManager)
	if err != nil {
		return nil, fmt.Errorf("failed to get tenant database: %w", err)
	}

	// Get agent configuration
	agent, err := s.repo.GetAIAgentByID(ctx, db, agentID)
	if err != nil {
		return nil, fmt.Errorf("failed to get agent: %w", err)
	}

	// Get AI settings to access welcome message
	settings, err := s.repo.GetAISettingsByID(ctx, db, agent.IDSettings)
	if err != nil {
		return nil, fmt.Errorf("failed to get AI settings: %w", err)
	}

	// Check if welcome message is configured
	if settings.WelcomeMessage == "" {
		return nil, fmt.Errorf("no welcome message configured for agent")
	}

	// Create welcome message response
	welcomeResponse := &ChatResponse{
		ID:        uuid.New(),
		AgentID:   agentID,
		SessionID: req.SessionID,
		Message:   settings.WelcomeMessage,
		Response:  settings.WelcomeMessage,
		Messages: []ChatMessage{
			{
				ID:        uuid.New(),
				Content:   settings.WelcomeMessage,
				Sender:    "ai",
				CreatedAt: time.Now(),
			},
		},
		CreatedAt:  time.Now(),
		TokensUsed: 0, // No tokens used for welcome message
	}

	return welcomeResponse, nil
}

// ResetSession clears all session-related data for a given session ID
func (s *service) ResetSession(ctx context.Context, sessionID string) error {
	s.logger.With(ctx).Info("ðŸ”„ Resetting session:", sessionID)

	// Clear conversation history
	s.sessions.Delete(sessionID)
	s.logger.With(ctx).Info("ðŸ—‘ï¸ Cleared conversation history for session:", sessionID)

	// Clear enhanced session data
	s.enhancedSessions.Delete(sessionID)
	s.logger.With(ctx).Info("ðŸ—‘ï¸ Cleared enhanced session data for session:", sessionID)

	// Clear field state cache
	s.fieldStateCache.Delete(sessionID)
	s.logger.With(ctx).Info("ðŸ—‘ï¸ Cleared field state cache for session:", sessionID)

	// Clear integration state cache
	s.integrationStateCache.Delete(sessionID)
	s.logger.With(ctx).Info("ðŸ—‘ï¸ Cleared integration state cache for session:", sessionID)

	// Clear conversation summaries
	s.conversationSummaries.Delete(sessionID)
	s.logger.With(ctx).Info("ðŸ—‘ï¸ Cleared conversation summaries for session:", sessionID)

	// Clear image analysis results
	s.imageAnalysisResults.Delete(sessionID)
	s.logger.With(ctx).Info("ðŸ—‘ï¸ Cleared image analysis results for session:", sessionID)

	// Clear transfer cooldown
	s.transferCooldown.Delete(sessionID)
	s.logger.With(ctx).Info("ðŸ—‘ï¸ Cleared transfer cooldown for session:", sessionID)

	// Clear payment detection cooldown
	s.paymentDetectionCooldown.Delete(sessionID)
	s.logger.With(ctx).Info("ðŸ—‘ï¸ Cleared payment detection cooldown for session:", sessionID)

	// Clear session-based behavior cache (need to iterate through all keys to find matching session)
	s.sessionBehaviorCache.Range(func(key, value interface{}) bool {
		if keyStr, ok := key.(string); ok {
			// Session behavior cache keys are in format: sessionID+agentID
			if strings.HasPrefix(keyStr, sessionID) {
				s.sessionBehaviorCache.Delete(key)
				s.logger.With(ctx).Info("ðŸ—‘ï¸ Cleared session behavior cache for key:", keyStr)
			}
		}
		return true
	})

	s.logger.With(ctx).Info("âœ… Session reset completed successfully for session:", sessionID)
	return nil
}

// AIUsageLog represents a comprehensive log entry for AI usage
type AIUsageLog struct {
	Timestamp    time.Time `json:"timestamp"`
	Model        string    `json:"model"`
	TokensUsed   int       `json:"tokens_used"`
	UsageCredits float64   `json:"usage_credits"` // tokens / 400
	RequestType  string    `json:"request_type"`
	SessionID    string    `json:"session_id"`
	AgentID      string    `json:"agent_id"`
	TenantID     string    `json:"tenant_id"`
	UserID       string    `json:"user_id"`
	PhoneNumber  string    `json:"phone_number,omitempty"`
	Platform     string    `json:"platform,omitempty"`
}

// logAIUsage creates a comprehensive log entry for AI usage with token tracking and usage calculation
// NOTE: This function should ONLY be called once per complete operation to avoid double logging
func (s *service) logAIUsage(ctx context.Context, model string, tokensUsed int, requestType string, sessionID string, agentID uuid.UUID, phoneNumber string, platform string) {
	// Calculate usage credits (tokens divided by 1000)
	usageCredits := float64(tokensUsed) / 1000.0

	// Get context information
	tenantID := token.GetTenantID(ctx)
	userID := token.GetUserID(ctx)

	// IMPORTANT: Do NOT add to token tracker here as it's already tracked in callOpenAI
	// This prevents double logging in the token tracker

	// Track model usage to database for evaluation operations
	if requestType == "dedicated_trigger_evaluation" || requestType == "trigger_evaluation_preprocess" ||
		requestType == "transfer_evaluation" || requestType == "order_extraction" ||
		requestType == "customer_info_extraction" {
		if tenantID != uuid.Nil {
			err := s.usageTrackingService.TrackModelUsage(ctx, tenantID, model, tokensUsed)
			if err != nil {
				s.logger.With(ctx).Error("âŒ Failed to track model usage for", requestType, ":", err)
			} else {
				s.logger.With(ctx).Info("ðŸ“Š Model usage tracked to database for", requestType, "- tenant:", tenantID, "model:", model, "tokens:", tokensUsed)
			}
		} else {
			s.logger.With(ctx).Error("âŒ Failed to track model usage for", requestType, ": tenant ID is nil")
		}
	}

	// Create usage log entry
	usageLog := AIUsageLog{
		Timestamp:    time.Now(),
		Model:        model,
		TokensUsed:   tokensUsed,
		UsageCredits: usageCredits,
		RequestType:  requestType,
		SessionID:    sessionID,
		AgentID:      agentID.String(),
		TenantID:     tenantID.String(),
		UserID:       userID.String(),
		PhoneNumber:  phoneNumber,
		Platform:     platform,
	}

	// Log the comprehensive AI usage information
	s.logger.With(ctx).Infof(
		"ðŸ¤– AI USAGE SUMMARY - Model: %s | Tokens: %d | Credits: %.3f | Type: %s | Session: %s | Agent: %s | Tenant: %s | User: %s | Phone: %s | Platform: %s",
		usageLog.Model,
		usageLog.TokensUsed,
		usageLog.UsageCredits,
		usageLog.RequestType,
		usageLog.SessionID,
		usageLog.AgentID,
		usageLog.TenantID,
		usageLog.UserID,
		usageLog.PhoneNumber,
		usageLog.Platform,
	)

	// Also log in a structured format for easy parsing
	s.logger.With(ctx).Infof("ðŸ“Š AI_USAGE_STRUCTURED: %+v", usageLog)
}

// checkIntegrationDependency validates if the dependency integration has been executed, meets success requirements, and produced meaningful data
func (s *service) checkIntegrationDependency(ctx context.Context, dependsOnIntegrationID uuid.UUID, requiresSuccess bool, integrationResults map[string]interface{}, integrations []custom_integration.AIAgentIntegrationResponse) bool {
	// Find the dependency integration name
	var dependencyName string
	for _, integration := range integrations {
		if integration.IDIntegration == dependsOnIntegrationID {
			dependencyName = integration.IntegrationName
			break
		}
	}

	if dependencyName == "" {
		s.logger.With(ctx).Error("âŒ Dependency integration not found:", dependsOnIntegrationID)
		return false
	}

	// Check if dependency has been executed
	dependencyResult, exists := integrationResults[dependencyName]
	if !exists {
		s.logger.With(ctx).Info("â­ï¸ Dependency integration not yet executed:", dependencyName)
		return false
	}

	// Validate dependency result structure
	resultMap, ok := dependencyResult.(map[string]interface{})
	if !ok {
		s.logger.With(ctx).Error("âŒ Invalid dependency result structure for:", dependencyName)
		return false
	}

	// If success is required, check the success status
	if requiresSuccess {
		if success, ok := resultMap["success"].(bool); ok && success {
			s.logger.With(ctx).Info("âœ… Dependency integration executed successfully:", dependencyName)

			// Additional validation: Check if dependency produced meaningful data
			if extractedData, hasData := resultMap["extractedData"].(map[string]interface{}); hasData {
				meaningfulDataCount := 0
				for _, value := range extractedData {
					if value != nil && value != "" && value != "null" {
						if strVal, ok := value.(string); ok {
							if strings.TrimSpace(strVal) != "" {
								meaningfulDataCount++
							}
						} else {
							meaningfulDataCount++
						}
					}
				}

				if meaningfulDataCount == 0 {
					s.logger.With(ctx).Error("âŒ Dependency integration succeeded but produced no meaningful data:", dependencyName)
					return false
				}

				s.logger.With(ctx).Info("âœ… Dependency integration has meaningful data:", dependencyName, "Fields:", meaningfulDataCount)
			} else {
				s.logger.With(ctx).Error("âŒ Dependency integration has no extracted data:", dependencyName)
				return false
			}

			return true
		} else {
			s.logger.With(ctx).Info("âŒ Dependency integration failed:", dependencyName)
			return false
		}
	}

	// If success is not required, just check if it was executed
	s.logger.With(ctx).Info("âœ… Dependency integration executed (success not required):", dependencyName)
	return true
}

// processCustomIntegrations handles the evaluation and execution of custom integrations
// with sequential processing - one integration at a time, waiting for customer satisfaction
func (s *service) processCustomIntegrations(ctx context.Context, db *dbcontext.DB, agentID uuid.UUID, userMessage, aiResponse, sessionID, phoneNumber string) error {
	// Get session state for sequential processing
	session := s.getOrCreateEnhancedSession(sessionID)

	// Check if customer is satisfied with the last integration result
	if session.WaitingForSatisfaction {
		isSatisfied := s.checkCustomerSatisfaction(ctx, userMessage, sessionID)
		if isSatisfied {
			s.logger.With(ctx).Info("âœ… Customer satisfied with last integration, proceeding to next")
			s.proceedToNextIntegration(sessionID)
		} else {
			s.logger.With(ctx).Info("â³ Customer not yet satisfied, staying on current integration")
			return nil // Don't process any new integrations until customer is satisfied
		}
	}

	// Load custom integrations for the AI agent
	s.logger.With(ctx).Info("ðŸ” Loading custom integrations for agent:", agentID)
	integrations, err := s.customIntegrationService.GetAIAgentIntegrationsByAgentID(ctx, agentID)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to load custom integrations for agent:", agentID, "Error:", err)
		return fmt.Errorf("failed to load custom integrations: %w", err)
	}

	if len(integrations) == 0 {
		s.logger.With(ctx).Info("ðŸ“‹ No custom integrations found for agent:", agentID)
		return nil
	}

	s.logger.With(ctx).Info("âœ… Successfully loaded", len(integrations), "custom integrations for agent:", agentID)

	// Get current session state
	session = s.getOrCreateEnhancedSession(sessionID)
	currentIndex := session.CurrentIntegrationIndex

	// Check if we've processed all integrations
	if currentIndex >= len(integrations) {
		s.logger.With(ctx).Info("ðŸŽ‰ All integrations have been processed sequentially")
		return nil
	}

	s.logger.With(ctx).Info("ðŸ“ Sequential processing: current integration index", currentIndex, "of", len(integrations))

	// Log detailed integration data for debugging
	for _, integration := range integrations {
		s.logger.With(ctx).Info("ðŸ“‹ Integration details:", "name", integration.IntegrationName, "id", integration.IDIntegration, "enabled", integration.IsEnabled)
		if integration.TriggerCondition != nil {
			s.logger.With(ctx).Info("ðŸŽ¯ Trigger condition:", "integration", integration.IntegrationName, "condition", *integration.TriggerCondition)
		}

		// Get and log fields for this integration
		fields, err := s.customIntegrationService.GetCustomIntegrationFieldsByIntegrationID(ctx, integration.IDIntegration)
		if err != nil {
			s.logger.With(ctx).Error("âŒ Failed to get fields for integration:", integration.IntegrationName, "Error:", err)
		} else {
			s.logger.With(ctx).Info("ðŸ“Š Integration fields count:", "integration", integration.IntegrationName, "fields_count", len(fields))
			for _, field := range fields {
				s.logger.With(ctx).Info("ðŸ”§ Field details:", "integration", integration.IntegrationName, "field_name", field.FieldName, "field_type", field.FieldType, "required", field.IsRequired)
				if field.EnumValues != nil {
					s.logger.With(ctx).Info("ðŸ“ Enum values:", "integration", integration.IntegrationName, "field", field.FieldName, "enum_values", *field.EnumValues)
				}
				if field.Description != nil {
					s.logger.With(ctx).Info("ðŸ“„ Field description:", "integration", integration.IntegrationName, "field", field.FieldName, "description", *field.Description)
				}
			}
		}
	}

	// Use session integration results for dependency checking
	integrationResults := session.IntegrationResults
	if integrationResults == nil {
		integrationResults = make(map[string]interface{})
	}

	// Process only the current integration in sequence
	integration := integrations[currentIndex]
	s.logger.With(ctx).Info("ðŸŽ¯ Processing integration", currentIndex+1, "of", len(integrations), ":", integration.IntegrationName)

	if !integration.IsEnabled {
		s.logger.With(ctx).Info("â­ï¸ Current integration is disabled, moving to next:", integration.IntegrationName)
		s.proceedToNextIntegration(sessionID)
		return nil
	}

	if integration.TriggerCondition == nil || *integration.TriggerCondition == "" {
		s.logger.With(ctx).Info("â­ï¸ Current integration has no trigger condition, moving to next:", integration.IntegrationName)
		s.proceedToNextIntegration(sessionID)
		return nil
	}

	// Check dependencies before processing
	if integration.DependsOnIntegration != nil {
		dependencyMet := s.checkIntegrationDependency(ctx, *integration.DependsOnIntegration, integration.RequiresSuccess, integrationResults, integrations)
		if !dependencyMet {
			s.logger.With(ctx).Info("â­ï¸ Current integration dependency not met, waiting:", integration.IntegrationName)
			return nil // Wait for dependency to be satisfied
		}
	}

	s.logger.With(ctx).Info("ðŸ” Evaluating trigger condition for integration:", integration.IntegrationName, "(ID:", integration.IDIntegration, ")")
	s.logger.With(ctx).Info("ðŸ“‹ Trigger condition:", *integration.TriggerCondition)

	// Evaluate if trigger condition is met using AI analysis
	triggerMet, extractedData, err := s.evaluateTriggerCondition(ctx, *integration.TriggerCondition, userMessage, aiResponse, integration.IDIntegration)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to evaluate trigger condition for integration:", integration.IntegrationName, "Error:", err)
		return err
	}

	if !triggerMet {
		s.logger.With(ctx).Info("âŒ Trigger condition NOT met for integration:", integration.IntegrationName, "(ID:", integration.IDIntegration, ")")
		return nil // Trigger not met, wait for next message
	}

	// ðŸŽ¯ CUSTOM INTEGRATION SUCCESSFULLY TRIGGERED
	s.logger.With(ctx).Info("ðŸŽ¯ ===== CUSTOM INTEGRATION TRIGGERED =====")
	s.logger.With(ctx).Info("ðŸŽ¯ Integration Name:", integration.IntegrationName)
	s.logger.With(ctx).Info("ðŸŽ¯ Integration ID:", integration.IDIntegration)
	s.logger.With(ctx).Info("ðŸŽ¯ Trigger Condition:", *integration.TriggerCondition)
	s.logger.With(ctx).Info("ðŸŽ¯ User Message:", userMessage)
	s.logger.With(ctx).Info("ðŸŽ¯ AI Response:", aiResponse)
	s.logger.With(ctx).Info("ðŸŽ¯ Extracted Data:", extractedData)
	s.logger.With(ctx).Info("ðŸŽ¯ =========================================")

	// Get contact ID if phone number is provided
	var contactID *uuid.UUID
	if phoneNumber != "" {
		contact, err := s.contactService.GetContactByIdentifier(ctx, phoneNumber)
		if err == nil {
			contactID = &contact.ID
			s.logger.With(ctx).Info("ðŸ“ž Found contact ID for phone number:", phoneNumber, "Contact ID:", contact.ID)
		} else {
			s.logger.With(ctx).Info("âš ï¸ Could not find contact for phone number:", phoneNumber, "Error:", err)
		}
	}

	// Execute the integration
	err = s.executeIntegration(ctx, integration, extractedData, contactID)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to execute integration:", integration.IntegrationName, "Error:", err)
		// Store failed integration result
		integrationResults[integration.IntegrationName] = map[string]interface{}{
			"success":       false,
			"error":         err.Error(),
			"integrationId": integration.IDIntegration,
			"extractedData": extractedData,
		}
		// Update session with failed result
		session.IntegrationResults = integrationResults
		s.updateEnhancedSession(sessionID, session)
		return err
	}

	s.logger.With(ctx).Info("âœ… Successfully executed integration:", integration.IntegrationName, "(ID:", integration.IDIntegration, ")")

	// Store the successful integration result
	integrationResults[integration.IntegrationName] = map[string]interface{}{
		"success":       true,
		"integrationId": integration.IDIntegration,
		"extractedData": extractedData,
	}
	s.logger.With(ctx).Info("ðŸ’¾ Stored successful integration result for:", integration.IntegrationName)

	// Update session with results and mark integration as executed
	session.IntegrationResults = integrationResults
	s.markIntegrationExecuted(sessionID, integration.IDIntegration, integration.IntegrationName, integrationResults[integration.IntegrationName].(map[string]interface{}))

	s.logger.With(ctx).Info("ðŸ“Š Integration executed successfully. Waiting for customer satisfaction before proceeding.")
	return nil
}

// evaluateTriggerCondition uses AI to determine if a trigger condition is met
// and extracts relevant data for the integration with enhanced validation
func (s *service) evaluateTriggerCondition(ctx context.Context, triggerCondition, userMessage, aiResponse string, integrationID uuid.UUID) (bool, map[string]interface{}, error) {
	// Enhanced validation: Check for minimum trigger condition requirements
	if strings.TrimSpace(triggerCondition) == "" {
		s.logger.With(ctx).Error("âŒ Empty trigger condition provided")
		return false, nil, fmt.Errorf("trigger condition cannot be empty")
	}

	// Enhanced validation: Check message content quality
	if len(strings.TrimSpace(userMessage)) < 3 {
		s.logger.With(ctx).Info("âš ï¸ User message too short for meaningful trigger evaluation")
		return false, nil, nil
	}

	// Get integration details for complete context
	integrationEntity, err := s.customIntegrationService.GetCustomIntegrationByID(ctx, integrationID)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to get integration details:", err)
		return false, nil, fmt.Errorf("failed to get integration details: %w", err)
	}

	// Enhanced validation: Check integration configuration completeness
	if integrationEntity.WebhookURL == "" {
		s.logger.With(ctx).Error("âŒ Integration has no webhook URL configured")
		return false, nil, fmt.Errorf("integration webhook URL not configured")
	}

	// Get integration fields to understand what data to extract
	fields, err := s.customIntegrationService.GetCustomIntegrationFieldsByIntegrationID(ctx, integrationID)

	// Build field descriptions for AI analysis
	fieldDescriptions := make([]string, 0, len(fields))
	for _, field := range fields {
		desc := fmt.Sprintf("%s (%s)", field.FieldName, field.FieldType)
		if field.Description != nil {
			desc += ": " + *field.Description
		}
		if field.FieldType == "enum" && field.EnumValues != nil {
			desc += " [Options: " + *field.EnumValues + "]"
		}
		if field.IsRequired {
			desc += " (Required)"
		}
		fieldDescriptions = append(fieldDescriptions, desc)
	}

	// Build field formatting rules dynamically based on actual field configurations
	// Use field descriptions as behavior guides for AI 2 to format field values properly
	fieldFormattingRules := make([]string, 0)

	for _, field := range fields {
		if field.FieldType == "enum" && field.EnumValues != nil {
			// Parse enum values
			enumOptions := strings.Split(*field.EnumValues, ",")
			for i, option := range enumOptions {
				enumOptions[i] = strings.TrimSpace(option)
			}

			// Enhanced enum field rule with description-based formatting behavior
			rule := fmt.Sprintf("- For %s field: Use fuzzy matching to find the best match from available enum options [%s].", field.FieldName, strings.Join(enumOptions, ", "))

			// CRITICAL: Use field description as formatting behavior guide for AI 2
			if field.Description != nil && *field.Description != "" {
				rule += fmt.Sprintf(" FORMATTING BEHAVIOR: %s", *field.Description)
				// Log the formatting behavior for debugging
				s.logger.With(ctx).Info("ðŸŽ¯ Field formatting behavior for", field.FieldName, ":", *field.Description)
			} else {
				rule += " If uncertain or no close match found, return to main AI with clarificationSuggestion asking user to choose from available options."
			}

			fieldFormattingRules = append(fieldFormattingRules, rule)

		} else if field.FieldType != "enum" {
			// Add rules for non-enum fields with description-based behavior
			var fieldRule string
			switch field.FieldType {
			case "text":
				fieldRule = fmt.Sprintf("- For %s field: Extract relevant text information from user message", field.FieldName)
			case "email":
				fieldRule = fmt.Sprintf("- For %s field: Extract valid email address from user message", field.FieldName)
			case "number":
				fieldRule = fmt.Sprintf("- For %s field: Extract numeric value from user message", field.FieldName)
			case "boolean":
				fieldRule = fmt.Sprintf("- For %s field: Determine true/false based on user intent", field.FieldName)
			case "date":
				fieldRule = fmt.Sprintf("- For %s field: Extract date information in YYYY-MM-DD format", field.FieldName)
			case "url":
				fieldRule = fmt.Sprintf("- For %s field: Extract valid URL from user message", field.FieldName)
			default:
				fieldRule = fmt.Sprintf("- For %s field: Extract relevant information from user message", field.FieldName)
			}

			// CRITICAL: Use field description as formatting behavior guide for AI 2
			if field.Description != nil && *field.Description != "" {
				fieldRule += fmt.Sprintf(" FORMATTING BEHAVIOR: %s", *field.Description)
				// Log the formatting behavior for debugging
				s.logger.With(ctx).Info("ðŸŽ¯ Field formatting behavior for", field.FieldName, ":", *field.Description)
			}

			fieldFormattingRules = append(fieldFormattingRules, fieldRule)
		}
	}

	// Build webhook payload structure information for better field validation
	webhookPayloadInfo := s.buildWebhookPayloadStructure(integrationEntity, fields)

	// Create AI prompt for trigger evaluation with complete integration context
	prompt := fmt.Sprintf(`Analyze the following conversation to determine if the trigger condition is met and extract relevant data.

=== COMPLETE INTEGRATION CONFIGURATION ===
Integration Name: %s
Integration ID: %s
Trigger Condition: %s
Webhook URL: %s
HTTP Method: %s
Content Type: %s
Timeout: %d seconds
Integration Description: %s

=== WEBHOOK PAYLOAD STRUCTURE ===
%s

=== INTEGRATION CONTEXT UNDERSTANDING ===
- This integration will send data to the webhook endpoint using %s method
- For GET requests: Field values become URL query parameters (?field1=value1&field2=value2)
- For POST requests: Field values become JSON body payload {"field1": "value1", "field2": "value2"}
- All field values must be properly validated and formatted before webhook execution
- Required fields are MANDATORY for successful webhook call
- Optional fields enhance the webhook payload when available
- Field descriptions provide formatting and validation guidance

User Message: %s
AI Response: %s

Required Fields to Extract:
%s

DYNAMIC FIELD FORMATTING RULES:
%s

Respond with a JSON object containing:
{
  "trigger_met": true/false,
  "extracted_data": {
    "field_name": "extracted_value",
    ...
  },
  "reasoning": "explanation of why trigger is/isn't met"
}

IMPORTANT RULES:
- Only set trigger_met to true if ALL required conditions are clearly met
- For enum fields, follow the specific formatting rules above for each field
- Ignore Indonesian particles like "min", "kak", "ya", "nih", "dong", "sih" when extracting data
- Apply appropriate formatting rules based on field type and configuration
- PARTICLE RECOGNITION: Understand that conversational particles are not part of the actual data`,
		integrationEntity.Name,
		integrationEntity.ID,
		triggerCondition,
		integrationEntity.WebhookURL,
		integrationEntity.HTTPMethod,
		integrationEntity.ContentType,
		integrationEntity.TimeoutSeconds,
		integrationEntity.Description,
		webhookPayloadInfo,
		integrationEntity.HTTPMethod,
		userMessage,
		aiResponse,
		strings.Join(fieldDescriptions, "\n"),
		strings.Join(fieldFormattingRules, "\n"))

	s.logger.With(ctx).Info("ðŸ¤– Sending trigger evaluation prompt to AI")

	// Call OpenAI for trigger evaluation with enhanced system instructions
	messages := []OpenAIMessage{
		{
			Role: "system",
			Content: `You are an advanced AI conversation analyst and data extraction system designed for internal processing. You have access to a large context window and sophisticated reasoning capabilities.

Your primary responsibilities:
1. COMPREHENSIVE CONVERSATION ANALYSIS: Analyze the entire conversation history with deep understanding of context, flow, and user intent
2. INTELLIGENT FIELD EXTRACTION: Extract required fields from any part of the conversation using contextual understanding
3. NATURAL CONVERSATION FLOW: Recognize when users are ready to proceed based on conversational cues and previous data sharing
4. CONTEXTUAL REASONING: Understand implied information, confirmations, and conversational progression

CRITICAL PROCESSING RULES:
- This is INTERNAL PROCESSING ONLY - never generate user-facing responses
- ONLY return the requested JSON object with no additional text
- Use your full reasoning capabilities to understand conversation context
- Recognize patterns like: user sharing info â†’ AI acknowledging â†’ user confirming â†’ trigger activation
- Be intelligent about extracting data from natural conversation flow
- Consider the entire conversation as a connected dialogue, not isolated messages

Your output MUST be valid JSON only.`,
		},
		{
			Role:    "user",
			Content: prompt,
		},
	}

	// Use a powerful model with large context window for comprehensive conversation analysis
	settings := &entity.AISettings{
		Model: "gpt-4.1-mini", // Using GPT-4.1 for better conversation understanding and field extraction
	}

	// Get token tracker from context or create a new one for tracking this evaluation
	tokenTracker := accesslog.GetTokenTrackerFromContext(ctx)
	if tokenTracker == nil {
		requestID := uuid.New().String()
		tokenTracker = accesslog.NewTokenTracker(requestID)
		s.logger.With(ctx).Infof("ðŸ”¢ Created token tracker for trigger evaluation: %s", requestID)
	}

	resp, err := s.callOpenAI(ctx, messages, settings, "trigger evaluation", len(prompt), tokenTracker, "trigger_evaluation")

	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to call OpenAI for trigger evaluation:", err)
		return false, nil, fmt.Errorf("failed to evaluate trigger condition: %w", err)
	}

	// NOTE: Model usage tracking is handled by the main conversation flow to avoid double tracking

	if len(resp.Choices) == 0 {
		s.logger.With(ctx).Error("âŒ No response from OpenAI for trigger evaluation")
		return false, nil, fmt.Errorf("no response from OpenAI")
	}

	responseContent := resp.Choices[0].Message.Content
	s.logger.With(ctx).Info("ðŸ¤– AI trigger evaluation raw response:", responseContent)

	// Clean and validate the response content
	responseContent = strings.TrimSpace(responseContent)

	// Validate JSON structure before unmarshaling
	if !json.Valid([]byte(responseContent)) {
		s.logger.With(ctx).Error("âŒ Invalid JSON structure detected, attempting to extract and repair JSON from response")
		s.logger.With(ctx).Info("ðŸ” Response length:", len(responseContent))
		s.logger.With(ctx).Info("ðŸ” First 100 chars:", responseContent[:min(100, len(responseContent))])
		s.logger.With(ctx).Info("ðŸ” Last 100 chars:", responseContent[max(0, len(responseContent)-100):])

		// Try to extract JSON from the response if it's wrapped in other text
		jsonStart := strings.Index(responseContent, "{")
		jsonEnd := strings.LastIndex(responseContent, "}")

		if jsonStart != -1 {
			var extractedJSON string
			if jsonEnd != -1 && jsonEnd > jsonStart {
				// Found both opening and closing braces
				extractedJSON = responseContent[jsonStart : jsonEnd+1]
			} else {
				// Missing closing brace, try to repair the JSON
				s.logger.With(ctx).Info("ðŸ”§ Attempting to repair incomplete JSON response")
				extractedJSON = responseContent[jsonStart:]

				// Try to complete the JSON structure
				if !strings.HasSuffix(strings.TrimSpace(extractedJSON), "}") {
					// Count opening and closing braces to determine how many we need
					openBraces := strings.Count(extractedJSON, "{")
					closeBraces := strings.Count(extractedJSON, "}")
					missingBraces := openBraces - closeBraces

					if missingBraces > 0 {
						// Add missing closing braces
						extractedJSON += strings.Repeat("}", missingBraces)
						s.logger.With(ctx).Info("ðŸ”§ Added", missingBraces, "missing closing braces")
					}
				}
			}

			if json.Valid([]byte(extractedJSON)) {
				s.logger.With(ctx).Info("âœ… Successfully extracted/repaired valid JSON from response")
				responseContent = extractedJSON
			} else {
				s.logger.With(ctx).Error("âŒ Extracted JSON is still invalid after repair attempt")
				s.logger.With(ctx).Info("ðŸ” Attempted JSON:", extractedJSON)
				// Don't return error here, let it fall through to fallback response
				responseContent = "" // This will trigger the fallback in json.Unmarshal
			}
		} else {
			s.logger.With(ctx).Error("âŒ No JSON structure found in response")
			// Don't return error here, let it fall through to fallback response
			responseContent = "" // This will trigger the fallback in json.Unmarshal
		}
	}

	// Parse the enhanced JSON response with field sources and confidence tracking
	var result struct {
		TriggerMet       bool                   `json:"trigger_met"`
		ExtractedData    map[string]interface{} `json:"extracted_data"`
		FieldSources     map[string]string      `json:"field_sources"`
		Reasoning        string                 `json:"reasoning"`
		Confidence       string                 `json:"confidence,omitempty"`
		ValidationErrors []string               `json:"validation_errors,omitempty"`
		RiskFactors      []string               `json:"risk_factors,omitempty"`
	}

	err = json.Unmarshal([]byte(responseContent), &result)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to parse AI response JSON:", err, "Response:", responseContent)

		// Try to create a fallback response structure
		s.logger.With(ctx).Error("ðŸ”„ Creating fallback response structure for main trigger evaluation")
		result = struct {
			TriggerMet       bool                   `json:"trigger_met"`
			ExtractedData    map[string]interface{} `json:"extracted_data"`
			FieldSources     map[string]string      `json:"field_sources"`
			Reasoning        string                 `json:"reasoning"`
			Confidence       string                 `json:"confidence,omitempty"`
			ValidationErrors []string               `json:"validation_errors,omitempty"`
			RiskFactors      []string               `json:"risk_factors,omitempty"`
		}{
			TriggerMet:       false,
			ExtractedData:    make(map[string]interface{}),
			FieldSources:     make(map[string]string),
			Reasoning:        "Failed to parse AI response JSON: " + err.Error(),
			Confidence:       "low",
			ValidationErrors: []string{"JSON parsing failed"},
			RiskFactors:      []string{"malformed_response"},
		}
		s.logger.With(ctx).Info("âœ… Using fallback response structure for main trigger evaluation")
	}

	// Enhanced validation: Check for validation errors and risk factors
	if len(result.ValidationErrors) > 0 {
		s.logger.With(ctx).Error("âš ï¸ Validation errors detected: %v", result.ValidationErrors)
		// Don't trigger if there are validation errors
		result.TriggerMet = false
	}

	if len(result.RiskFactors) > 0 {
		s.logger.With(ctx).Error("âš ï¸ Risk factors identified: %v", result.RiskFactors)
		// Apply additional scrutiny for risky triggers
		if result.Confidence == "low" || result.Confidence == "" {
			s.logger.With(ctx).Info("ðŸ›¡ï¸ Blocking low-confidence trigger with risk factors")
			result.TriggerMet = false
		}
	}

	// Enhanced validation: Reasoning takes priority over trigger_met value
	if result.Reasoning != "" {
		// Check if reasoning contains phrases indicating the trigger should be false
		reasoningLower := strings.ToLower(result.Reasoning)
		contradictoryPhrases := []string{
			"trigger_met should be false",
			"trigger_met must be false",
			"should be trigger_met: false",
			"trigger condition is not met",
			"trigger condition not met",
			"correcting this: trigger_met should be false",
			"the correct response should be trigger_met: false",
			"no location was provided",
			"no location is present",
			"no specific location was provided",
			"no geographical reference",
			"does not contain any geographical reference",
			"does not explicitly mention any location",
			"no location was given",
			"trigger_met should be false",
			"proper conclusion is that",
			"therefore, the proper conclusion",
		}

		// Also check for logical conclusions that indicate false
		logicalFalsePhrases := []string{
			"therefore", "thus", "hence", "consequently", "as a result",
			"proper conclusion", "correct response", "should be false",
		}

		hasContradiction := false
		for _, phrase := range contradictoryPhrases {
			if strings.Contains(reasoningLower, phrase) {
				hasContradiction = true
				break
			}
		}

		// Additional check for logical flow that concludes with false
		if !hasContradiction {
			for _, logicalPhrase := range logicalFalsePhrases {
				if strings.Contains(reasoningLower, logicalPhrase) {
					// Check if the logical conclusion mentions false or not met
					logicalIndex := strings.Index(reasoningLower, logicalPhrase)
					if logicalIndex != -1 {
						remainingText := reasoningLower[logicalIndex:]
						if strings.Contains(remainingText, "false") || strings.Contains(remainingText, "not met") {
							hasContradiction = true
							break
						}
					}
				}
			}
		}

		if hasContradiction {
			if result.TriggerMet {
				s.logger.With(ctx).Error("ðŸ” Detected reasoning contradiction - AI reasoning indicates trigger should be false but trigger_met is true")
				s.logger.With(ctx).Error("ðŸ”§ REASONING TAKES PRIORITY: Overriding trigger_met to false based on reasoning analysis")
			} else {
				s.logger.With(ctx).Info("âœ… Reasoning and trigger_met are consistent - both indicate false")
			}
			result.TriggerMet = false
			result.ValidationErrors = append(result.ValidationErrors, "Reasoning analysis indicates trigger should be false - reasoning takes priority")
		}

		// Enhanced validation: Check for geographical mapping contradictions in reasoning
		if result.TriggerMet && len(result.ExtractedData) > 0 {
			// Check if reasoning mentions a different city than what was extracted
			if kotaValue, exists := result.ExtractedData["kota"]; exists {
				kotaStr, ok := kotaValue.(string)
				if ok {
					// Find the kota field to get its enum values dynamically
					var kotaEnumValues []string
					for _, field := range fields {
						if field.FieldName == "kota" && field.FieldType == "enum" && field.EnumValues != nil {
							// Parse enum values (comma-separated)
							enumOptions := strings.Split(*field.EnumValues, ",")
							for _, option := range enumOptions {
								kotaEnumValues = append(kotaEnumValues, strings.TrimSpace(option))
							}
							break
						}
					}

					reasoningContainsCity := ""
					// If we have enum values, check for contradictions dynamically
					if len(kotaEnumValues) > 0 {
						// Check each enum value to see if it's mentioned in reasoning
						for _, enumValue := range kotaEnumValues {
							// Create variations to check (e.g., "Kota_Depok" -> ["kota_depok", "depok", "kota depok"])
							cityVariations := []string{
								strings.ToLower(enumValue),
								strings.ToLower(strings.ReplaceAll(enumValue, "_", " ")),
							}

							// Extract city name from enum (e.g., "Kota_Depok" -> "depok")
							if strings.Contains(enumValue, "_") {
								parts := strings.Split(enumValue, "_")
								if len(parts) > 1 {
									cityName := strings.ToLower(parts[len(parts)-1])
									cityVariations = append(cityVariations, cityName)
								}
							}

							// Check if any variation is mentioned in reasoning
							for _, variation := range cityVariations {
								if strings.Contains(reasoningLower, variation) {
									reasoningContainsCity = enumValue
									break
								}
							}

							if reasoningContainsCity != "" {
								break
							}
						}
					}

					// Check if reasoning mentions a different city than extracted
					if reasoningContainsCity != "" && reasoningContainsCity != kotaStr {
						s.logger.With(ctx).Error("ðŸ—ºï¸ Detected geographical mapping contradiction - Reasoning mentions '%s' but extracted '%s'", reasoningContainsCity, kotaStr)
						s.logger.With(ctx).Error("ðŸ”§ REASONING TAKES PRIORITY: Correcting extracted city based on reasoning analysis")

						// Update the extracted data to match the reasoning
						result.ExtractedData["kota"] = reasoningContainsCity
						result.ValidationErrors = append(result.ValidationErrors, fmt.Sprintf("Geographical mapping corrected: reasoning indicated '%s' but extraction showed '%s' - reasoning takes priority", reasoningContainsCity, kotaStr))

						s.logger.With(ctx).Info("âœ… Corrected kota value from '%s' to '%s' based on reasoning analysis", kotaStr, reasoningContainsCity)
					}
				}
			}
		}
	}

	// Enhanced validation: Verify required fields are present
	if result.TriggerMet {
		requiredFieldsMissing := s.validateRequiredFields(fields, result.ExtractedData)
		if len(requiredFieldsMissing) > 0 {
			s.logger.With(ctx).Error("âš ï¸ Required fields missing: %v", requiredFieldsMissing)
			result.TriggerMet = false
			result.ValidationErrors = append(result.ValidationErrors, fmt.Sprintf("Missing required fields: %s", strings.Join(requiredFieldsMissing, ", ")))
		}
	}

	// Log the final validated result
	s.logger.With(ctx).Info("ðŸ¤– AI trigger evaluation final result:", fmt.Sprintf(`{"trigger_met": %t, "reasoning": "%s"}`, result.TriggerMet, result.Reasoning))
	s.logger.With(ctx).Info("ðŸ“Š Enhanced trigger evaluation result - Met:", result.TriggerMet, "Reasoning:", result.Reasoning)
	if len(result.FieldSources) > 0 {
		s.logger.With(ctx).Info("ðŸ” Field extraction sources:", result.FieldSources)
	}
	if result.Confidence != "" {
		s.logger.With(ctx).Info("ðŸŽ¯ Extraction confidence level:", result.Confidence)
	}
	if len(result.ValidationErrors) > 0 {
		s.logger.With(ctx).Info("âŒ Validation errors:", result.ValidationErrors)
	}
	if len(result.RiskFactors) > 0 {
		s.logger.With(ctx).Info("âš ï¸ Risk factors:", result.RiskFactors)
	}

	return result.TriggerMet, result.ExtractedData, nil
}

// validateRequiredFields checks if all required fields are present in extracted data
func (s *service) validateRequiredFields(fields []entity.CustomIntegrationField, extractedData map[string]interface{}) []string {
	var missingFields []string
	for _, field := range fields {
		if field.IsRequired {
			if value, exists := extractedData[field.FieldName]; !exists || value == nil || value == "" {
				missingFields = append(missingFields, field.FieldName)
			}
		}
	}
	return missingFields
}

// validateIntegrationData performs comprehensive validation before integration execution
func (s *service) validateIntegrationData(ctx context.Context, integration custom_integration.AIAgentIntegrationResponse, fields []entity.CustomIntegrationField, extractedData map[string]interface{}) error {
	s.logger.With(ctx).Info("ðŸ” Validating integration data for:", integration.IntegrationName)

	// Check if we have any meaningful data at all
	if len(extractedData) == 0 {
		s.logger.With(ctx).Error("âŒ No data extracted for integration:", integration.IntegrationName)
		return fmt.Errorf("no data extracted for integration execution")
	}

	// Count non-empty values
	nonEmptyCount := 0
	for fieldName, value := range extractedData {
		if value != nil && value != "" && value != "null" {
			// Additional check for string values that might be whitespace only
			if strVal, ok := value.(string); ok {
				if strings.TrimSpace(strVal) != "" {
					nonEmptyCount++
					s.logger.With(ctx).Info("âœ… Valid field data:", fieldName, "=", value)
				} else {
					s.logger.With(ctx).Info("âš ï¸ Empty/whitespace field:", fieldName)
				}
			} else {
				nonEmptyCount++
				s.logger.With(ctx).Info("âœ… Valid field data:", fieldName, "=", value)
			}
		} else {
			s.logger.With(ctx).Info("âš ï¸ Null/empty field:", fieldName, "=", value)
		}
	}

	// Require at least one meaningful field value
	if nonEmptyCount == 0 {
		s.logger.With(ctx).Error("âŒ All extracted data is null/empty for integration:", integration.IntegrationName)
		return fmt.Errorf("all extracted data is null or empty - integration execution blocked")
	}

	// Check required fields specifically
	missingRequired := s.validateRequiredFields(fields, extractedData)
	if len(missingRequired) > 0 {
		s.logger.With(ctx).Error("âŒ Missing required fields:", missingRequired, "for integration:", integration.IntegrationName)
		return fmt.Errorf("missing required fields: %s", strings.Join(missingRequired, ", "))
	}

	// For integrations with dependencies, ensure we have sufficient data quality
	if integration.DependsOnIntegration != nil {
		// More strict validation for dependent integrations
		requiredFieldCount := 0
		for _, field := range fields {
			if field.IsRequired {
				requiredFieldCount++
			}
		}

		// If this integration has required fields, ensure we have meaningful data for them
		if requiredFieldCount > 0 {
			validRequiredCount := 0
			for _, field := range fields {
				if field.IsRequired {
					if value, exists := extractedData[field.FieldName]; exists && value != nil && value != "" {
						if strVal, ok := value.(string); ok {
							if strings.TrimSpace(strVal) != "" {
								validRequiredCount++
							}
						} else {
							validRequiredCount++
						}
					}
				}
			}

			if validRequiredCount < requiredFieldCount {
				s.logger.With(ctx).Error("âŒ Insufficient valid required field data for dependent integration:", integration.IntegrationName, "Valid:", validRequiredCount, "Required:", requiredFieldCount)
				return fmt.Errorf("insufficient valid required field data for dependent integration - expected %d, got %d", requiredFieldCount, validRequiredCount)
			}
		}
	}

	s.logger.With(ctx).Info("âœ… Integration data validation passed for:", integration.IntegrationName, "Non-empty fields:", nonEmptyCount)
	return nil
}

// executeIntegration executes the custom integration API call with comprehensive logging and data validation
func (s *service) executeIntegration(ctx context.Context, integration custom_integration.AIAgentIntegrationResponse, extractedData map[string]interface{}, contactID *uuid.UUID) error {
	s.logger.With(ctx).Info("ðŸš€ Starting integration execution for:", integration.IntegrationName, "(ID:", integration.IDIntegration, ")")
	s.logger.With(ctx).Info("ðŸ“Š Request data:", extractedData)

	// Get integration fields to validate data completeness
	fields, err := s.customIntegrationService.GetCustomIntegrationFieldsByIntegrationID(ctx, integration.IDIntegration)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to get integration fields for validation:", err)
		return fmt.Errorf("failed to get integration fields: %w", err)
	}

	// Validate data completeness before execution
	if err := s.validateIntegrationData(ctx, integration, fields, extractedData); err != nil {
		s.logger.With(ctx).Error("âŒ Integration data validation failed:", integration.IntegrationName, "Error:", err)
		return fmt.Errorf("integration data validation failed: %w", err)
	}

	// Prepare the execution request
	executeReq := custom_integration.ExecuteIntegrationRequest{
		IDIntegration: integration.IDIntegration,
		IDAIAgent:     integration.IDAIAgent,
		IDContact:     contactID,
		FieldValues:   extractedData,
	}

	s.logger.With(ctx).Info("ðŸ“¤ Calling custom integration service ExecuteIntegration")
	s.logger.With(ctx).Info("ðŸ“‹ Integration ID:", executeReq.IDIntegration)
	s.logger.With(ctx).Info("ðŸ¤– AI Agent ID:", executeReq.IDAIAgent)
	if executeReq.IDContact != nil {
		s.logger.With(ctx).Info("ðŸ“ž Contact ID:", *executeReq.IDContact)
	} else {
		s.logger.With(ctx).Info("ðŸ“ž Contact ID: nil")
	}
	s.logger.With(ctx).Info("ðŸ“Š Field values:", executeReq.FieldValues)

	// Execute the integration
	executionResult, err := s.customIntegrationService.ExecuteIntegration(ctx, executeReq)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Integration execution failed:", err)
		s.logger.With(ctx).Error("âŒ Failed integration:", integration.IntegrationName, "(ID:", integration.IDIntegration, ")")
		return fmt.Errorf("integration execution failed: %w", err)
	}

	// Log successful execution details
	s.logger.With(ctx).Info("âœ… Integration executed successfully:", integration.IntegrationName)
	s.logger.With(ctx).Info("ðŸ“‹ Execution log ID:", executionResult.ID)
	s.logger.With(ctx).Info("âœ… Success status:", executionResult.Success)
	if executionResult.StatusCode != nil {
		s.logger.With(ctx).Info("ðŸ“Š HTTP status code:", *executionResult.StatusCode)
	}
	if executionResult.ExecutionDurationMs != nil {
		s.logger.With(ctx).Info("â±ï¸ Execution duration:", *executionResult.ExecutionDurationMs, "ms")
	}

	// Log request and response details
	if executionResult.RequestBody != nil {
		s.logger.With(ctx).Info("ðŸ“¤ Request body:", *executionResult.RequestBody)
	}
	if executionResult.ResponseBody != nil {
		s.logger.With(ctx).Info("ðŸ“¥ Response body:", *executionResult.ResponseBody)
	}
	if executionResult.ErrorMessage != nil {
		s.logger.With(ctx).Info("âš ï¸ Error message:", *executionResult.ErrorMessage)
	}

	// Log data processing status
	if executionResult.Success {
		s.logger.With(ctx).Info("âœ… Integration data processed successfully and loaded to AI context")
		s.logger.With(ctx).Info("ðŸ“Š Integration response data is now available for future AI interactions")
	} else {
		s.logger.With(ctx).Error("âŒ Integration execution completed but marked as unsuccessful")
		s.logger.With(ctx).Error("âŒ Data processing failed - response not loaded to AI context")
	}

	return nil
}

// preProcessCustomIntegrations evaluates and executes custom integrations before AI response generation
// Returns integration results that can be included in the AI context
func (s *service) preProcessCustomIntegrations(ctx context.Context, db *dbcontext.DB, agentID uuid.UUID, userMessage, phoneNumber, sessionID string) (map[string]interface{}, error) {
	// Load custom integrations for the AI agent
	s.logger.With(ctx).Info("ðŸ” Pre-processing custom integrations for agent:", agentID)
	integrations, err := s.customIntegrationService.GetAIAgentIntegrationsByAgentID(ctx, agentID)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to load custom integrations for agent:", agentID, "Error:", err)
		return nil, fmt.Errorf("failed to load custom integrations: %w", err)
	}

	if len(integrations) == 0 {
		s.logger.With(ctx).Info("ðŸ“‹ No custom integrations found for agent:", agentID)
		return nil, nil
	}

	s.logger.With(ctx).Info("âœ… Successfully loaded", len(integrations), "custom integrations for agent:", agentID)

	// Get or create enhanced session for field state tracking
	enhancedSession := s.getOrCreateEnhancedSession(sessionID)
	enhancedSession.LastAI2Evaluation = time.Now()

	integrationResults := make(map[string]interface{})

	// Process each integration with enhanced field state tracking
	for _, integration := range integrations {
		if !integration.IsEnabled {
			s.logger.With(ctx).Info("â­ï¸ Skipping disabled integration:", integration.IntegrationName, "(ID:", integration.IDIntegration, ")")
			continue
		}

		if integration.TriggerCondition == nil || *integration.TriggerCondition == "" {
			s.logger.With(ctx).Info("â­ï¸ Skipping integration with no trigger condition:", integration.IntegrationName, "(ID:", integration.IDIntegration, ")")
			continue
		}

		// Check dependencies before processing
		if integration.DependsOnIntegration != nil {
			dependencyMet := s.checkIntegrationDependency(ctx, *integration.DependsOnIntegration, integration.RequiresSuccess, integrationResults, integrations)
			if !dependencyMet {
				s.logger.With(ctx).Info("â­ï¸ Skipping integration due to unmet dependency:", integration.IntegrationName, "(ID:", integration.IDIntegration, ")")
				continue
			}
		}

		// Check if integration was recently triggered to prevent redundant execution
		// Use configurable cooldown period per integration (0 = no cooldown)
		// MODIFIED: Only skip if the last execution was successful (skip-on-success logic)
		integrationKey := integration.IDIntegration.String()
		if state, exists := enhancedSession.IntegrationStatus[integrationKey]; exists {
			if integration.CooldownMinutes > 0 && state.LastTriggered != nil && time.Since(*state.LastTriggered) < time.Duration(integration.CooldownMinutes)*time.Minute {
				// Check if the last execution was successful
				lastExecutionSuccessful := false
				if state.LastResult != nil {
					if success, ok := state.LastResult["success"].(bool); ok && success {
						lastExecutionSuccessful = true
					}
				}

				// Only skip if the last execution was successful
				if lastExecutionSuccessful {
					s.logger.With(ctx).Info("â­ï¸ Skipping recently triggered integration (last execution successful):", integration.IntegrationName, "(last triggered:", state.LastTriggered.Format(time.RFC3339), ", cooldown:", integration.CooldownMinutes, "minutes)")
					continue
				} else {
					s.logger.With(ctx).Info("ðŸ”„ Retrying integration (last execution failed):", integration.IntegrationName, "(last triggered:", state.LastTriggered.Format(time.RFC3339), ", cooldown:", integration.CooldownMinutes, "minutes)")
				}
			}
		}

		s.logger.With(ctx).Info("ðŸ” Pre-evaluating trigger condition for integration:", integration.IntegrationName, "(ID:", integration.IDIntegration, ")")
		s.logger.With(ctx).Info("ðŸ“‹ Trigger condition:", *integration.TriggerCondition)

		// Get integration fields for field state tracking
		fields, err := s.customIntegrationService.GetCustomIntegrationFieldsByIntegrationID(ctx, integration.IDIntegration)
		if err != nil {
			s.logger.With(ctx).Error("âŒ Failed to get integration fields:", integration.IntegrationName, "Error:", err)
			continue
		}

		// Check field state and determine missing fields
		missingFields := s.checkMissingFields(enhancedSession, fields)
		readyToTrigger := len(missingFields) == 0

		// Update integration state
		s.updateIntegrationState(sessionID, integration.IDIntegration, integration.IntegrationName, readyToTrigger, missingFields)

		// Evaluate if trigger condition is met using AI analysis with enhanced field context
		triggerMet, extractedData, _, err := s.evaluateTriggerConditionPreProcessEnhanced(ctx, *integration.TriggerCondition, userMessage, sessionID, integration.IDIntegration, enhancedSession)
		if err != nil {
			s.logger.With(ctx).Error("âŒ Failed to evaluate trigger condition for integration:", integration.IntegrationName, "Error:", err)
			continue
		}

		// Update field state with newly extracted data
		for fieldName, value := range extractedData {
			if value != nil && value != "" {
				s.updateFieldState(sessionID, fieldName, value, "AI2_extraction", 0.8)
			}
		}

		if !triggerMet {
			s.logger.With(ctx).Info("âŒ Trigger condition NOT met for integration:", integration.IntegrationName, "(ID:", integration.IDIntegration, ")")
			continue
		}

		// ðŸŽ¯ CUSTOM INTEGRATION SUCCESSFULLY TRIGGERED (PRE-PROCESS)
		s.logger.With(ctx).Info("ðŸŽ¯ ===== CUSTOM INTEGRATION TRIGGERED (PRE-PROCESS) =====")
		s.logger.With(ctx).Info("ðŸŽ¯ Integration Name:", integration.IntegrationName)
		s.logger.With(ctx).Info("ðŸŽ¯ Integration ID:", integration.IDIntegration)
		s.logger.With(ctx).Info("ðŸŽ¯ Trigger Condition:", *integration.TriggerCondition)
		s.logger.With(ctx).Info("ðŸŽ¯ User Message:", userMessage)
		s.logger.With(ctx).Info("ðŸŽ¯ Session ID:", sessionID)
		s.logger.With(ctx).Info("ðŸŽ¯ Phone Number:", phoneNumber)
		s.logger.With(ctx).Info("ðŸŽ¯ Extracted Data:", extractedData)
		s.logger.With(ctx).Info("ðŸŽ¯ =======================================================")

		// Get contact ID if phone number is provided
		var contactID *uuid.UUID
		if phoneNumber != "" {
			contact, err := s.contactService.GetContactByIdentifier(ctx, phoneNumber)
			if err == nil {
				contactID = &contact.ID
				s.logger.With(ctx).Info("ðŸ“ž Found contact ID for phone number:", phoneNumber, "Contact ID:", contact.ID)
			} else {
				s.logger.With(ctx).Info("âš ï¸ Could not find contact for phone number:", phoneNumber, "Error:", err)
			}
		}

		// Execute the integration and capture the result
		executionResult, err := s.executeIntegrationWithResult(ctx, integration, extractedData, contactID)
		if err != nil {
			s.logger.With(ctx).Error("âŒ Failed to execute integration:", integration.IntegrationName, "Error:", err)
			// Store the failed integration result for AI context
			failureData := map[string]interface{}{
				"success":       false,
				"error":         err.Error(),
				"extractedData": extractedData,
			}
			integrationResults[integration.IntegrationName] = failureData
			s.logger.With(ctx).Info("ðŸ’¾ Stored failed integration result for:", integration.IntegrationName, "Data:", failureData)
			continue
		}

		s.logger.With(ctx).Info("âœ… Successfully executed integration:", integration.IntegrationName, "(ID:", integration.IDIntegration, ")")

		// Store the successful integration result for AI context
		// Dereference the ResponseBody pointer to store the actual string value
		var responseBodyValue interface{}
		if executionResult.ResponseBody != nil {
			responseBodyValue = *executionResult.ResponseBody
		}

		resultData := map[string]interface{}{
			"success":       executionResult.Success,
			"responseBody":  responseBodyValue,
			"extractedData": extractedData,
		}
		integrationResults[integration.IntegrationName] = resultData
		s.logger.With(ctx).Info("ðŸ’¾ Stored integration result for:", integration.IntegrationName, "Data:", resultData)

		// CRITICAL FIX: Mark integration as triggered in session state
		// This ensures the integration results are persisted and available for future AI interactions
		s.markIntegrationTriggered(sessionID, integration.IDIntegration, resultData)
		s.logger.With(ctx).Info("ðŸ”„ Marked integration as triggered in session state:", integration.IntegrationName)
	}

	s.logger.With(ctx).Info("ðŸŽ¯ Pre-processing complete. Final integration results:", integrationResults)
	s.logger.With(ctx).Info("ðŸ“Š Total integrations processed:", len(integrationResults))
	return integrationResults, nil
}

// evaluateTriggerConditionPreProcess evaluates trigger condition without AI response (for pre-processing)
// Returns: triggerMet, extractedData, clarificationSuggestion, error
func (s *service) evaluateTriggerConditionPreProcess(ctx context.Context, triggerCondition, userMessage, sessionID string, integrationID uuid.UUID) (bool, map[string]interface{}, string, error) {
	// Get integration details
	integrationEntity, err := s.customIntegrationService.GetCustomIntegrationByID(ctx, integrationID)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to get integration details:", err)
		return false, nil, "", fmt.Errorf("failed to get integration details: %w", err)
	}

	// Get integration fields to understand what data to extract
	fields, err := s.customIntegrationService.GetCustomIntegrationFieldsByIntegrationID(ctx, integrationID)

	// Build field descriptions for AI analysis
	fieldDescriptions := make([]string, 0, len(fields))
	for _, field := range fields {
		desc := fmt.Sprintf("%s (%s)", field.FieldName, field.FieldType)
		if field.Description != nil {
			desc += ": " + *field.Description
		}
		if field.FieldType == "enum" && field.EnumValues != nil {
			desc += " [Options: " + *field.EnumValues + "]"
		}
		if field.IsRequired {
			desc += " (Required)"
		}
		fieldDescriptions = append(fieldDescriptions, desc)
	}

	// Retrieve conversation history from session AND include current message context
	var conversationHistory []OpenAIMessage
	if history, exists := s.sessions.Load(sessionID); exists {
		if historyMessages, ok := history.([]OpenAIMessage); ok {
			conversationHistory = historyMessages
		}
	}

	// CRITICAL FIX: Include the current user message in the conversation context
	// This ensures the AI has access to the complete conversation including the current trigger message
	if userMessage != "" {
		currentMessage := OpenAIMessage{
			Role:    "user",
			Content: userMessage,
		}
		conversationHistory = append(conversationHistory, currentMessage)
		s.logger.With(ctx).Info("ðŸ”„ Added current user message to conversation context for trigger evaluation")
	}

	// Build conversation context for field extraction
	conversationContext := ""
	if len(conversationHistory) > 0 {
		conversationContext = "\n\nCOMPLETE CONVERSATION HISTORY (including current message):\n"
		for i, msg := range conversationHistory {
			if msg.Role == "user" {
				conversationContext += fmt.Sprintf("User Message %d: %s\n", i+1, msg.Content)
			} else if msg.Role == "assistant" {
				conversationContext += fmt.Sprintf("AI Response %d: %s\n", i+1, msg.Content)
			}
		}
		s.logger.With(ctx).Info("ðŸ“ Built conversation context with", len(conversationHistory), "messages for trigger evaluation")
	} else {
		s.logger.With(ctx).Info("âš ï¸ No conversation history available for trigger evaluation")
	}

	// Build comprehensive field analysis for better extraction
	requiredFields := make([]string, 0)
	optionalFields := make([]string, 0)
	for _, field := range fields {
		if field.IsRequired {
			requiredFields = append(requiredFields, field.FieldName)
		} else {
			optionalFields = append(optionalFields, field.FieldName)
		}
	}

	// Build field formatting rules dynamically based on actual field configurations
	// Use field descriptions as behavior guides for AI 2 to format field values properly
	fieldFormattingRules := make([]string, 0)

	for _, field := range fields {
		if field.FieldType == "enum" && field.EnumValues != nil {
			// Parse enum values
			enumOptions := strings.Split(*field.EnumValues, ",")
			for i, option := range enumOptions {
				enumOptions[i] = strings.TrimSpace(option)
			}

			// Enhanced enum field rule with intelligent matching
			rule := fmt.Sprintf("   - For %s field: Use intelligent fuzzy matching to find the best match from available enum options [%s].", field.FieldName, strings.Join(enumOptions, ", "))

			// CRITICAL: Use field description as formatting behavior guide for AI 2
			if field.Description != nil && *field.Description != "" {
				rule += fmt.Sprintf(" FORMATTING BEHAVIOR: %s", *field.Description)
				// Log the formatting behavior for debugging
				s.logger.With(ctx).Info("ðŸŽ¯ Field formatting behavior for", field.FieldName, ":", *field.Description)
			} else {
				rule += " If uncertain or no close match found, return to main AI with clarificationSuggestion asking user to choose from available options."
			}

			fieldFormattingRules = append(fieldFormattingRules, rule)

		} else if field.FieldType != "enum" {
			// Add rules for non-enum fields with description-based behavior
			var fieldRule string
			switch field.FieldType {
			case "text":
				fieldRule = fmt.Sprintf("   - For %s field: Extract relevant text information from user message", field.FieldName)
			case "email":
				fieldRule = fmt.Sprintf("   - For %s field: Extract valid email address from user message", field.FieldName)
			case "number":
				fieldRule = fmt.Sprintf("   - For %s field: Extract numeric value from user message", field.FieldName)
			case "boolean":
				fieldRule = fmt.Sprintf("   - For %s field: Determine true/false based on user intent", field.FieldName)
			case "date":
				fieldRule = fmt.Sprintf("   - For %s field: Extract date information in YYYY-MM-DD format", field.FieldName)
			case "url":
				fieldRule = fmt.Sprintf("   - For %s field: Extract valid URL from user message", field.FieldName)
			default:
				fieldRule = fmt.Sprintf("   - For %s field: Extract relevant information from user message", field.FieldName)
			}

			// CRITICAL: Use field description as formatting behavior guide for AI 2
			if field.Description != nil && *field.Description != "" {
				fieldRule += fmt.Sprintf(" FORMATTING BEHAVIOR: %s", *field.Description)
				// Log the formatting behavior for debugging
				s.logger.With(ctx).Info("ðŸŽ¯ Field formatting behavior for", field.FieldName, ":", *field.Description)
			}

			fieldFormattingRules = append(fieldFormattingRules, fieldRule)
		}
	}

	// Build webhook payload structure information for better field validation
	webhookPayloadInfo := s.buildWebhookPayloadStructure(integrationEntity, fields)

	// Add current date context for accurate date processing
	currentTime := time.Now()
	dateContext := fmt.Sprintf(`

=== CURRENT DATE CONTEXT ===
Today's date: %s
Current year: %d
Current month: %02d
Current day: %02d

IMPORTANT DATE FORMATTING RULES:
- When user says 'tanggal 18' format it as: %d-%02d-18
- When user says '18 agustus' format it as: %d-08-18
- When user says 'besok' (tomorrow) format it as: %s
- When user says 'lusa' (day after tomorrow) format it as: %s
- Always use the current year (%d) unless explicitly specified otherwise
- For relative dates like 'besok' or 'lusa', calculate from today's date`,
		currentTime.Format("2006-01-02"),
		currentTime.Year(),
		int(currentTime.Month()),
		currentTime.Day(),
		currentTime.Year(),
		int(currentTime.Month()),
		currentTime.Year(),
		currentTime.AddDate(0, 0, 1).Format("2006-01-02"),
		currentTime.AddDate(0, 0, 2).Format("2006-01-02"),
		currentTime.Year())

	// Create enhanced AI prompt for intelligent field extraction with complete integration context
	prompt := fmt.Sprintf(`You are an advanced data extraction and conversation analysis system. Your task is to intelligently analyze the COMPLETE conversation history (including the current message) to determine if the integration trigger condition is met.%s

=== COMPLETE INTEGRATION CONFIGURATION ===
Integration Name: %s
Integration ID: %s
Trigger Condition: %s
Webhook URL: %s
HTTP Method: %s
Content Type: %s
Timeout: %d seconds
Integration Description: %s

=== WEBHOOK PAYLOAD STRUCTURE ===
%s

=== INTEGRATION CONTEXT UNDERSTANDING ===
- This integration will send data to the webhook endpoint using %s method
- For GET requests: Field values become URL query parameters (?field1=value1&field2=value2)
- For POST requests: Field values become JSON body payload {"field1": "value1", "field2": "value2"}
- All field values must be properly validated and formatted before webhook execution
- Required fields are MANDATORY for successful webhook call
- Optional fields enhance the webhook payload when available
- Field descriptions provide formatting and validation guidance

=== COMPLETE CONVERSATION ANALYSIS ===%s

=== REQUIRED FIELDS FOR INTEGRATION ===
%s

=== FIELD EXTRACTION STRATEGY ===
Required Fields: [%s]
Optional Fields: [%s]

=== ENHANCED ANALYSIS INSTRUCTIONS ===

1. CURRENT MESSAGE PRIORITY ANALYSIS:
   - PRIORITIZE the current user message for trigger evaluation
   - If the current message contains clear intent or new information, focus on that
   - Reference conversation history for context when needed
   - Avoid being overly influenced by previous negative responses or unavailable items
   - Focus on what the user is asking for NOW, not what was discussed before

2. INTELLIGENT FIELD MATCHING:
   - For names: Look for introductions, signatures, mentions like "saya [name]", "nama saya [name]"
   - For emails: Look for email addresses, contact sharing, "email saya [email]"
   - For phone numbers: Look for phone sharing, "nomor saya [phone]", contact details
   - For addresses: Look for location mentions, delivery addresses, "alamat saya [address]"
   - For services: Look for service requests, inquiries, "saya butuh [service]"
   - For locations: Use comprehensive geographical intelligence to map ANY location mention to the correct parent city (e.g., Sawangan â†’ Depok, Kemang â†’ Jakarta Selatan, Rajeg â†’ Tangerang, Serpong â†’ Tangerang Selatan)
	   - For text fields: Extract relevant information based on field name and context
%s
	   - PARTICLE RECOGNITION: Ignore Indonesian conversational particles (min, kak, ya, nih, dong, sih) when extracting data
	   - GEOGRAPHICAL INTELLIGENCE: Apply comprehensive knowledge of Indonesian administrative geography:
	     * Understand district (kecamatan) to city relationships across all major Indonesian cities
	     * Recognize sub-districts (kelurahan/desa) and map them to their parent cities
	     * Identify popular areas, neighborhoods, and landmarks within cities
	     * Handle multi-word location names and variations (e.g., 'Jakarta Barat', 'Tangerang Selatan')
	     * Apply hierarchical mapping: Specific Location â†’ District â†’ City â†’ Province
	     * Use contextual clues when location names are ambiguous (consider surrounding context)

3. CONTEXTUAL TRIGGER EVALUATION:
   - FOCUS on the current message intent and context
   - If the current message contains a new request or inquiry, evaluate it independently
   - Previous unavailable items or negative responses should NOT prevent new valid requests
   - Use conversation history for context about the CURRENT request
   - Reset evaluation context when user asks about different items or services
   - IMPORTANT: Each new user message should be evaluated on its own merit

4. TRIGGER EVALUATION LOGIC:
   - PRIORITIZE extracting fields from the current user message
   - Set trigger_met = true if ALL required fields can be found (current message + conversation history as backup)
   - If the current message shows clear intent for a new request, evaluate it independently
   - Don't let previous negative responses block new valid requests
   - Use conversation history for context about the CURRENT request
   - Include field sources to show where each value was found, prioritizing current message

5. NATURAL CONVERSATION FLOW RECOGNITION:
   - Treat each new user message as a potential fresh start
   - When users ask about new items/services, evaluate independently from previous requests
   - Previous unavailable items should NOT influence evaluation of new requests
   - Use conversation history for context about the CURRENT request
   - Focus on the user's CURRENT intent rather than past conversation context

Respond ONLY with a JSON object:
{
  "trigger_met": true/false,
  "extracted_data": {
    "field_name": "extracted_value",
    ...
  },
  "field_sources": {
    "field_name": "source description (e.g., 'User Message 3', 'AI Response 2')",
    ...
  },
  "reasoning": "detailed explanation of analysis and decision, including which messages contained the required fields"
}

CRITICAL RULES:
- This is INTERNAL PROCESSING - do NOT generate user-facing responses
- ONLY output the JSON object above
- PRIORITIZE the current user message for trigger evaluation
- Previous negative responses or unavailable items should NOT block new valid requests
- For enum fields, follow the specific formatting rules above for each field
- NEVER assume field values not explicitly mentioned in the conversation
- Focus on the user's CURRENT intent and request, not past conversation context
- Use conversation history for context about the CURRENT request
- DYNAMIC FIELD HANDLING: Apply appropriate formatting rules based on field type and configuration`,
		dateContext,
		integrationEntity.Name,
		integrationEntity.ID,
		triggerCondition,
		integrationEntity.WebhookURL,
		integrationEntity.HTTPMethod,
		integrationEntity.ContentType,
		integrationEntity.TimeoutSeconds,
		integrationEntity.Description,
		webhookPayloadInfo,
		integrationEntity.HTTPMethod,
		conversationContext,
		strings.Join(fieldDescriptions, "\n"),
		strings.Join(requiredFields, ", "),
		strings.Join(optionalFields, ", "),
		strings.Join(fieldFormattingRules, "\n"))

	s.logger.With(ctx).Info("ðŸ¤– Sending pre-process trigger evaluation prompt to AI")

	// Call OpenAI for trigger evaluation
	messages := []OpenAIMessage{
		{
			Role:    "system",
			Content: "You are a data extraction system for internal processing. Your ONLY job is to analyze text and return JSON data. You MUST NOT generate any user-facing responses, conversational text, or waiting messages like 'tunggu saya cek'. ONLY return the requested JSON object.",
		},
		{
			Role:    "user",
			Content: prompt,
		},
	}

	// Use a powerful model for comprehensive trigger evaluation and conversation analysis
	settings := &entity.AISettings{
		Model: "gpt-4.1-nano",
	}

	// Get token tracker from context or create a new one for tracking this evaluation
	tokenTracker := accesslog.GetTokenTrackerFromContext(ctx)
	if tokenTracker == nil {
		requestID := uuid.New().String()
		tokenTracker = accesslog.NewTokenTracker(requestID)
		s.logger.With(ctx).Infof("ðŸ”¢ Created token tracker for trigger evaluation preprocess: %s", requestID)
	}

	resp, err := s.callOpenAI(ctx, messages, settings, "trigger evaluation", len(prompt), tokenTracker, "trigger_evaluation_preprocess")

	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to call OpenAI for trigger evaluation:", err)
		return false, nil, "", fmt.Errorf("failed to evaluate trigger condition: %w", err)
	}

	// Log AI usage for trigger evaluation preprocessing (specific operation, separate from main conversation flow)
	s.logAIUsage(ctx, settings.Model, resp.Usage.TotalTokens, "trigger_evaluation_preprocess", sessionID, uuid.Nil, "", "internal")

	// NOTE: Model usage tracking is handled by the main conversation flow to avoid double tracking

	if len(resp.Choices) == 0 {
		s.logger.With(ctx).Error("âŒ No response from OpenAI for trigger evaluation")
		return false, nil, "", fmt.Errorf("no response from OpenAI")
	}

	responseContent := resp.Choices[0].Message.Content
	s.logger.With(ctx).Info("ðŸ¤– AI pre-process trigger evaluation response:", responseContent)

	// Clean and validate the response content
	responseContent = strings.TrimSpace(responseContent)

	// Log response length and first/last characters for debugging
	s.logger.With(ctx).Info("ðŸ“ Response length:", len(responseContent))
	if len(responseContent) > 0 {
		s.logger.With(ctx).Info("ðŸ” First 50 chars:", responseContent[:min(50, len(responseContent))])
		s.logger.With(ctx).Info("ðŸ” Last 50 chars:", responseContent[max(0, len(responseContent)-50):])
	}

	// Validate JSON structure before unmarshaling
	if !json.Valid([]byte(responseContent)) {
		s.logger.With(ctx).Error("âŒ Invalid JSON structure detected, attempting to extract JSON from response")

		// Try to extract JSON from the response if it's wrapped in other text
		jsonStart := strings.Index(responseContent, "{")
		jsonEnd := strings.LastIndex(responseContent, "}")

		if jsonStart != -1 && jsonEnd != -1 && jsonEnd > jsonStart {
			extractedJSON := responseContent[jsonStart : jsonEnd+1]
			if json.Valid([]byte(extractedJSON)) {
				s.logger.With(ctx).Info("âœ… Successfully extracted valid JSON from response")
				responseContent = extractedJSON
			} else {
				s.logger.With(ctx).Error("âŒ Extracted JSON is still invalid")
				return false, nil, "", fmt.Errorf("invalid JSON structure in AI response")
			}
		} else {
			s.logger.With(ctx).Error("âŒ No JSON structure found in response")
			return false, nil, "", fmt.Errorf("no valid JSON found in AI response")
		}
	}

	// Parse the enhanced JSON response with field sources and confidence tracking
	var result struct {
		TriggerMet    bool                   `json:"trigger_met"`
		ExtractedData map[string]interface{} `json:"extracted_data"`
		FieldSources  map[string]string      `json:"field_sources"`
		Reasoning     string                 `json:"reasoning"`
		Confidence    string                 `json:"confidence,omitempty"`
	}

	err = json.Unmarshal([]byte(responseContent), &result)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to parse AI response JSON:", err, "Response:", responseContent)
		s.logger.With(ctx).Error("ðŸ“Š Response bytes:", []byte(responseContent))

		// Try to create a fallback response structure
		s.logger.With(ctx).Error("ðŸ”„ Creating fallback response structure")
		result = struct {
			TriggerMet    bool                   `json:"trigger_met"`
			ExtractedData map[string]interface{} `json:"extracted_data"`
			FieldSources  map[string]string      `json:"field_sources"`
			Reasoning     string                 `json:"reasoning"`
			Confidence    string                 `json:"confidence,omitempty"`
		}{
			TriggerMet:    false,
			ExtractedData: make(map[string]interface{}),
			FieldSources:  make(map[string]string),
			Reasoning:     "Failed to parse AI response JSON: " + err.Error(),
			Confidence:    "low",
		}
		s.logger.With(ctx).Info("âœ… Using fallback response structure")
	}

	s.logger.With(ctx).Info("ðŸ“Š Enhanced trigger evaluation result - Met:", result.TriggerMet, "Reasoning:", result.Reasoning)
	if len(result.FieldSources) > 0 {
		s.logger.With(ctx).Info("ðŸ” Field extraction sources:", result.FieldSources)
	}
	if result.Confidence != "" {
		s.logger.With(ctx).Info("ðŸŽ¯ Extraction confidence level:", result.Confidence)
	}

	// Extract clarification suggestion from reasoning if present
	clarificationSuggestion := ""
	if !result.TriggerMet {
		if strings.Contains(result.Reasoning, "unclear mapping") {
			// Check if this is an uncertain mapping
			if strings.Contains(result.Reasoning, "Suggest asking for clarification") {
				// Generate a generic clarification request
				clarificationSuggestion = "Bisa diperjelas maksudnya?"
				s.logger.With(ctx).Info("ðŸ’¬ Generic clarification suggestion generated:", clarificationSuggestion)
			}
		} else if strings.Contains(result.Reasoning, "not supported in available options") || strings.Contains(result.Reasoning, "not listed among the supported options") {
			// This is an unsupported location/value - generate clarification to ask for supported alternatives
			clarificationSuggestion = "Maaf, lokasi tersebut belum tersedia dalam jangkauan layanan kami. Bisa coba lokasi lain?"
			s.logger.With(ctx).Info("ðŸš« Unsupported location detected, clarification suggestion generated:", clarificationSuggestion)
		}
	}

	return result.TriggerMet, result.ExtractedData, clarificationSuggestion, nil
}

// executeIntegrationWithResult executes the custom integration and returns the result
func (s *service) executeIntegrationWithResult(ctx context.Context, integration custom_integration.AIAgentIntegrationResponse, extractedData map[string]interface{}, contactID *uuid.UUID) (*custom_integration.IntegrationExecutionLogResponse, error) {
	s.logger.With(ctx).Info("ðŸš€ Starting integration execution with result capture for:", integration.IntegrationName, "(ID:", integration.IDIntegration, ")")
	s.logger.With(ctx).Info("ðŸ“Š Request data:", extractedData)

	// Prepare the execution request
	executeReq := custom_integration.ExecuteIntegrationRequest{
		IDIntegration: integration.IDIntegration,
		IDAIAgent:     integration.IDAIAgent,
		IDContact:     contactID,
		FieldValues:   extractedData,
	}

	s.logger.With(ctx).Info("ðŸ“¤ Calling custom integration service ExecuteIntegration")

	// Execute the integration
	executionResult, err := s.customIntegrationService.ExecuteIntegration(ctx, executeReq)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Integration execution failed:", err)
		return nil, fmt.Errorf("integration execution failed: %w", err)
	}

	// Log successful execution details
	s.logger.With(ctx).Info("âœ… Integration executed successfully:", integration.IntegrationName)
	s.logger.With(ctx).Info("ðŸ“‹ Execution log ID:", executionResult.ID)
	s.logger.With(ctx).Info("âœ… Success status:", executionResult.Success)
	if executionResult.ResponseBody != nil {
		s.logger.With(ctx).Info("ðŸ“¥ Response body:", *executionResult.ResponseBody)
	}

	return &executionResult, nil
}

// buildWebhookPayloadStructure creates a description of the webhook payload structure
func (s *service) buildWebhookPayloadStructure(integration custom_integration.CustomIntegrationResponse, fields []entity.CustomIntegrationField) string {
	if len(fields) == 0 {
		return "No fields configured for this integration."
	}

	var structure strings.Builder
	structure.WriteString("Expected webhook payload structure:\n")

	if integration.HTTPMethod == "GET" {
		structure.WriteString("Query Parameters:\n")
		for _, field := range fields {
			structure.WriteString(fmt.Sprintf("  - %s (%s)", field.FieldName, field.FieldType))
			if field.IsRequired {
				structure.WriteString(" [Required]")
			}
			if field.Description != nil {
				structure.WriteString(fmt.Sprintf(": %s", *field.Description))
			}
			structure.WriteString("\n")
		}
	} else {
		structure.WriteString("JSON Body Structure:\n{\n")
		for i, field := range fields {
			structure.WriteString(fmt.Sprintf(`  "%s": "<%s>"`, field.FieldName, field.FieldType))
			if field.IsRequired {
				structure.WriteString(" // Required")
			}
			if field.Description != nil {
				structure.WriteString(fmt.Sprintf(" // %s", *field.Description))
			}
			if i < len(fields)-1 {
				structure.WriteString(",")
			}
			structure.WriteString("\n")
		}
		structure.WriteString("}")
	}

	return structure.String()
}

// validateAIResponseAgainstIntegration validates that AI response aligns with integration results
// Updated to be more intelligent about validation and avoid false positives
func (s *service) validateAIResponseAgainstIntegration(ctx context.Context, aiResponse string, integrationResults map[string]interface{}) bool {
	if len(integrationResults) == 0 {
		return true // No integration results to validate against
	}

	aiResponseLower := strings.ToLower(aiResponse)

	// More nuanced detection of positive responses - only flag clear contradictions
	hasStrongPositiveResponse := (strings.Contains(aiResponseLower, "yay") || strings.Contains(aiResponseLower, "mantap")) &&
		(strings.Contains(aiResponseLower, "tersedia") || strings.Contains(aiResponseLower, "available") || strings.Contains(aiResponseLower, "covered"))

	for integrationName, result := range integrationResults {
		if resultMap, ok := result.(map[string]interface{}); ok {
			// Check if integration was successful first
			if success, exists := resultMap["success"]; exists {
				if successBool, ok := success.(bool); ok && !successBool {
					// If integration failed, don't validate against response body
					s.logger.With(ctx).Info("âš ï¸ Skipping validation for failed integration:", integrationName)
					continue
				}
			}

			if responseBody, exists := resultMap["responseBody"]; exists && responseBody != nil {
				var responseContent string
				if responseStr, ok := responseBody.(*string); ok && responseStr != nil {
					responseContent = strings.ToLower(*responseStr)
				} else if responseStr, ok := responseBody.(string); ok {
					responseContent = strings.ToLower(responseStr)
				} else {
					continue // Skip if we can't get string content
				}

				// More specific detection of negative integration responses
				isStrongNegativeIntegrationResponse := (strings.Contains(responseContent, "tidak terover") || strings.Contains(responseContent, "not covered")) &&
					!strings.Contains(responseContent, "tersedia") && !strings.Contains(responseContent, "available")

				// Only flag clear contradictions where AI strongly affirms availability despite clear negative integration response
				if isStrongNegativeIntegrationResponse && hasStrongPositiveResponse {
					s.logger.With(ctx).Error("âš ï¸ POTENTIAL CONTRADICTION: AI gave strong positive response despite negative integration result")
					s.logger.With(ctx).Error("âš ï¸ Integration:", integrationName, "Response:", responseContent)
					s.logger.With(ctx).Error("âš ï¸ AI Response:", aiResponse)
					// Log as warning but don't fail validation - let AI handle the context appropriately
					// The AI should be able to interpret integration results and respond accordingly
				}
			}
		}
	}

	return true // Always return true - let AI handle integration results contextually
}

// buildOpenAIMessagesWithoutIntegrationTriggers creates OpenAI messages without integration trigger conditions
// This is used when we already have integration results to avoid confusion
func (s *service) buildOpenAIMessagesWithoutIntegrationTriggers(ctx context.Context, settings *entity.AISettings, specificKnowledge string, userMessage string, sessionID string, leadContext string, agentID string) []OpenAIMessage {
	// Build system content without integration trigger conditions
	systemContent := s.buildOptimizedSystemContentWithoutIntegrations(ctx, settings, specificKnowledge, userMessage, leadContext)

	// Create system message
	messages := []OpenAIMessage{
		{
			Role:    "system",
			Content: systemContent,
		},
	}

	// Add conversation history if session ID is provided
	if sessionID != "" {
		if history, exists := s.sessions.Load(sessionID); exists {
			if historyMessages, ok := history.([]OpenAIMessage); ok {
				// Add conversation history (limit to avoid token overflow)
				maxHistory := 10
				startIdx := len(historyMessages) - maxHistory
				if startIdx < 0 {
					startIdx = 0
				}
				messages = append(messages, historyMessages[startIdx:]...)
			}
		}
	}

	// Add current user message
	messages = append(messages, OpenAIMessage{
		Role:    "user",
		Content: userMessage,
	})

	// Apply behavior reinforcement for long conversations
	messages = s.reinforceBehaviorConsistency(messages, settings)

	return messages
}

// buildOptimizedSystemContentWithoutIntegrations creates system content without integration trigger conditions
// Now uses session-based behavior caching to dramatically reduce token usage
func (s *service) buildOptimizedSystemContentWithoutIntegrations(ctx context.Context, settings *entity.AISettings, specificKnowledge string, userMessage string, leadContext string) string {
	// Analyze message complexity to determine optimization level
	complexity := s.analyzeMessageComplexity(userMessage)
	s.logger.Info("ðŸ§  Message complexity analysis:", complexity)

	// Extract session ID from context for session-based caching
	sessionID := ""
	if sessionValue := ctx.Value("sessionID"); sessionValue != nil {
		if sessionStr, ok := sessionValue.(string); ok {
			sessionID = sessionStr
		}
	}

	// Use session-based behavior caching for MASSIVE token savings
	var systemContent string
	if sessionID != "" {
		// Create a dummy agent UUID for this function since agentID is not passed
		// This will still provide session-based caching benefits
		dummyAgentUUID := uuid.New()
		systemContent = s.getSessionBehaviorCache(ctx, sessionID, dummyAgentUUID, settings.Behaviour, complexity)
		s.logger.With(ctx).Info("ðŸš€ Using session-cached behavior (without integrations) - MASSIVE TOKEN SAVINGS! Length:", len(systemContent), "characters")
	} else {
		// Fallback to regular behavior compression
		systemContent = s.compressBehaviorPrompt(settings.Behaviour, complexity)
		s.logger.Info("ðŸ“‹ Using regular behavior compression (no session) - Length:", len(systemContent), "characters")
	}

	// Add minimal transfer condition
	if settings.TransferCondition != "" {
		systemContent += "\nTRANSFER: " + settings.TransferCondition
	}

	// Add minimal knowledge if available
	if specificKnowledge != "" {
		systemContent += "\nKnowledge: " + specificKnowledge
	}

	// Add minimal lead context
	if leadContext != "" {
		systemContent += "\nLead: " + leadContext
	}

	// Critical behavior consistency rules are now at the beginning with absolute priority
	// No need to duplicate them here

	return systemContent
}

// sendMultipleImagesWithDetails sends multiple images with their corresponding product details as captions
func (s *service) sendMultipleImagesWithDetails(ctx context.Context, session, number, message string, imageURLs []string) error {
	// Split the message into sections based on image URLs
	messageSections := s.splitMessageByImages(message, imageURLs)

	s.logger.With(ctx).Infof("Starting to send %d product images - Session: %s, Number: %s", len(imageURLs), session, number)

	// Track success and failures
	var successCount, failureCount int
	var lastError error

	// Send each image with its corresponding detail as caption
	for i, imageURL := range imageURLs {
		var caption string
		if i < len(messageSections) {
			caption = messageSections[i]
		}

		// Clean up the caption
		caption = s.cleanCaption(caption)

		s.logger.With(ctx).Infof("Sending product image %d/%d - Session: %s, URL: %s", i+1, len(imageURLs), session, imageURL)

		// Add a small delay between sends to avoid overwhelming the WhatsApp API
		if i > 0 {
			select {
			case <-ctx.Done():
				return fmt.Errorf("context cancelled while sending product %d/%d: %w", i+1, len(imageURLs), ctx.Err())
			case <-time.After(ProductSendDelay):
				// Continue with next image
			}
		}

		err := s.sendMediaToWhatsApp(ctx, session, number, caption, imageURL)
		if err != nil {
			failureCount++
			lastError = err
			s.logger.With(ctx).Errorf("Failed to send product image %d/%d: %v - Session: %s, URL: %s",
				i+1, len(imageURLs), err, session, imageURL)

			// Try to send as text fallback for this specific product
			if caption != "" {
				fallbackMessage := fmt.Sprintf("Product %d:\n%s\n\nImage: %s", i+1, caption, imageURL)
				if fallbackErr := s.sendTextToWhatsApp(ctx, session, number, fallbackMessage); fallbackErr != nil {
					s.logger.With(ctx).Errorf("Failed to send fallback text for product %d: %v", i+1, fallbackErr)
				} else {
					s.logger.With(ctx).Infof("Sent fallback text for product %d/%d - Session: %s", i+1, len(imageURLs), session)
					successCount++ // Count fallback as success
				}
			}
			continue
		}

		successCount++
		s.logger.With(ctx).Infof("Successfully sent product image %d/%d - Session: %s, Number: %s, URL: %s",
			i+1, len(imageURLs), session, number, imageURL)
	}

	// Log final results
	s.logger.With(ctx).Infof("Product sending completed - Session: %s, Success: %d/%d, Failures: %d",
		session, successCount, len(imageURLs), failureCount)

	// Return error only if all products failed to send
	if successCount == 0 {
		// Send user-friendly error message
		s.handleProductSendingError(ctx, session, number, lastError, len(imageURLs))
		return fmt.Errorf("failed to send any of the %d products: %w", len(imageURLs), lastError)
	}

	// Send summary message if some products failed
	if failureCount > 0 {
		// Determine if failures were due to timeouts
		timeoutFailures := s.isTimeoutError(lastError)
		var summaryMessage string

		if timeoutFailures {
			summaryMessage = fmt.Sprintf("âš ï¸ Successfully sent %d out of %d products. %d products experienced network timeouts but were sent as text. Consider requesting fewer products at once for faster delivery.",
				successCount, len(imageURLs), failureCount)
		} else {
			summaryMessage = fmt.Sprintf("âœ… Successfully sent %d out of %d products. %d products had delivery issues but were sent as text.",
				successCount, len(imageURLs), failureCount)
		}

		if err := s.sendTextToWhatsApp(ctx, session, number, summaryMessage); err != nil {
			s.logger.With(ctx).Errorf("Failed to send summary message: %v", err)
		}

		// Log metrics for monitoring
		s.logger.With(ctx).Error("PRODUCT_SENDING_PARTIAL_FAILURE - Session: %s, Total: %d, Success: %d, Failures: %d, Timeout_Related: %v",
			session, len(imageURLs), successCount, failureCount, timeoutFailures)
	} else {
		// Log successful completion
		s.logger.With(ctx).Infof("PRODUCT_SENDING_SUCCESS - Session: %s, Total: %d, All products sent successfully",
			session, len(imageURLs))
	}

	return nil
}

// splitMessageByImages splits the message into sections corresponding to each image
func (s *service) splitMessageByImages(message string, imageURLs []string) []string {
	// Create a copy of the message to work with
	workingMessage := message

	// Find positions of each image URL in the message
	type imagePosition struct {
		url   string
		index int
	}

	var positions []imagePosition
	for _, imageURL := range imageURLs {
		// Look for the image URL in various formats
		index := strings.Index(workingMessage, imageURL)
		if index == -1 {
			index = strings.Index(workingMessage, "`"+imageURL+"`")
		}
		if index != -1 {
			positions = append(positions, imagePosition{url: imageURL, index: index})
		}
	}

	// Sort positions by index
	for i := 0; i < len(positions)-1; i++ {
		for j := i + 1; j < len(positions); j++ {
			if positions[i].index > positions[j].index {
				positions[i], positions[j] = positions[j], positions[i]
			}
		}
	}

	var sections []string

	// If we can't find proper positions, try to split by common patterns
	if len(positions) == 0 {
		// Fallback: split by common product separators
		lines := strings.Split(workingMessage, "\n")
		currentSection := ""
		imageCount := 0

		for _, line := range lines {
			// Check if this line contains an image URL
			containsImage := false
			for _, imageURL := range imageURLs {
				if strings.Contains(line, imageURL) {
					containsImage = true
					break
				}
			}

			if containsImage {
				// Save current section if we have content
				if strings.TrimSpace(currentSection) != "" {
					sections = append(sections, currentSection)
				}
				// Start new section
				currentSection = ""
				imageCount++
			} else {
				// Add line to current section
				if currentSection != "" {
					currentSection += "\n"
				}
				currentSection += line
			}
		}

		// Add the last section
		if strings.TrimSpace(currentSection) != "" {
			sections = append(sections, currentSection)
		}

		// If we still don't have enough sections, try to split the remaining text
		for len(sections) < len(imageURLs) {
			if len(sections) == 0 {
				// Use the entire message as first section
				sections = append(sections, workingMessage)
			} else {
				// Add empty sections
				sections = append(sections, "")
			}
		}

		return sections
	}

	// Extract sections based on image positions
	lastEnd := 0
	for i, pos := range positions {
		// Get text before this image
		if pos.index > lastEnd {
			sectionText := workingMessage[lastEnd:pos.index]
			sections = append(sections, sectionText)
		}

		// Find the end of this image URL
		imageEnd := pos.index + len(pos.url)
		if strings.Contains(workingMessage[pos.index:], "`"+pos.url+"`") {
			imageEnd = pos.index + len("`"+pos.url+"`")
		}

		// Get text after this image until next image or end
		nextStart := len(workingMessage)
		if i+1 < len(positions) {
			nextStart = positions[i+1].index
		}

		if nextStart > imageEnd {
			sectionText := workingMessage[imageEnd:nextStart]
			sections = append(sections, sectionText)
		}

		lastEnd = nextStart
	}

	return sections
}

// cleanCaption cleans up the caption text by removing image URLs and formatting
func (s *service) cleanCaption(caption string) string {
	if caption == "" {
		return ""
	}

	// Remove "Gambar:" lines and clean up
	caption = regexp.MustCompile(`(?i)\s*gambar:\s*`).ReplaceAllString(caption, "")

	// Remove any remaining image URLs
	caption = regexp.MustCompile(`https?://[^\s]+`).ReplaceAllString(caption, "")

	// Remove backticks
	caption = strings.ReplaceAll(caption, "`", "")

	// Clean up whitespace
	caption = strings.TrimSpace(caption)
	caption = regexp.MustCompile(`\n\s*\n`).ReplaceAllString(caption, "\n\n")

	// Remove leading/trailing newlines
	caption = strings.Trim(caption, "\n")

	return caption
}

// isTimeoutError checks if an error is related to timeout or context deadline
func (s *service) isTimeoutError(err error) bool {
	if err == nil {
		return false
	}
	errorStr := strings.ToLower(err.Error())
	return strings.Contains(errorStr, "timeout") ||
		strings.Contains(errorStr, "deadline") ||
		strings.Contains(errorStr, "context canceled") ||
		strings.Contains(errorStr, "context deadline exceeded")
}

// handleProductSendingError provides user-friendly error handling for product sending failures
func (s *service) handleProductSendingError(ctx context.Context, session, number string, err error, productCount int) {
	if s.isTimeoutError(err) {
		errorMessage := fmt.Sprintf("âš ï¸ Network timeout occurred while sending %d products. This can happen with large product catalogs. Please try again or request fewer products at once.", productCount)
		if sendErr := s.sendTextToWhatsApp(ctx, session, number, errorMessage); sendErr != nil {
			s.logger.With(ctx).Errorf("Failed to send timeout error message: %v", sendErr)
		}
	} else {
		errorMessage := fmt.Sprintf("âŒ Failed to send %d products due to technical issues. Please try again later or contact support if the problem persists.", productCount)
		if sendErr := s.sendTextToWhatsApp(ctx, session, number, errorMessage); sendErr != nil {
			s.logger.With(ctx).Errorf("Failed to send error message: %v", sendErr)
		}
	}
}

// sendMediaToWhatsApp sends media via S3 URL to the WhatsApp API with retry logic
func (s *service) sendMediaToWhatsApp(ctx context.Context, session, number, caption, s3URL string) error {
	return s.sendMediaToWhatsAppWithRetry(ctx, session, number, caption, s3URL, 3)
}

// sendMediaToWhatsAppWithRetry sends media with configurable retry attempts
func (s *service) sendMediaToWhatsAppWithRetry(ctx context.Context, session, number, caption, s3URL string, maxRetries int) error {
	var lastErr error

	for attempt := 0; attempt <= maxRetries; attempt++ {
		if attempt > 0 {
			// Exponential backoff: 1s, 2s, 4s
			backoffDuration := time.Duration(1<<uint(attempt-1)) * time.Second
			s.logger.With(ctx).Error("Retrying media send (attempt %d/%d) after %v - Session: %s, URL: %s",
				attempt+1, maxRetries+1, backoffDuration, session, s3URL)

			select {
			case <-ctx.Done():
				return ctx.Err()
			case <-time.After(backoffDuration):
			}
		}

		// Prepare the request payload for WhatsApp media API
		payload := map[string]string{
			"session": session,
			"number":  number,
			"caption": caption,
			"s3_url":  s3URL,
		}

		jsonData, err := json.Marshal(payload)
		if err != nil {
			return fmt.Errorf("failed to marshal WhatsApp media request: %w", err)
		}

		// Create HTTP request to WhatsApp media API
		req, err := http.NewRequestWithContext(ctx, "POST", s.whatsappServiceURL+"/send-media-s3", bytes.NewBuffer(jsonData))
		if err != nil {
			return fmt.Errorf("failed to create WhatsApp media request: %w", err)
		}

		req.Header.Set("Content-Type", "application/json")

		// Increased timeout for media requests with context deadline consideration
		timeout := WhatsAppMediaTimeout
		if deadline, ok := ctx.Deadline(); ok {
			// Use remaining context time if less than our timeout
			if remaining := time.Until(deadline); remaining < timeout {
				timeout = remaining - (5 * time.Second) // Leave 5s buffer
				if timeout < 10*time.Second {
					timeout = 10 * time.Second // Minimum 10s timeout
				}
			}
		}

		client := &http.Client{Timeout: timeout}
		resp, err := client.Do(req)
		if err != nil {
			lastErr = fmt.Errorf("failed to send WhatsApp media request (attempt %d): %w", attempt+1, err)
			s.logger.With(ctx).Errorf("Media send attempt %d failed: %v", attempt+1, err)
			continue
		}
		defer resp.Body.Close()

		// Check response status
		if resp.StatusCode != http.StatusOK {
			body, _ := io.ReadAll(resp.Body)
			lastErr = fmt.Errorf("WhatsApp media API error (attempt %d): %s - %s", attempt+1, resp.Status, string(body))
			s.logger.With(ctx).Errorf("Media send attempt %d failed with status %s: %s", attempt+1, resp.Status, string(body))

			// Don't retry on client errors (4xx)
			if resp.StatusCode >= 400 && resp.StatusCode < 500 {
				return lastErr
			}
			continue
		}

		s.logger.With(ctx).Infof("Successfully sent media to WhatsApp (attempt %d) - Session: %s, Number: %s, S3 URL: %s",
			attempt+1, session, number, s3URL)
		return nil
	}

	return fmt.Errorf("failed to send media after %d attempts: %w", maxRetries+1, lastErr)
}

// UploadImageFromWhatsApp downloads an image from WhatsApp, uploads it to S3, and processes it
func (s *service) UploadImageFromWhatsApp(ctx context.Context, agentID uuid.UUID, req WhatsAppImageRequest) (*ChatResponse, error) {
	// Get tenant ID from context
	_, tenantID, err := dbcontext.GetTenantDB(ctx, s.dbManager)
	if err != nil {
		return nil, fmt.Errorf("failed to get tenant info: %w", err)
	}

	// Download the image from the provided URL
	imageData, filename, err := s.downloadImageFromURL(ctx, req.ImageURL)
	if err != nil {
		return nil, fmt.Errorf("failed to download image: %w", err)
	}

	// Generate unique filename
	uniqueFilename, err := s.generateUniqueFilename(filename)
	if err != nil {
		return nil, fmt.Errorf("failed to generate unique filename: %w", err)
	}

	// Upload to S3 with tenant-specific folder
	s3URL, err := s.s3Service.UploadWithTenant(tenantID.String(), uniqueFilename, imageData)
	if err != nil {
		return nil, fmt.Errorf("failed to upload image to S3: %w", err)
	}

	s.logger.With(ctx).Infof("Successfully uploaded WhatsApp image to S3: %s", s3URL)

	// Create a message indicating the image was received
	message := "Image received and uploaded"
	if req.Caption != "" {
		message = fmt.Sprintf("Image received with caption: %s", req.Caption)
	}

	// Process the image message through AI with true vision-based payment detection
	var aiResponse string
	var tokensUsed int

	// Check if we should analyze for bank transfer slip based on conversation context and caption
	shouldAnalyzePayment := s.shouldAnalyzeForPaymentProof(ctx, req.SessionID, req.Caption)
	if shouldAnalyzePayment {
		s.logger.With(ctx).Info("ðŸ” PAYMENT DETECTION ACTIVATED", "session_id", req.SessionID, "caption", req.Caption, "image_url", s3URL)
	} else {
		s.logger.With(ctx).Info("ðŸ“· Regular image processing", "session_id", req.SessionID, "caption", req.Caption)
	}

	// Get tenant database
	tenantDB, _, err := dbcontext.GetTenantDB(ctx, s.dbManager)
	if err != nil {
		return nil, fmt.Errorf("failed to get tenant database: %w", err)
	}

	// Get AI agent directly using agentID (which is ai_agents.id from WhatsApp gateway)
	agent, err := s.repo.GetAIAgentByID(ctx, tenantDB, agentID)
	if err != nil {
		return nil, fmt.Errorf("failed to get AI agent: %w", err)
	}

	// Get AI settings
	settings, err := s.repo.GetAISettingsByID(ctx, tenantDB, agent.IDSettings)
	if err != nil {
		s.logger.With(ctx).Errorf("Failed to get AI settings: %v", err)
		return nil, fmt.Errorf("failed to get AI settings: %w", err)
	}

	// Step 1: Conditionally use gpt-4o-mini to analyze the image
	var imageAnalysis string
	var imageAnalysisTokens int

	// Always perform dynamic AI analysis based on behavior and context
	// The analysis strategy will determine the appropriate approach (payment, expert, OCR, etc.)
	if true { // Always analyze images dynamically
		s.logger.With(ctx).Info("ðŸ–¼ï¸ Performing AI analysis for image", "s3_url", s3URL, "should_analyze_payment", shouldAnalyzePayment)

		// Build vision message for image analysis using dynamic approach
		analysisPrompt := s.buildDynamicImageAnalysisPrompt(ctx, settings, shouldAnalyzePayment, req.Caption)

		if req.Caption != "" {
			analysisPrompt = fmt.Sprintf("User sent an image with caption: %s\n\n%s", req.Caption, analysisPrompt)
		}

		visionMessage := s.buildVisionMessage(analysisPrompt, s3URL, "high")

		// Build messages for gpt-4o-mini analysis
		analysisMessages := []OpenAIMessage{
			{
				Role:    "system",
				Content: "You are an expert image analyst. Provide detailed, accurate descriptions of images.",
			},
			visionMessage,
		}

		// Determine if we should use OCR based on analysis strategy
		analysisStrategy := s.determineImageAnalysisStrategy(strings.ToLower(settings.Behaviour), req.Caption, shouldAnalyzePayment)

		if analysisStrategy.UseOCR {
			// Use OCR for product text extraction
			s.logger.With(ctx).Info("ðŸ“¦ Using OCR for product text extraction", "strategy", analysisStrategy.Type)

			// Download image for OCR processing
			imageData, _, err := s.downloadImageFromURL(ctx, s3URL)
			if err != nil {
				s.logger.With(ctx).Errorf("Failed to download image for OCR: %v", err)
				// Fallback to vision analysis
				goto visionAnalysis
			}

			// Extract text using OCR
			extractedText, err := s.extractTextFromImageData(ctx, imageData)
			if err != nil {
				s.logger.With(ctx).Errorf("Failed to extract text from image: %v", err)
				// Fallback to vision analysis
				goto visionAnalysis
			}

			if extractedText != "" {
				imageAnalysis = fmt.Sprintf("ðŸ“¦ PRODUCT TEXT EXTRACTED:\n%s\n\nThis appears to be a product image with text content that can be used for product information lookup.", extractedText)
				imageAnalysisTokens = 50 // Minimal tokens for OCR result
				s.logger.With(ctx).Info("âœ… OCR text extraction successful", "text_length", len(extractedText))
			} else {
				s.logger.With(ctx).Info("âš ï¸ OCR extracted no text, falling back to vision analysis")
				goto visionAnalysis
			}
		}

	visionAnalysis:
		if !analysisStrategy.UseOCR || imageAnalysis == "" {
			// Use gpt-4.1-mini for image analysis
			analysisSettings := *settings // Copy settings
			analysisSettings.Model = "gpt-4.1-mini"
			s.logger.With(ctx).Info("ðŸ” Step 1: Using gpt-4.1-nano for image analysis", "original_model", settings.Model, "strategy", analysisStrategy.Type)

			// For image analysis, use a simple message for complexity analysis
			// Get token tracker from context or create a new one for tracking this analysis
			tokenTracker := accesslog.GetTokenTrackerFromContext(ctx)
			if tokenTracker == nil {
				requestID := uuid.New().String()
				tokenTracker = accesslog.NewTokenTracker(requestID)
				s.logger.With(ctx).Infof("ðŸ”¢ Created token tracker for image analysis: %s", requestID)
			}

			analysisResp, err := s.callOpenAI(ctx, analysisMessages, &analysisSettings, "image analysis", len(analysisMessages[0].Content.(string)), tokenTracker, "image_analysis")
			if err != nil {
				s.logger.With(ctx).Errorf("Failed to get image analysis from gpt-4.1-nano: %v", err)
				return nil, fmt.Errorf("failed to analyze image with gpt-4.1-nano: %w", err)
			}

			// Note: Token tracking is handled by the main conversation flow via tokenTracker

			if len(analysisResp.Choices) == 0 {
				return nil, fmt.Errorf("no response from gpt-4.1-nano image analysis")
			}

			imageAnalysis = analysisResp.Choices[0].Message.Content
			imageAnalysisTokens = analysisResp.Usage.TotalTokens
		}

		s.logger.With(ctx).Info("âœ… Step 1 Complete: gpt-4.1-nano image analysis",
			"tokens_used", imageAnalysisTokens,
			"analysis_length", len(imageAnalysis),
			"analysis_preview", imageAnalysis[:min(500, len(imageAnalysis))])
	}

	// Store image analysis result for later use by SendMessage/buildOpenAIMessages
	if req.SessionID != "" && imageAnalysis != "" {
		analysisResult := &ImageAnalysisResult{
			Analysis:  imageAnalysis,
			Timestamp: time.Now(),
			TTL:       30 * time.Minute, // Analysis expires after 30 minutes
		}
		s.imageAnalysisResults.Store(req.SessionID, analysisResult)
		s.logger.With(ctx).Info("ðŸ’¾ Stored image analysis result for session - will be used in next message", "session_id", req.SessionID)
	}

	// Return simple acknowledgment - the actual conversation will happen in SendMessage
	aiResponse = "Image received and analyzed. Please send your message."
	tokensUsed = imageAnalysisTokens

	s.logger.With(ctx).Info("âœ… Image analysis complete - stored for next message",
		"analysis_tokens", imageAnalysisTokens,
		"analysis_length", len(imageAnalysis),
		"analysis_preview", imageAnalysis[:min(200, len(imageAnalysis))])

	// Log AI usage for image analysis (specific operation, separate from main conversation flow)
	s.logAIUsage(ctx, "gpt-4.1-mini", tokensUsed, "image_analysis", req.SessionID, agentID, "", "whatsapp")

	// Return the chat response
	return &ChatResponse{
		ID:         uuid.New(),
		AgentID:    agentID,
		SessionID:  req.SessionID,
		Message:    message,
		Media:      &s3URL,
		Response:   aiResponse,
		CreatedAt:  time.Now(),
		TokensUsed: tokensUsed,
	}, nil
}

// buildDynamicImageAnalysisPrompt creates a flexible image analysis prompt based on AI behavior
func (s *service) buildDynamicImageAnalysisPrompt(ctx context.Context, settings *entity.AISettings, shouldAnalyzePayment bool, caption string) string {
	// Extract key context from AI behavior to understand the AI's role and expertise
	behaviorLower := strings.ToLower(settings.Behaviour)

	// Determine analysis strategy based on AI behavior and context
	analysisStrategy := s.determineImageAnalysisStrategy(behaviorLower, caption, shouldAnalyzePayment)

	s.logger.With(ctx).Info("ðŸ” Dynamic image analysis strategy determined",
		"strategy", analysisStrategy.Type,
		"focus_areas", analysisStrategy.FocusAreas,
		"should_analyze_payment", shouldAnalyzePayment)

	switch analysisStrategy.Type {
	case "payment_validation":
		return s.buildPaymentAnalysisPrompt()
	case "technical_analysis":
		return s.buildTechnicalAnalysisPrompt(analysisStrategy.FocusAreas)
	case "product_ocr":
		return s.buildProductOCRPrompt()
	case "expert_analysis":
		return s.buildExpertAnalysisPrompt(analysisStrategy.ExpertDomain, analysisStrategy.FocusAreas)
	default:
		return s.buildGeneralAnalysisPrompt()
	}
}

// ImageAnalysisStrategy defines how an image should be analyzed
type ImageAnalysisStrategy struct {
	Type         string   // payment_validation, technical_analysis, product_ocr, expert_analysis, general
	ExpertDomain string   // cctv, interior_design, architecture, etc.
	FocusAreas   []string // specific things to look for
	UseOCR       bool     // whether to prioritize text extraction
}

// determineImageAnalysisStrategy analyzes AI behavior to determine optimal image analysis approach
func (s *service) determineImageAnalysisStrategy(behaviorLower, caption string, shouldAnalyzePayment bool) ImageAnalysisStrategy {
	// Priority 1: Payment analysis (most common use case)
	if shouldAnalyzePayment {
		return ImageAnalysisStrategy{
			Type:       "payment_validation",
			FocusAreas: []string{"bank_interface", "transaction_details", "payment_confirmation"},
			UseOCR:     false,
		}
	}

	// Priority 2: Expert domain analysis based on AI behavior
	if strings.Contains(behaviorLower, "cctv") || strings.Contains(behaviorLower, "security") || strings.Contains(behaviorLower, "surveillance") {
		return ImageAnalysisStrategy{
			Type:         "expert_analysis",
			ExpertDomain: "cctv_security",
			FocusAreas:   []string{"room_layout", "optimal_placement", "coverage_areas", "blind_spots"},
			UseOCR:       false,
		}
	}

	if strings.Contains(behaviorLower, "interior") || strings.Contains(behaviorLower, "design") || strings.Contains(behaviorLower, "decoration") {
		return ImageAnalysisStrategy{
			Type:         "expert_analysis",
			ExpertDomain: "interior_design",
			FocusAreas:   []string{"space_layout", "color_scheme", "furniture_placement", "lighting"},
			UseOCR:       false,
		}
	}

	if strings.Contains(behaviorLower, "architect") || strings.Contains(behaviorLower, "building") || strings.Contains(behaviorLower, "construction") {
		return ImageAnalysisStrategy{
			Type:         "expert_analysis",
			ExpertDomain: "architecture",
			FocusAreas:   []string{"structural_elements", "floor_plan", "measurements", "building_features"},
			UseOCR:       false,
		}
	}

	// Priority 3: Product/catalog analysis (OCR focus)
	if strings.Contains(behaviorLower, "produk") || strings.Contains(behaviorLower, "product") ||
		strings.Contains(behaviorLower, "catalog") || strings.Contains(behaviorLower, "katalog") ||
		strings.Contains(behaviorLower, "jual") || strings.Contains(behaviorLower, "sell") {
		// Check if caption suggests product information
		captionLower := strings.ToLower(caption)
		if strings.Contains(captionLower, "box") || strings.Contains(captionLower, "package") ||
			strings.Contains(captionLower, "label") || strings.Contains(captionLower, "text") {
			return ImageAnalysisStrategy{
				Type:       "product_ocr",
				FocusAreas: []string{"text_extraction", "product_details", "specifications"},
				UseOCR:     true,
			}
		}
	}

	// Priority 4: Technical analysis for diagrams, plans, etc.
	captionLower := strings.ToLower(caption)
	if strings.Contains(captionLower, "plan") || strings.Contains(captionLower, "diagram") ||
		strings.Contains(captionLower, "blueprint") || strings.Contains(captionLower, "schema") ||
		strings.Contains(captionLower, "circle") || strings.Contains(captionLower, "mark") {
		return ImageAnalysisStrategy{
			Type:       "technical_analysis",
			FocusAreas: []string{"technical_elements", "markings", "annotations", "patterns"},
			UseOCR:     false,
		}
	}

	// Default: General analysis
	return ImageAnalysisStrategy{
		Type:       "general",
		FocusAreas: []string{"general_description"},
		UseOCR:     false,
	}
}

// buildPaymentAnalysisPrompt creates the payment validation prompt
func (s *service) buildPaymentAnalysisPrompt() string {
	return `Analyze if this is a valid Indonesian payment slip. Accept: bank/payment apps (BCA, BNI, BRI, Mandiri, DANA, OVO, GoPay), transaction details, ATM receipts. Reject: food, products, people, documents, diagrams. State clearly: valid payment or not.`
}

// buildTechnicalAnalysisPrompt creates prompts for technical diagrams and plans
func (s *service) buildTechnicalAnalysisPrompt(focusAreas []string) string {
	return fmt.Sprintf(`Analyze technical image focusing on: %s. Describe elements, markings, annotations, patterns, measurements, structure.`, strings.Join(focusAreas, ", "))
}

// buildProductOCRPrompt creates prompts for product text extraction
func (s *service) buildProductOCRPrompt() string {
	return `Extract all visible text: product names, specifications, model numbers, prices, brands, labels. Organize clearly.`
}

// buildExpertAnalysisPrompt creates domain-specific expert analysis prompts
func (s *service) buildExpertAnalysisPrompt(expertDomain string, focusAreas []string) string {
	switch expertDomain {
	case "cctv_security":
		return `As CCTV expert, analyze room layout, entry points, blind spots, optimal camera positions, lighting. Recommend placement strategy.`

	case "interior_design":
		return `As interior designer, analyze layout, colors, lighting, furniture placement, flow, style. Provide design recommendations.`

	case "architecture":
		return `As architect, analyze structural elements, floor plan, building features, spatial organization, style. Provide assessment.`

	default:
		return fmt.Sprintf(`As %s expert, analyze focusing on: %s. Provide professional analysis.`, expertDomain, strings.Join(focusAreas, ", "))
	}
}

// buildGeneralAnalysisPrompt creates a general image analysis prompt
func (s *service) buildGeneralAnalysisPrompt() string {
	return `Describe image: main subjects, setting, colors, lighting, visible text, context, notable details.`
}

// extractTextFromImageData extracts text from image data using OCR
func (s *service) extractTextFromImageData(ctx context.Context, imageData []byte) (string, error) {
	// Create a temporary file for OCR processing
	tempFile, err := os.CreateTemp("", "ocr_image_*.jpg")
	if err != nil {
		return "", fmt.Errorf("failed to create temp file: %w", err)
	}
	defer os.Remove(tempFile.Name())
	defer tempFile.Close()

	// Write image data to temp file
	if _, err := tempFile.Write(imageData); err != nil {
		return "", fmt.Errorf("failed to write image data: %w", err)
	}

	// Close file before OCR processing
	tempFile.Close()

	// Extract text using existing OCR function
	return s.extractTextFromImage(ctx, tempFile.Name())
}

// downloadImageFromURL downloads an image from the given URL with enhanced error handling and validation
func (s *service) downloadImageFromURL(ctx context.Context, imageURL string) ([]byte, string, error) {
	// Validate URL format
	if !strings.HasPrefix(imageURL, "http://") && !strings.HasPrefix(imageURL, "https://") {
		return nil, "", fmt.Errorf("invalid image URL format: %s", imageURL)
	}

	// Create request with timeout
	req, err := http.NewRequestWithContext(ctx, "GET", imageURL, nil)
	if err != nil {
		return nil, "", fmt.Errorf("failed to create request: %w", err)
	}

	// Set user agent to avoid blocking
	req.Header.Set("User-Agent", "VH-AI-CRM/1.0")

	// Use client with reasonable timeout and connection pooling
	client := &http.Client{
		Timeout: 30 * time.Second,
		Transport: &http.Transport{
			MaxIdleConns:       10,
			IdleConnTimeout:    30 * time.Second,
			DisableCompression: false,
		},
	}

	resp, err := client.Do(req)
	if err != nil {
		return nil, "", fmt.Errorf("failed to download image: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return nil, "", fmt.Errorf("failed to download image: status %d", resp.StatusCode)
	}

	// Check content type
	contentType := resp.Header.Get("Content-Type")
	if !strings.HasPrefix(contentType, "image/") {
		s.logger.With(ctx).Infof("Suspicious content type for image: %s (URL: %s)", contentType, imageURL)
	}

	// Check content length
	contentLength := resp.Header.Get("Content-Length")
	if contentLength != "" {
		if size, err := strconv.ParseInt(contentLength, 10, 64); err == nil && size > MaxImageSize {
			return nil, "", fmt.Errorf("image too large: %d bytes (max: %d)", size, MaxImageSize)
		}
	}

	// Read with size limit
	limitedReader := io.LimitReader(resp.Body, MaxImageSize+1)
	imageData, err := io.ReadAll(limitedReader)
	if err != nil {
		return nil, "", fmt.Errorf("failed to read image data: %w", err)
	}

	// Check actual size
	if len(imageData) > MaxImageSize {
		return nil, "", fmt.Errorf("image too large: %d bytes (max: %d)", len(imageData), MaxImageSize)
	}

	// Validate image format
	if !s.isValidImageFormat(imageData) {
		return nil, "", fmt.Errorf("invalid image format")
	}

	// Compress image if needed
	compressedData, err := s.compressImageIfNeeded(imageData)
	if err != nil {
		s.logger.With(ctx).Infof("Failed to compress image, using original: %v", err)
		compressedData = imageData
	}

	// Extract filename from URL
	filename := filepath.Base(imageURL)
	if filename == "." || filename == "/" {
		filename = "whatsapp_image.jpg" // Default filename
	}

	s.logger.With(ctx).Info("Image downloaded successfully",
		"url", imageURL,
		"original_size", len(imageData),
		"compressed_size", len(compressedData),
		"filename", filename)

	return compressedData, filename, nil
}

// generateUniqueFilename generates a unique filename with timestamp and random string
func (s *service) generateUniqueFilename(originalFilename string) (string, error) {
	// Generate random bytes
	randomBytes := make([]byte, 8)
	_, err := rand.Read(randomBytes)
	if err != nil {
		return "", fmt.Errorf("failed to generate random bytes: %w", err)
	}

	// Get file extension
	ext := filepath.Ext(originalFilename)
	if ext == "" {
		ext = ".jpg" // Default to jpg if no extension
	}

	// Create unique filename: timestamp_randomhex_originalname
	timestamp := time.Now().Unix()
	randomHex := hex.EncodeToString(randomBytes)
	baseFilename := strings.TrimSuffix(originalFilename, ext)

	uniqueFilename := fmt.Sprintf("%d_%s_%s%s", timestamp, randomHex, baseFilename, ext)
	return uniqueFilename, nil
}

// isValidImageFormat validates if the data represents a valid image format
func (s *service) isValidImageFormat(data []byte) bool {
	if len(data) < 8 {
		return false
	}

	// Check for common image format signatures
	// JPEG
	if len(data) >= 2 && data[0] == 0xFF && data[1] == 0xD8 {
		return true
	}
	// PNG
	if len(data) >= 8 && string(data[:8]) == "\x89PNG\r\n\x1a\n" {
		return true
	}
	// GIF
	if len(data) >= 6 && (string(data[:6]) == "GIF87a" || string(data[:6]) == "GIF89a") {
		return true
	}
	// WebP
	if len(data) >= 12 && string(data[:4]) == "RIFF" && string(data[8:12]) == "WEBP" {
		return true
	}
	// BMP
	if len(data) >= 2 && data[0] == 0x42 && data[1] == 0x4D {
		return true
	}

	return false
}

// compressImageIfNeeded compresses the image if it's too large
func (s *service) compressImageIfNeeded(data []byte) ([]byte, error) {
	// If image is already small enough, return as-is
	if len(data) <= MaxImageSize/2 {
		return data, nil
	}

	// Try to decode the image
	img, format, err := image.Decode(bytes.NewReader(data))
	if err != nil {
		return data, fmt.Errorf("failed to decode image: %w", err)
	}

	// Check if we need to resize
	bounds := img.Bounds()
	width := bounds.Dx()
	height := bounds.Dy()

	// Calculate new dimensions if needed
	newWidth, newHeight := width, height
	if width > MaxImageDimension || height > MaxImageDimension {
		if width > height {
			newWidth = MaxImageDimension
			newHeight = height * MaxImageDimension / width
		} else {
			newHeight = MaxImageDimension
			newWidth = width * MaxImageDimension / height
		}

		// Resize image (simple nearest neighbor for now)
		img = s.resizeImage(img, newWidth, newHeight)
	}

	// Compress based on format
	var buf bytes.Buffer
	switch format {
	case "jpeg":
		err = jpeg.Encode(&buf, img, &jpeg.Options{Quality: ImageQuality})
	case "png":
		err = png.Encode(&buf, img)
	default:
		// Default to JPEG for other formats
		err = jpeg.Encode(&buf, img, &jpeg.Options{Quality: ImageQuality})
	}

	if err != nil {
		return data, fmt.Errorf("failed to encode compressed image: %w", err)
	}

	compressed := buf.Bytes()
	// Only return compressed version if it's actually smaller
	if len(compressed) < len(data) {
		return compressed, nil
	}
	return data, nil
}

// resizeImage performs simple image resizing using nearest neighbor
func (s *service) resizeImage(src image.Image, newWidth, newHeight int) image.Image {
	srcBounds := src.Bounds()
	srcWidth := srcBounds.Dx()
	srcHeight := srcBounds.Dy()

	// Create new image
	dst := image.NewRGBA(image.Rect(0, 0, newWidth, newHeight))

	// Simple nearest neighbor scaling
	for y := 0; y < newHeight; y++ {
		for x := 0; x < newWidth; x++ {
			srcX := x * srcWidth / newWidth
			srcY := y * srcHeight / newHeight
			dst.Set(x, y, src.At(srcX+srcBounds.Min.X, srcY+srcBounds.Min.Y))
		}
	}

	return dst
}

// getOrCreateCircuitBreaker gets or creates a circuit breaker for a service
func (s *service) getOrCreateCircuitBreaker(serviceName string) *CircuitBreaker {
	if cb, exists := s.circuitBreaker.Load(serviceName); exists {
		if circuitBreaker, ok := cb.(*CircuitBreaker); ok {
			return circuitBreaker
		}
	}

	// Create new circuit breaker
	newCB := &CircuitBreaker{
		FailureCount: 0,
		State:        "closed",
		Threshold:    5,                // Allow 5 failures before opening
		Timeout:      30 * time.Second, // Stay open for 30 seconds
	}

	s.circuitBreaker.Store(serviceName, newCB)
	return newCB
}

// canExecute checks if the circuit breaker allows execution
func (cb *CircuitBreaker) canExecute() bool {
	cb.mutex.RLock()
	defer cb.mutex.RUnlock()

	switch cb.State {
	case "closed":
		return true
	case "open":
		// Check if timeout has passed
		if time.Since(cb.LastFailureTime) > cb.Timeout {
			cb.mutex.RUnlock()
			cb.mutex.Lock()
			cb.State = "half-open"
			cb.mutex.Unlock()
			cb.mutex.RLock()
			return true
		}
		return false
	case "half-open":
		return true
	default:
		return false
	}
}

// recordSuccess records a successful execution
func (cb *CircuitBreaker) recordSuccess() {
	cb.mutex.Lock()
	defer cb.mutex.Unlock()

	cb.FailureCount = 0
	cb.State = "closed"
}

// recordFailure records a failed execution
func (cb *CircuitBreaker) recordFailure() {
	cb.mutex.Lock()
	defer cb.mutex.Unlock()

	cb.FailureCount++
	cb.LastFailureTime = time.Now()

	if cb.FailureCount >= cb.Threshold {
		cb.State = "open"
	}
}

// cleanupOldSessions removes old session data to prevent memory leaks
func (s *service) cleanupOldSessions() {
	cutoff := time.Now().Add(-SessionCleanupInterval)

	// Clean up payment detection cooldowns
	s.paymentDetectionCooldown.Range(func(key, value interface{}) bool {
		if lastTime, ok := value.(time.Time); ok {
			if lastTime.Before(cutoff) {
				s.paymentDetectionCooldown.Delete(key)
			}
		}
		return true
	})

	// Clean up transfer cooldowns
	s.transferCooldown.Range(func(key, value interface{}) bool {
		if lastTime, ok := value.(time.Time); ok {
			if lastTime.Before(cutoff) {
				s.transferCooldown.Delete(key)
			}
		}
		return true
	})

	// Clean up old sessions (keep only recent MaxSessionHistory messages)
	s.sessions.Range(func(key, value interface{}) bool {
		if messages, ok := value.([]OpenAIMessage); ok {
			if len(messages) > MaxSessionHistory {
				// Keep only the most recent messages
				recentMessages := messages[len(messages)-MaxSessionHistory:]
				s.sessions.Store(key, recentMessages)
			}
		}
		return true
	})
}

// cleanupEnhancedSessions removes old enhanced session data to prevent memory leaks
func (s *service) cleanupEnhancedSessions() {
	cutoff := time.Now().Add(-2 * time.Hour) // Clean sessions older than 2 hours

	s.enhancedSessions.Range(func(key, value interface{}) bool {
		if session, ok := value.(*EnhancedSession); ok {
			if session.LastUpdated.Before(cutoff) {
				s.enhancedSessions.Delete(key)
			}
		}
		return true
	})

	// Clean up conversation summaries for deleted sessions
	s.conversationSummaries.Range(func(key, value interface{}) bool {
		if _, exists := s.enhancedSessions.Load(key); !exists {
			s.conversationSummaries.Delete(key)
		}
		return true
	})
}

// cleanupFieldStates removes old field state data to prevent memory leaks
func (s *service) cleanupFieldStates() {
	cutoff := time.Now().Add(-24 * time.Hour) // Clean field states older than 24 hours

	s.fieldStateCache.Range(func(key, value interface{}) bool {
		if fieldState, ok := value.(*SessionFieldState); ok {
			if fieldState.LastUpdated.Before(cutoff) {
				s.fieldStateCache.Delete(key)
			}
		}
		return true
	})
}

// startBackgroundTasks starts background maintenance tasks
func (s *service) startBackgroundTasks(ctx context.Context) {
	// Session cleanup task
	go func() {
		ticker := time.NewTicker(SessionCleanupInterval)
		defer ticker.Stop()

		for {
			select {
			case <-ctx.Done():
				return
			case <-ticker.C:
				s.cleanupOldSessions()
				s.logger.With(ctx).Info("ðŸ§¹ Completed session cleanup")
			}
		}
	}()

	// Enhanced session cleanup task (runs every 30 minutes)
	go func() {
		ticker := time.NewTicker(30 * time.Minute)
		defer ticker.Stop()

		for {
			select {
			case <-ctx.Done():
				return
			case <-ticker.C:
				s.cleanupEnhancedSessions()
				s.logger.With(ctx).Info("ðŸ§¹ Completed enhanced session cleanup")
			}
		}
	}()

	// Field state cleanup task (runs every hour)
	go func() {
		ticker := time.NewTicker(1 * time.Hour)
		defer ticker.Stop()

		for {
			select {
			case <-ctx.Done():
				return
			case <-ticker.C:
				s.cleanupFieldStates()
				s.logger.With(ctx).Info("ðŸ§¹ Completed field state cleanup")
			}
		}
	}()

	// Behavior cache cleanup task (runs every hour)
	go func() {
		ticker := time.NewTicker(1 * time.Hour)
		defer ticker.Stop()

		for {
			select {
			case <-ctx.Done():
				return
			case <-ticker.C:
				s.cleanupBehaviorCache()
				s.logger.With(ctx).Info("ðŸ§¹ Completed behavior cache cleanup")
			}
		}
	}()
}

// shouldAnalyzeForPaymentProof determines if we should analyze images for bank transfer slips
// Enhanced logic to check conversation context with cooldown protection
// Caption is used for context but does NOT affect confidence in payment detection
func (s *service) shouldAnalyzeForPaymentProof(ctx context.Context, sessionID string, caption string) bool {
	if sessionID == "" {
		s.logger.With(ctx).Info("âŒ Payment detection skipped: empty session ID")
		return false
	}

	// Check cooldown to prevent rapid successive payment detections (reduced to 2 seconds)
	paymentCooldown := 2 * time.Second
	if lastDetection, exists := s.paymentDetectionCooldown.Load(sessionID); exists {
		if lastTime, ok := lastDetection.(time.Time); ok {
			if time.Since(lastTime) < paymentCooldown {
				s.logger.With(ctx).Info("â° Payment detection cooldown active", "session_id", sessionID, "remaining", paymentCooldown-time.Since(lastTime))
				return false
			}
		}
	}

	// Caption is logged for context but does NOT determine payment analysis confidence
	if caption != "" {
		s.logger.With(ctx).Info("ðŸ“ Image caption provided (for context only)", "session_id", sessionID, "caption", caption)
	} else {
		s.logger.With(ctx).Info("ðŸ“ No caption provided with image", "session_id", sessionID)
	}

	// Get recent conversation history
	var conversationHistory []OpenAIMessage
	if history, exists := s.sessions.Load(sessionID); exists {
		if historyMessages, ok := history.([]OpenAIMessage); ok {
			conversationHistory = historyMessages
		}
	}

	// Look at the last few messages to determine context
	recentMessages := ""
	messageCount := len(conversationHistory)
	startIndex := messageCount - 6 // Look at last 6 messages (3 exchanges)
	if startIndex < 0 {
		startIndex = 0
	}

	for i := startIndex; i < messageCount; i++ {
		msg := conversationHistory[i]
		if msg.Role == "user" {
			if content, ok := msg.Content.(string); ok {
				recentMessages += "Customer: " + content + "\n"
			}
		} else if msg.Role == "assistant" {
			if content, ok := msg.Content.(string); ok {
				recentMessages += "AI: " + content + "\n"
			}
		}
	}

	// Check if AI recently asked for payment proof (expanded patterns)
	aiRequestPatterns := []string{
		"kirimkan bukti transfer", "send the transfer proof", "upload bukti pembayaran",
		"foto struk atm", "screenshot mobile banking", "bukti pembayaran",
		"mohon kirimkan bukti", "please upload proof", "tolong foto struk",
		"silakan kirim bukti", "please send proof", "upload payment proof",
		"kirim foto struk", "send receipt photo", "bukti transfer yang jelas",
		"screenshot pembayaran", "payment screenshot", "foto bukti bayar",
		"setelah transfer, tolong kirim", "after transfer, please send",
		"bisa foto struk", "can you photo the receipt", "kirim bukti transfernya",
		"transfer ke rekening", "transfer to account", "silakan transfer",
		"mohon transfer", "please transfer", "bayar ke", "pay to",
		"rekening", "account", "pembayaran", "payment", "transfer",
		"bukti", "proof", "struk", "receipt", "slip",
	}

	recentMessagesLower := strings.ToLower(recentMessages)
	for _, pattern := range aiRequestPatterns {
		if strings.Contains(recentMessagesLower, strings.ToLower(pattern)) {
			s.logger.With(ctx).Info("ðŸ¤– AI payment proof request detected for image analysis", "session_id", sessionID, "pattern", pattern)
			return true
		}
	}

	// Check if customer recently mentioned completing payment (expanded keywords)
	customerPaymentKeywords := []string{
		"sudah transfer", "already transferred", "sudah bayar", "already paid",
		"pembayaran selesai", "payment completed", "transfer berhasil", "transfer successful",
		"sudah kirim uang", "already sent money", "uang sudah masuk", "money already in",
		"ini buktinya", "nih buktinya", "here's the proof", "bukti transfer", "transfer proof",
		"sudah transfer nih", "just transferred", "baru transfer", "just paid",
		"ini struk", "here's receipt", "foto struk", "receipt photo",
		"screenshot", "ss", "bukti", "proof", "struk", "receipt",
		"transfer", "bayar", "pay", "lunas", "paid off",
		"selesai", "done", "berhasil", "success", "sukses",
	}

	for _, keyword := range customerPaymentKeywords {
		if strings.Contains(recentMessagesLower, strings.ToLower(keyword)) {
			s.logger.With(ctx).Info("ðŸ’° Customer payment completion detected for image analysis", "session_id", sessionID, "keyword", keyword)
			return true
		}
	}

	// Check if caption suggests payment content (fallback detection)
	if caption != "" {
		captionLower := strings.ToLower(caption)
		paymentCaptionKeywords := []string{
			"transfer", "bayar", "pay", "bukti", "proof", "struk", "receipt",
			"bank", "atm", "mobile banking", "m-banking", "bca", "bni", "bri", "mandiri",
			"dana", "ovo", "gopay", "shopeepay", "linkaja", "jenius",
			"pembayaran", "payment", "transaksi", "transaction",
		}

		for _, keyword := range paymentCaptionKeywords {
			if strings.Contains(captionLower, keyword) {
				s.logger.With(ctx).Info("ðŸ’¡ Payment-related caption detected, enabling payment analysis", "session_id", sessionID, "keyword", keyword, "caption", caption)
				return true
			}
		}
	}

	// More restrictive fallback: only trigger if there's explicit payment/transfer context
	// Remove overly broad business terms that cause false positives
	paymentSpecificTerms := []string{
		"transfer ke rekening", "transfer to account", "silakan transfer ke",
		"mohon transfer ke", "please transfer to", "bayar ke rekening",
		"payment to account", "kirim ke rekening", "send to account",
		"setelah transfer", "after transfer", "sudah transfer", "already transferred",
		"konfirmasi pembayaran", "payment confirmation", "bukti pembayaran",
		"proof of payment", "transfer berhasil", "transfer successful",
	}

	for _, term := range paymentSpecificTerms {
		if strings.Contains(recentMessagesLower, strings.ToLower(term)) {
			s.logger.With(ctx).Info("ðŸ’¼ Specific payment context detected, enabling payment analysis", "session_id", sessionID, "term", term)
			return true
		}
	}

	// Only skip analysis if no context was found at all
	s.logger.With(ctx).Info("âŒ No payment context detected, skipping payment analysis", "session_id", sessionID, "caption", caption)
	return false
}

// extractImageURLs extracts image URLs from text using regex patterns
func (s *service) extractImageURLs(text string) []string {
	// First, let's handle backtick-wrapped URLs by preprocessing the text
	backtickPattern := regexp.MustCompile("`([^`]+)`")
	backtickMatches := backtickPattern.FindAllStringSubmatch(text, -1)

	// Define regex patterns for different types of image URLs
	patterns := []*regexp.Regexp{
		// S3 URLs (AWS S3 bucket URLs)
		regexp.MustCompile(`https?://[\w\-\.]+\.s3[\w\-\.]*\.amazonaws\.com/[\w\-\./\%]+\.(jpg|jpeg|png|gif|webp|bmp|tiff)(?:\?[\w\-\=\&]*)?`),
		// Generic HTTPS image URLs
		regexp.MustCompile(`https?://[\w\-\.]+(:[0-9]+)?/[\w\-\./\%]*\.(jpg|jpeg|png|gif|webp|bmp|tiff)(?:\?[\w\-\=\&]*)?`),
		// Data URLs for images
		regexp.MustCompile(`data:image/[\w\-]+;base64,[A-Za-z0-9+/=]+`),
	}

	var imageURLs []string

	// First check backtick-wrapped content
	for _, backtickMatch := range backtickMatches {
		if len(backtickMatch) > 1 {
			content := backtickMatch[1]
			for _, pattern := range patterns {
				if pattern.MatchString(content) {
					// Check if URL is not already in the list
					found := false
					for _, existing := range imageURLs {
						if existing == content {
							found = true
							break
						}
					}
					if !found {
						imageURLs = append(imageURLs, content)
					}
					break
				}
			}
		}
	}

	// Then check the entire text for non-backtick URLs
	for _, pattern := range patterns {
		matches := pattern.FindAllString(text, -1)
		for _, match := range matches {
			// Check if URL is not already in the list
			found := false
			for _, existing := range imageURLs {
				if existing == match {
					found = true
					break
				}
			}
			if !found {
				imageURLs = append(imageURLs, match)
			}
		}
	}

	return imageURLs
}

// TransferAnalysis represents the AI's analysis of transfer conditions
type TransferAnalysis struct {
	ShouldTransfer bool    `json:"should_transfer"`
	Reason         string  `json:"reason"`
	ExtractedInfo  string  `json:"extracted_info"`
	PotentialValue float64 `json:"potential_value"`
	Confidence     string  `json:"confidence"`
	TargetPipeline string  `json:"target_pipeline,omitempty"` // Pipeline name to transfer to
	TransferType   string  `json:"transfer_type,omitempty"`   // "next_stage" or "pipeline"
}

// evaluateAndHandleTransferConditions evaluates if transfer conditions are met and handles the transfer
func (s *service) evaluateAndHandleTransferConditions(ctx context.Context, db *dbcontext.DB, agentID uuid.UUID, aiSettings *entity.AISettings, userMessage, aiResponse, sessionID, phoneNumber string) error {
	// Check transfer cooldown to prevent rapid successive transfers

	// Log evaluation attempt for debugging
	s.logger.With(ctx).Info("ðŸ” Starting transfer evaluation:", "agent_id:", agentID, "session_id:", sessionID, "user_message:", userMessage, "has_transfer_condition:", aiSettings.TransferCondition != "")

	// Extract and update customer information from conversation
	if phoneNumber != "" {
		err := s.extractAndUpdateCustomerInfo(ctx, db, phoneNumber, userMessage, aiResponse, sessionID)
		if err != nil {
			s.logger.With(ctx).Error("Failed to extract and update customer info:", "agent_id:", agentID, "session_id:", sessionID, "phone_number:", phoneNumber, "error:", err)
			// Don't fail the whole process if customer info extraction fails
		}
	}

	if aiSettings.TransferCondition == "" {
		s.logger.With(ctx).Info("No transfer condition set, skipping evaluation:", "agent_id:", agentID, "session_id:", sessionID)
		return nil // No transfer condition set
	}

	// Get conversation history for context
	var conversationHistory []OpenAIMessage
	if history, exists := s.sessions.Load(sessionID); exists {
		if historyMessages, ok := history.([]OpenAIMessage); ok {
			conversationHistory = historyMessages
		}
	}

	// Check for payment validation conditions and image analysis conflicts
	if s.isPaymentValidationCondition(aiSettings.TransferCondition) {
		// For payment validation, check if there's conflicting image analysis
		if s.hasConflictingImageAnalysis(conversationHistory, aiResponse) {
			s.logger.With(ctx).Info("âŒ Payment validation blocked: Image analysis indicates invalid payment", "session_id:", sessionID)
			return nil // Block transfer due to conflicting analysis
		}
	}

	// Evaluate transfer condition using AI
	analysis, err := s.evaluateTransferCondition(ctx, aiSettings.TransferCondition, userMessage, aiResponse, conversationHistory)
	if err != nil {
		return fmt.Errorf("failed to evaluate transfer condition: %w", err)
	}

	if !analysis.ShouldTransfer {
		return nil // Conditions not met
	}

	// Find lead associated with this phone number to progress
	err = s.progressLeadToNextStage(ctx, db, agentID, phoneNumber, analysis)
	if err != nil {
		return fmt.Errorf("failed to progress lead to next stage: %w", err)
	}

	// Set transfer cooldown to prevent rapid successive transfers
	s.transferCooldown.Store(sessionID, time.Now())

	s.logger.With(ctx).Info("ðŸ”„ Lead transferred to next stage:", "agent_id:", agentID, "session_id:", sessionID, "reason:", analysis.Reason, "extracted_info:", analysis.ExtractedInfo, "potential_value:", analysis.PotentialValue, "confidence:", analysis.Confidence)
	return nil
}

// evaluateTransferCondition uses efficient rule-based + AI evaluation
func (s *service) evaluateTransferCondition(ctx context.Context, transferCondition, userMessage, aiResponse string, conversationHistory []OpenAIMessage) (*TransferAnalysis, error) {
	// // First try rule-based evaluation (no tokens used)
	// ruleResult := s.evaluateTransferByRules(transferCondition, userMessage, aiResponse)
	// if ruleResult.Confidence == "high" {
	// 	s.logger.With(ctx).Info("ðŸ” Transfer evaluation (rule-based):", "should_transfer:", ruleResult.ShouldTransfer, "reason:", ruleResult.Reason, "confidence:", ruleResult.Confidence)
	// 	return ruleResult, nil
	// }

	// Only use AI for uncertain cases
	s.logger.With(ctx).Info("ðŸ¤– Using AI for uncertain transfer evaluation:", "user_message:", userMessage, "transfer_condition:", transferCondition)
	return s.evaluateTransferByAI(ctx, transferCondition, userMessage, aiResponse, conversationHistory)
}

// evaluateTransferByRules uses keyword-based rules for fast evaluation
func (s *service) evaluateTransferByRules(transferCondition, userMessage, aiResponse string) *TransferAnalysis {
	msgLower := strings.ToLower(userMessage)
	aiResponseLower := strings.ToLower(aiResponse)
	conditionLower := strings.ToLower(transferCondition)

	// First, check for high confidence NO-TRANSFER cases (product inquiries)
	// These should NEVER trigger transfers regardless of other keywords
	productInquiryKeywords := []string{
		"harga", "price", "produk", "product", "size", "ukuran",
		"warna", "color", "stock", "stok", "available", "tersedia",
		"katalog", "catalog", "list", "daftar", "lihat", "show",
		"semua produk", "all products", "ada apa", "what do you have",
		"apa saja", "what are", "berapa", "how much", "info", "informasi",
		"spesifikasi", "specification", "detail", "feature", "fitur",
		"recommend", "rekomen", "suggest", "saran", "pilihan", "options",
		"browse", "browsing", "jelajah", "cari", "search", "find",
	}

	for _, keyword := range productInquiryKeywords {
		if strings.Contains(msgLower, keyword) {
			s.logger.Info("ðŸ›¡ï¸ Product inquiry detected - blocking transfer:", "keyword:", keyword, "message:", userMessage)
			return &TransferAnalysis{
				ShouldTransfer: false,
				Reason:         fmt.Sprintf("Product inquiry detected: %s", keyword),
				ExtractedInfo:  "Customer browsing products",
				PotentialValue: 0,
				Confidence:     "high",
			}
		}
	}

	// Check for casual conversation patterns that should NOT trigger transfers
	casualConversationPatterns := []string{
		"halo", "hello", "hi", "hai", "selamat", "good morning", "good afternoon",
		"terima kasih", "thank you", "thanks", "makasih", "ok", "oke", "baik",
		"iya", "yes", "ya", "sure", "siap", "ready", "boleh", "can", "bisa",
	}

	for _, pattern := range casualConversationPatterns {
		if strings.Contains(msgLower, pattern) && len(strings.Fields(userMessage)) <= 3 {
			s.logger.Info("ðŸ›¡ï¸ Casual conversation detected - blocking transfer:", "pattern:", pattern, "message:", userMessage)
			return &TransferAnalysis{
				ShouldTransfer: false,
				Reason:         "Casual conversation",
				ExtractedInfo:  "Customer engaging in casual chat",
				PotentialValue: 0,
				Confidence:     "high",
			}
		}
	}

	// Only check for GENUINE issue keywords with context validation
	genuineIssueKeywords := []string{
		"komplain", "complaint", "refund", "return money", "cancel order", "batal pesanan",
		"very angry", "sangat marah", "very disappointed", "sangat kecewa",
		"speak to manager", "bicara dengan manager", "human agent", "agen manusia",
		"not satisfied", "tidak puas", "big problem", "masalah besar",
	}

	// Require multiple indicators or strong context for issue detection
	issueIndicators := 0
	for _, keyword := range genuineIssueKeywords {
		if strings.Contains(msgLower, keyword) {
			issueIndicators++
		}
	}

	// Only transfer for genuine issues with strong indicators
	if issueIndicators >= 1 && (strings.Contains(msgLower, "manager") || strings.Contains(msgLower, "human") || strings.Contains(msgLower, "refund")) {
		return &TransferAnalysis{
			ShouldTransfer: true,
			Reason:         "Genuine customer issue detected",
			ExtractedInfo:  fmt.Sprintf("Customer issue: %s", userMessage),
			PotentialValue: 0,
			Confidence:     "high",
		}
	}

	// Check for payment validation scenarios
	if strings.Contains(conditionLower, "valid") && (strings.Contains(conditionLower, "payment") || strings.Contains(conditionLower, "transfer") || strings.Contains(conditionLower, "slip")) {
		// First check for AI rejection of payment validity
		// Use more precise matching to avoid false positives
		paymentRejectionKeywords := []string{
			"not valid", "tidak valid", "bukan slip pembayaran",
			"tampaknya bukan", "not a payment", "not a transfer", "bukan bukti",
			"tolong kirim ulang", "please send again", "kirim foto yang jelas",
			"not a receipt", "bukan struk", "maaf", "sorry",
		}

		// Check for rejection keywords with context to avoid false positives
		for _, keyword := range paymentRejectionKeywords {
			if strings.Contains(aiResponseLower, keyword) {
				return &TransferAnalysis{
					ShouldTransfer: false,
					Reason:         "AI rejected payment validity",
					ExtractedInfo:  "Payment validation failed - AI indicated invalid payment",
					PotentialValue: 0,
					Confidence:     "high",
				}
			}
		}

		// Separate check for 'invalid' to ensure it's not part of 'valid'
		if strings.Contains(aiResponseLower, "invalid") && !strings.Contains(aiResponseLower, "valid payment") && !strings.Contains(aiResponseLower, "payment is valid") {
			return &TransferAnalysis{
				ShouldTransfer: false,
				Reason:         "AI rejected payment validity (invalid)",
				ExtractedInfo:  "Payment validation failed - AI indicated invalid payment",
				PotentialValue: 0,
				Confidence:     "high",
			}
		}

		// Only check for confirmation if no rejection was found
		paymentConfirmationKeywords := []string{
			"pembayaran diterima", "payment received", "valid payment", "pembayaran valid",
			"terima kasih sudah mengirimkan", "bukti transfer", "transfer berhasil",
			"pembayaran berhasil", "payment successful", "pesanan akan segera",
		}
		for _, keyword := range paymentConfirmationKeywords {
			if strings.Contains(aiResponseLower, keyword) {
				return &TransferAnalysis{
					ShouldTransfer: true,
					Reason:         "AI confirmed valid payment",
					ExtractedInfo:  "Payment validation completed by AI",
					PotentialValue: 0,
					Confidence:     "high",
				}
			}
		}
	}

	// Check for order completion signals (only if transfer condition mentions purchase/order)
	if strings.Contains(conditionLower, "purchase") || strings.Contains(conditionLower, "order") {
		completionSignals := []string{"itu saja", "sudah cukup", "tidak ada lagi", "cukup", "selesai"}
		for _, signal := range completionSignals {
			if strings.Contains(msgLower, signal) && strings.Contains(aiResponseLower, "ada produk lain") {
				return &TransferAnalysis{
					ShouldTransfer: true,
					Reason:         "Order completion confirmed",
					ExtractedInfo:  "Customer completed order process",
					PotentialValue: 0,
					Confidence:     "high",
				}
			}
		}
	}

	// Check for name provision (only if transfer condition mentions name)
	if strings.Contains(conditionLower, "name") || strings.Contains(conditionLower, "nama") {
		namePatterns := []string{"nama saya", "my name is", "i'm", "i am"}
		for _, pattern := range namePatterns {
			if strings.Contains(msgLower, pattern) {
				return &TransferAnalysis{
					ShouldTransfer: true,
					Reason:         "Customer provided name",
					ExtractedInfo:  fmt.Sprintf("Customer name from: %s", userMessage),
					PotentialValue: 0,
					Confidence:     "high",
				}
			}
		}
	}

	// Default: uncertain, needs AI evaluation (but bias towards NO transfer)
	return &TransferAnalysis{
		ShouldTransfer: false,
		Reason:         "No clear transfer indicators found",
		ExtractedInfo:  "",
		PotentialValue: 0,
		Confidence:     "medium",
	}
}

// evaluateTransferByAI uses AI for uncertain cases only
func (s *service) evaluateTransferByAI(ctx context.Context, transferCondition, userMessage, aiResponse string, conversationHistory []OpenAIMessage) (*TransferAnalysis, error) {
	// Build conversation context for better evaluation
	conversationContext := ""
	for i, msg := range conversationHistory {
		if i >= len(conversationHistory)-6 { // Only last 6 messages for token efficiency
			if msg.Role == "user" {
				conversationContext += fmt.Sprintf("User: %s\n", msg.Content)
			} else if msg.Role == "assistant" {
				conversationContext += fmt.Sprintf("AI: %s\n", msg.Content)
			}
		}
	}

	// Detect pipeline transfer conditions
	transferType := "next_stage"
	targetPipeline := ""

	// Check for pipeline transfer patterns in the transfer condition
	conditionLower := strings.ToLower(transferCondition)
	if strings.Contains(conditionLower, "transfer to") && strings.Contains(conditionLower, "pipeline") {
		transferType = "pipeline"
		// Extract pipeline name from condition
		if strings.Contains(conditionLower, "pengaduan pipeline") {
			targetPipeline = "Pengaduan"
		} else if strings.Contains(conditionLower, "pelanggan baru pipeline") {
			targetPipeline = "Pelanggan Baru"
		} else if strings.Contains(conditionLower, "pelanggan lama pipeline") {
			targetPipeline = "Pelanggan Lama"
		}
	}

	// Flexible transfer evaluation prompt optimized for token efficiency
	evaluationPrompt := fmt.Sprintf(`TRANSFER EVALUATION

Condition: %s
User: %s
AI: %s
Context: %s

RULES:
1. Analyze if the exact condition is met based on user input and AI validation
2. Evidence required: actual proof/data/selection, not just discussion
3. AI confirmation only valid if user provided required evidence
4. Conservative approach: doubt = no transfer
5. Payment conditions need actual payment proof (screenshots, receipts)
6. Selection conditions need explicit user choice/statement

JSON: {"should_transfer":false,"reason":"brief","extracted_info":"","potential_value":0,"confidence":"high/medium/low","transfer_type":"%s","target_pipeline":"%s"}`,
		transferCondition, userMessage, aiResponse, conversationContext, transferType, targetPipeline)

	messages := []OpenAIMessage{{
		Role:    "user",
		Content: evaluationPrompt,
	}}

	settings := &entity.AISettings{

		Model: "gpt-4.1-mini", // Use gpt-4.1-mini for better reasoning in transfer evaluation
	}

	// Get token tracker from context or create a new one for tracking this evaluation
	tokenTracker := accesslog.GetTokenTrackerFromContext(ctx)
	if tokenTracker == nil {
		requestID := uuid.New().String()
		tokenTracker = accesslog.NewTokenTracker(requestID)
		s.logger.With(ctx).Infof("ðŸ”¢ Created token tracker for transfer evaluation: %s", requestID)
	}

	resp, err := s.callOpenAI(ctx, messages, settings, "transfer evaluation", len(evaluationPrompt), tokenTracker, "transfer_evaluation")
	if err != nil {
		// Fallback to rule-based result
		return &TransferAnalysis{
			ShouldTransfer: false,
			Reason:         "AI evaluation failed, defaulting to no transfer",
			ExtractedInfo:  "",
			PotentialValue: 0,
			Confidence:     "low",
		}, nil
	}

	// Log AI usage for transfer evaluation (specific operation, separate from main conversation flow)
	s.logAIUsage(ctx, settings.Model, resp.Usage.TotalTokens, "transfer_evaluation", "", uuid.Nil, "", "internal")

	// NOTE: Model usage tracking is handled by the main conversation flow to avoid double tracking

	// Log credit usage for transfer evaluation
	tenantID := token.GetTenantID(ctx)
	userID := token.GetUserID(ctx)
	tokensUsed := resp.Usage.TotalTokens
	s.logger.With(ctx).Infof("Credit usage - Transfer Evaluation | TenantID: %s | UserID: %s | Model: %s | TokensUsed: %d", tenantID, userID, settings.Model, tokensUsed)

	if len(resp.Choices) == 0 {
		return &TransferAnalysis{
			ShouldTransfer: false,
			Reason:         "No AI response",
			ExtractedInfo:  "",
			PotentialValue: 0,
			Confidence:     "low",
		}, nil
	}

	var analysis TransferAnalysis
	err = json.Unmarshal([]byte(resp.Choices[0].Message.Content), &analysis)
	if err != nil {
		s.logger.With(ctx).Error("Failed to parse transfer analysis response:", "raw_response:", resp.Choices[0].Message.Content, "parse_error:", err)
		return &TransferAnalysis{
			ShouldTransfer: false,
			Reason:         "Parse error, defaulting to no transfer",
			ExtractedInfo:  "",
			PotentialValue: 0,
			Confidence:     "low",
		}, nil
	}

	s.logger.With(ctx).Info("Transfer condition evaluation completed:", "should_transfer:", analysis.ShouldTransfer, "reason:", analysis.Reason, "confidence:", analysis.Confidence)
	return &analysis, nil
}

// processResponsePlaceholders processes placeholders in AI responses like [TOTAL], [JUMLAH], [DAFTAR_LENGKAP_PRODUK]
func (s *service) processResponsePlaceholders(ctx context.Context, db *dbcontext.DB, response, sessionID string) (string, error) {
	// Check if response contains any placeholders
	if !strings.Contains(response, "[TOTAL]") && !strings.Contains(response, "[JUMLAH]") && !strings.Contains(response, "[DAFTAR_LENGKAP_PRODUK]") {
		return response, nil
	}

	// Get conversation history for context
	var conversationHistory []OpenAIMessage
	if history, exists := s.sessions.Load(sessionID); exists {
		if historyMessages, ok := history.([]OpenAIMessage); ok {
			conversationHistory = historyMessages
		}
	}

	// Build conversation context
	conversationContext := ""
	for _, msg := range conversationHistory {
		if msg.Role == "user" {
			conversationContext += fmt.Sprintf("Customer: %s\n", msg.Content)
		} else if msg.Role == "assistant" {
			conversationContext += fmt.Sprintf("AI: %s\n", msg.Content)
		}
	}

	// Extract order information from conversation
	orderInfo, err := s.extractOrderFromConversation(ctx, db, conversationContext)
	if err != nil {
		s.logger.With(ctx).Errorf("Failed to extract order from conversation: %v", err)
		return response, nil // Return original response if extraction fails
	}

	// Replace placeholders
	processedResponse := response
	if orderInfo != nil {
		// Replace [DAFTAR_LENGKAP_PRODUK] with formatted product list
		if strings.Contains(processedResponse, "[DAFTAR_LENGKAP_PRODUK]") {
			productList := s.formatProductList(orderInfo.Products)
			processedResponse = strings.ReplaceAll(processedResponse, "[DAFTAR_LENGKAP_PRODUK]", productList)
		}

		// Replace [TOTAL] and [JUMLAH] with calculated total
		// Use formatCurrencyWithoutPrefix since templates already include "Rp"
		totalFormatted := s.formatCurrencyWithoutPrefix(orderInfo.Total)
		processedResponse = strings.ReplaceAll(processedResponse, "[TOTAL]", totalFormatted)
		processedResponse = strings.ReplaceAll(processedResponse, "[JUMLAH]", totalFormatted)
	}

	return processedResponse, nil
}

// OrderInfo represents extracted order information
type OrderInfo struct {
	Products []ProductOrder `json:"products"`
	Total    float64        `json:"total"`
}

// ProductOrder represents a product in an order
type ProductOrder struct {
	Name     string  `json:"name"`
	SKU      string  `json:"sku"`
	Quantity int     `json:"quantity"`
	Price    float64 `json:"price"`
	Subtotal float64 `json:"subtotal"`
}

// extractOrderFromConversation extracts order information from conversation history
func (s *service) extractOrderFromConversation(ctx context.Context, db *dbcontext.DB, conversationContext string) (*OrderInfo, error) {
	// First try simple regex extraction for common patterns
	orderInfo := s.extractOrderByRegex(conversationContext)
	if orderInfo != nil && len(orderInfo.Products) > 0 {
		return orderInfo, nil
	}

	// Only use AI if regex extraction fails
	return s.extractOrderByAI(ctx, conversationContext)
}

// extractOrderByRegex uses regex patterns for fast order extraction
func (s *service) extractOrderByRegex(conversationContext string) *OrderInfo {
	lines := strings.Split(conversationContext, "\n")
	var products []ProductOrder

	// Common order patterns
	orderPatterns := []*regexp.Regexp{
		regexp.MustCompile(`(?i)(saya mau|mau|pesan|ambil|beli)\s+(\d+)\s+([\w\s]+)`),
		regexp.MustCompile(`(?i)(\d+)\s+(\w+[\w\s]*?)\s*(?:dong|ya|aja|saja)?`),
	}

	for _, line := range lines {
		if !strings.Contains(strings.ToLower(line), "customer:") {
			continue
		}

		for _, pattern := range orderPatterns {
			matches := pattern.FindStringSubmatch(line)
			if len(matches) >= 4 {
				quantity, err := strconv.Atoi(matches[2])
				if err != nil {
					continue
				}
				productName := strings.TrimSpace(matches[3])
				if len(productName) > 2 { // Avoid single characters
					products = append(products, ProductOrder{
						Name:     productName,
						Quantity: quantity,
						Price:    0, // Will be looked up
					})
				}
			}
		}
	}

	if len(products) == 0 {
		return nil
	}

	return &OrderInfo{
		Products: products,
		Total:    0, // Will be calculated after price lookup
	}
}

// extractOrderByAI uses AI for complex order extraction
func (s *service) extractOrderByAI(ctx context.Context, conversationContext string) (*OrderInfo, error) {
	// Ultra-compressed extraction prompt
	extractionPrompt := fmt.Sprintf(`Extract confirmed orders from: %s\nJSON: {"products":[{"name":"text","quantity":1}],"has_confirmed_products":bool}`,
		conversationContext)

	messages := []OpenAIMessage{{
		Role:    "user",
		Content: extractionPrompt,
	}}

	settings := &entity.AISettings{
		Model: "gpt-4.1-nano",
	}

	// Get token tracker from context or create a new one for tracking this evaluation
	tokenTracker := accesslog.GetTokenTrackerFromContext(ctx)
	if tokenTracker == nil {
		requestID := uuid.New().String()
		tokenTracker = accesslog.NewTokenTracker(requestID)
		s.logger.With(ctx).Infof("ðŸ”¢ Created token tracker for order extraction: %s", requestID)
	}

	resp, err := s.callOpenAI(ctx, messages, settings, "order extraction", len(extractionPrompt), tokenTracker, "order_extraction")
	if err != nil {
		return nil, fmt.Errorf("failed to call OpenAI for order extraction: %w", err)
	}

	// Log AI usage for order extraction (specific operation, separate from main conversation flow)
	s.logAIUsage(ctx, settings.Model, resp.Usage.TotalTokens, "order_extraction", "", uuid.Nil, "", "internal")

	// NOTE: Model usage tracking is handled by the main conversation flow to avoid double tracking

	if len(resp.Choices) == 0 {
		return nil, fmt.Errorf("no response from OpenAI")
	}

	// Parse the JSON response
	var extractionResult struct {
		Products []struct {
			Name             string `json:"name"`
			SKU              string `json:"sku"`
			Quantity         int    `json:"quantity"`
			NeedsPriceLookup bool   `json:"needs_price_lookup"`
		} `json:"products"`
		HasConfirmedProducts bool `json:"has_confirmed_products"`
	}

	err = json.Unmarshal([]byte(resp.Choices[0].Message.Content), &extractionResult)
	if err != nil {
		s.logger.With(ctx).Error("Failed to parse order extraction response:", "raw_response:", resp.Choices[0].Message.Content, "parse_error:", err)
		return nil, fmt.Errorf("failed to parse order extraction response: %w", err)
	}

	if !extractionResult.HasConfirmedProducts || len(extractionResult.Products) == 0 {
		return nil, nil // No confirmed products found
	}

	// Get tenant database connection
	tenantDB, _, err := dbcontext.GetTenantDB(ctx, s.dbManager)
	if err != nil {
		return nil, fmt.Errorf("failed to get tenant database: %w", err)
	}

	// Create product service for price lookup
	productRepo := product.NewRepository(tenantDB)
	productService := product.NewService(productRepo, s.dbManager, s.logger)

	// Process each product and get prices from knowledge base
	var processedProducts []ProductOrder
	totalAmount := 0.0

	for _, extractedProduct := range extractionResult.Products {
		if !extractedProduct.NeedsPriceLookup {
			continue
		}

		// Search for product by name in knowledge base
		productInfo, err := s.findProductByName(ctx, tenantDB, productService, extractedProduct.Name)
		if err != nil {
			s.logger.With(ctx).Errorf("Failed to find product '%s': %v", extractedProduct.Name, err)
			continue
		}

		if productInfo == nil {
			s.logger.With(ctx).Errorf("Product '%s' not found in knowledge base", extractedProduct.Name)
			continue
		}

		// Calculate subtotal - handle nullable price
		var price float64
		if productInfo.Price != nil {
			price = *productInfo.Price
		} else {
			price = 0
		}
		subtotal := float64(extractedProduct.Quantity) * price
		totalAmount += subtotal

		processedProducts = append(processedProducts, ProductOrder{
			Name:     productInfo.Name,
			SKU:      productInfo.SKU,
			Quantity: extractedProduct.Quantity,
			Price:    price,
			Subtotal: subtotal,
		})
	}

	if len(processedProducts) == 0 {
		return nil, nil // No valid products found
	}

	return &OrderInfo{
		Products: processedProducts,
		Total:    totalAmount,
	}, nil
}

// findProductByName searches for a product by name in the knowledge base
func (s *service) findProductByName(ctx context.Context, db *dbcontext.DB, productService product.Service, productName string) (*entity.Product, error) {
	// Get all products and search by name (case-insensitive)
	products, err := productService.GetProducts(ctx)
	if err != nil {
		return nil, fmt.Errorf("failed to get products: %w", err)
	}

	// Convert ProductWithCategoryResponse to entity.Product for searching
	var entityProducts []entity.Product
	for _, productResp := range products {
		entityProduct := entity.Product{
			ID:          productResp.ID,
			IDCategory:  productResp.IDCategory,
			SKU:         productResp.SKU,
			Name:        productResp.Name,
			Description: productResp.Description,
			Stock:       productResp.Stock,
			Price:       productResp.Price,
			Status:      productResp.Status,
			CreatedAt:   productResp.CreatedAt,
			UpdatedAt:   productResp.UpdatedAt,
		}
		entityProducts = append(entityProducts, entityProduct)
	}

	// Normalize search term
	searchName := strings.ToLower(strings.TrimSpace(productName))

	// First try exact match
	for _, product := range products {
		if strings.ToLower(product.Name) == searchName {
			// Convert ProductWithCategoryResponse to entity.Product
			entityProduct := &entity.Product{
				ID:          product.ID,
				IDCategory:  product.IDCategory,
				SKU:         product.SKU,
				Name:        product.Name,
				Description: product.Description,
				Stock:       product.Stock,
				Price:       product.Price,
				Status:      product.Status,
				CreatedAt:   product.CreatedAt,
				UpdatedAt:   product.UpdatedAt,
			}
			return entityProduct, nil
		}
	}

	// Then try partial match
	for _, product := range products {
		if strings.Contains(strings.ToLower(product.Name), searchName) {
			// Convert ProductWithCategoryResponse to entity.Product
			entityProduct := &entity.Product{
				ID:          product.ID,
				IDCategory:  product.IDCategory,
				SKU:         product.SKU,
				Name:        product.Name,
				Description: product.Description,
				Stock:       product.Stock,
				Price:       product.Price,
				Status:      product.Status,
				CreatedAt:   product.CreatedAt,
				UpdatedAt:   product.UpdatedAt,
			}
			return entityProduct, nil
		}
	}

	// Try reverse partial match (search term contains product name)
	for _, product := range products {
		if strings.Contains(searchName, strings.ToLower(product.Name)) {
			// Convert ProductWithCategoryResponse to entity.Product
			entityProduct := &entity.Product{
				ID:          product.ID,
				IDCategory:  product.IDCategory,
				SKU:         product.SKU,
				Name:        product.Name,
				Description: product.Description,
				Stock:       product.Stock,
				Price:       product.Price,
				Status:      product.Status,
				CreatedAt:   product.CreatedAt,
				UpdatedAt:   product.UpdatedAt,
			}
			return entityProduct, nil
		}
	}

	return nil, nil // Product not found
}

// formatProductList formats the product list for display
func (s *service) formatProductList(products []ProductOrder) string {
	if len(products) == 0 {
		return ""
	}

	var items []string
	for _, product := range products {
		priceFormatted := s.formatCurrency(product.Price)
		subtotalFormatted := s.formatCurrency(product.Subtotal)
		item := fmt.Sprintf("â€¢ %s (x%d) - %s = %s", product.Name, product.Quantity, priceFormatted, subtotalFormatted)
		items = append(items, item)
	}

	return strings.Join(items, "\n")
}

// formatCurrency formats a float64 amount as Indonesian Rupiah
func (s *service) formatCurrency(amount float64) string {
	return fmt.Sprintf("Rp %s", s.formatNumber(amount))
}

// formatCurrencyWithoutPrefix formats a float64 amount without the "Rp" prefix
// This is used for placeholders that already include "Rp" in the template
func (s *service) formatCurrencyWithoutPrefix(amount float64) string {
	return s.formatNumber(amount)
}

// formatNumber formats a number with thousand separators
func (s *service) formatNumber(amount float64) string {
	// Convert to integer for formatting (assuming no decimal places for IDR)
	amountInt := int64(amount)

	// Convert to string and add thousand separators
	amountStr := fmt.Sprintf("%d", amountInt)
	if len(amountStr) <= 3 {
		return amountStr
	}

	// Add dots as thousand separators
	var result []string
	for i, digit := range amountStr {
		if i > 0 && (len(amountStr)-i)%3 == 0 {
			result = append(result, ".")
		}
		result = append(result, string(digit))
	}

	return strings.Join(result, "")
}

// extractAndUpdateCustomerInfo extracts customer information from conversation and updates lead records
func (s *service) extractAndUpdateCustomerInfo(ctx context.Context, db *dbcontext.DB, phoneNumber, userMessage, aiResponse, sessionID string) error {
	// Get conversation history for context
	var conversationHistory []OpenAIMessage
	if history, exists := s.sessions.Load(sessionID); exists {
		if historyMessages, ok := history.([]OpenAIMessage); ok {
			conversationHistory = historyMessages
		}
	}

	// Build conversation context
	conversationContext := ""
	for _, msg := range conversationHistory {
		if msg.Role == "user" {
			conversationContext += fmt.Sprintf("Customer: %s\n", msg.Content)
		} else if msg.Role == "assistant" {
			conversationContext += fmt.Sprintf("AI: %s\n", msg.Content)
		}
	}
	conversationContext += fmt.Sprintf("Customer: %s\nAI: %s", userMessage, aiResponse)

	// Create extraction prompt
	extractionPrompt := fmt.Sprintf(`You are an intelligent customer information extractor for a CRM system. Your task is to analyze customer conversations and extract key personal information that should be stored in the customer's profile.

CONVERSATION HISTORY:
%s

CRITICAL EXTRACTION RULES:
1. ONLY extract customer's name if the CUSTOMER explicitly introduces themselves or states their name
2. DO NOT extract names that appear in AI responses or greetings (e.g., "Hai Kak Edgar" from AI)
3. DO NOT extract names unless the customer directly says something like "nama saya...", "I'm...", "call me...", etc.
4. Only extract information that the customer explicitly provided about themselves
5. Do not make assumptions or infer information from AI responses
6. When extracting names, use your natural language understanding to identify the actual person's name, filtering out casual words, slang, or filler words that aren't part of the formal name

Respond ONLY with a valid JSON object in this exact format:
{
  "has_new_info": true/false,
  "customer_name": "clean proper name or empty string",
  "additional_notes": "other relevant information or empty string"
}

Valid extraction examples (customer introduces themselves):
- Customer says: "nama saya edgar nih" â†’ extract "Edgar"
- Customer says: "saya john dong" â†’ extract "John"
- Customer says: "panggil aja sarah ya" â†’ extract "Sarah"
- Customer says: "I'm kak budi" â†’ extract "Budi"

Invalid extraction examples (DO NOT extract):
- AI says: "Hai Kak Edgar!" â†’ DO NOT extract "Edgar"
- AI says: "Halo John, bagaimana kabarnya?" â†’ DO NOT extract "John"
- Customer asks about product without introducing themselves â†’ DO NOT extract any name

Other information:
- If customer mentions preferences like "I like blue colors", note it in additional_notes
- If no new personal information is provided by the customer, set has_new_info to false`, conversationContext)

	// Call OpenAI for extraction
	messages := []OpenAIMessage{
		{
			Role:    "system",
			Content: extractionPrompt,
		},
	}

	settings := &entity.AISettings{
		Model: "gpt-4.1-nano", // Use gpt-4.1 for extraction
	}

	// For customer info extraction, use simple message analysis
	// Get token tracker from context or create a new one for tracking this evaluation
	tokenTracker := accesslog.GetTokenTrackerFromContext(ctx)
	if tokenTracker == nil {
		requestID := uuid.New().String()
		tokenTracker = accesslog.NewTokenTracker(requestID)
		s.logger.With(ctx).Infof("ðŸ”¢ Created token tracker for customer info extraction: %s", requestID)
	}

	resp, err := s.callOpenAI(ctx, messages, settings, "customer info extraction", len(extractionPrompt), tokenTracker, "customer_info_extraction")
	if err != nil {
		return fmt.Errorf("failed to call OpenAI for customer info extraction: %w", err)
	}

	// Log AI usage for customer info extraction (specific operation, separate from main conversation flow)
	s.logAIUsage(ctx, settings.Model, resp.Usage.TotalTokens, "customer_info_extraction", "", uuid.Nil, phoneNumber, "whatsapp")

	// Note: Token tracking is handled by the main conversation flow via tokenTracker

	// Log credit usage for customer info extraction
	tenantID := token.GetTenantID(ctx)
	userID := token.GetUserID(ctx)
	tokensUsed := resp.Usage.TotalTokens
	s.logger.With(ctx).Infof("Credit usage - Customer Info Extraction | TenantID: %s | UserID: %s | Model: %s | TokensUsed: %d | PhoneNumber: %s", tenantID, userID, settings.Model, tokensUsed, phoneNumber)

	if len(resp.Choices) == 0 {
		return fmt.Errorf("no response from OpenAI")
	}

	// Parse the JSON response
	var extraction struct {
		HasNewInfo      bool   `json:"has_new_info"`
		CustomerName    string `json:"customer_name"`
		AdditionalNotes string `json:"additional_notes"`
	}
	err = json.Unmarshal([]byte(resp.Choices[0].Message.Content), &extraction)
	if err != nil {
		return fmt.Errorf("failed to parse customer info extraction response: %w", err)
	}

	if !extraction.HasNewInfo {
		return nil // No new information to update
	}

	// Find contact by phone number
	contact, err := s.contactService.GetContactByIdentifier(ctx, phoneNumber)
	if err != nil {
		s.logger.With(ctx).Info("Contact not found for phone number:", phoneNumber, "Error:", err)
		return nil // Don't fail if contact not found
	}

	// Find unassigned lead by contact ID (only unresolved leads)
	lead, err := s.leadService.GetUnassignedLeadByIDContact(ctx, contact.ID)
	if err != nil {
		s.logger.With(ctx).Info("Unassigned lead not found for contact:", contact.ID, "Error:", err)
		return nil // Don't fail if lead not found
	}

	// Prepare updates - only update notes, preserve original lead name
	updatedNotes := lead.Notes

	// Add customer name to notes if extracted (don't change lead name)
	// Check for duplicates to prevent multiple entries of the same customer name
	if extraction.CustomerName != "" {
		// Check if this customer name already exists in the notes
		customerNamePattern := fmt.Sprintf("Customer Name: %s", extraction.CustomerName)
		if !strings.Contains(updatedNotes, customerNamePattern) {
			timestamp := time.Now().Format("2006-01-02 15:04:05")
			nameNote := fmt.Sprintf("\n[%s] Customer Name: %s", timestamp, extraction.CustomerName)
			if updatedNotes == "" {
				updatedNotes = strings.TrimPrefix(nameNote, "\n")
			} else {
				updatedNotes += nameNote
			}
			s.logger.With(ctx).Info("ðŸ“ Adding customer name to notes:", extraction.CustomerName)
		} else {
			s.logger.With(ctx).Info("ðŸ“ Customer name already exists in notes, skipping duplicate:", extraction.CustomerName)
		}
	}

	// Update notes with additional information
	if extraction.AdditionalNotes != "" {
		timestamp := time.Now().Format("2006-01-02 15:04:05")
		newNote := fmt.Sprintf("\n[%s] Customer Info: %s", timestamp, extraction.AdditionalNotes)
		if updatedNotes == "" {
			updatedNotes = strings.TrimPrefix(newNote, "\n")
		} else {
			updatedNotes += newNote
		}
		s.logger.With(ctx).Info("ðŸ“ Adding customer notes:", extraction.AdditionalNotes)
	}

	// Update the lead if there are changes to notes
	if updatedNotes != lead.Notes {
		// Create a simple update by modifying the existing lead entity
		lead.Notes = updatedNotes
		lead.UpdatedAt = time.Now()

		// Use the lead repository to update the lead
		// We need to get the lead repository through the lead service
		// Since we can't access the repository directly, let's create a minimal update request
		// and use reflection or a workaround

		// For now, let's create a simple struct that matches UpdateLeadRequest
		type updateLeadReq struct {
			Notes *string `json:"notes,omitempty"`
		}

		// Call the helper method to update the lead (only notes)
		err = s.callUpdateLeadService(ctx, lead.ID, lead.Name, updatedNotes)
		if err != nil {
			return fmt.Errorf("failed to update lead with customer info: %w", err)
		}

		s.logger.With(ctx).Info("âœ… Successfully updated customer information for lead:", lead.ID)
	}

	return nil
}

// callUpdateLeadService is a helper method to update lead information
func (s *service) callUpdateLeadService(ctx context.Context, leadID uuid.UUID, name, notes string) error {
	// Use the lead service's UpdateLead method which properly handles the update
	updateReq := lead.UpdateLeadRequest{
		Notes: &notes,
	}

	err := s.leadService.UpdateLead(ctx, leadID, updateReq)
	if err != nil {
		return fmt.Errorf("failed to update lead: %w", err)
	}

	return nil
}

// isPaymentValidationCondition checks if the transfer condition is related to payment validation
func (s *service) isPaymentValidationCondition(condition string) bool {
	conditionLower := strings.ToLower(condition)
	return (strings.Contains(conditionLower, "valid") || strings.Contains(conditionLower, "confirmed")) &&
		(strings.Contains(conditionLower, "payment") || strings.Contains(conditionLower, "transfer") || strings.Contains(conditionLower, "slip"))
}

// hasConflictingImageAnalysis checks if there's a conflict between image analysis and conversation AI response
func (s *service) hasConflictingImageAnalysis(conversationHistory []OpenAIMessage, aiResponse string) bool {
	// Look for recent image analysis in conversation history
	for i := len(conversationHistory) - 1; i >= 0 && i >= len(conversationHistory)-5; i-- {
		message := conversationHistory[i]
		if message.Role == "user" {
			content := ""
			if str, ok := message.Content.(string); ok {
				content = str
			}

			// Check if this message contains image analysis indicating invalid payment
			if strings.Contains(content, "Image Analysis:") {
				contentLower := strings.ToLower(content)

				// Keywords that indicate invalid payment in image analysis
				invalidPaymentKeywords := []string{
					"not a valid indonesian payment slip",
					"not a valid payment slip",
					"does not contain any visible bank",
					"not contain any visible payment",
					"does not appear to be a payment",
					"not a payment receipt",
					"not a bank receipt",
					"not a transfer receipt",
					"photograph of a room",
					"interior", "ceiling", "cabinet", "door",
				}

				for _, keyword := range invalidPaymentKeywords {
					if strings.Contains(contentLower, keyword) {
						// Found image analysis indicating invalid payment
						// Now check if AI response contradicts this
						aiResponseLower := strings.ToLower(aiResponse)

						// Keywords that indicate AI is treating payment as valid
						validPaymentKeywords := []string{
							"pembayaran diterima", "payment received", "valid payment",
							"pembayaran valid", "terima kasih sudah mengirimkan",
							"bukti transfer", "transfer berhasil", "pembayaran berhasil",
							"payment successful", "pesanan akan segera",
						}

						for _, validKeyword := range validPaymentKeywords {
							if strings.Contains(aiResponseLower, validKeyword) {
								return true // Conflict detected
							}
						}
					}
				}
			}
		}
	}
	return false
}

// progressLeadToNextStage moves the lead to the next stage or transfers to a different pipeline
func (s *service) progressLeadToNextStage(ctx context.Context, db *dbcontext.DB, agentID uuid.UUID, phoneNumber string, analysis *TransferAnalysis) error {
	s.logger.With(ctx).Info("ðŸ”„ Transfer conditions met for agent:", agentID, "Phone:", phoneNumber)
	s.logger.With(ctx).Info("ðŸ“ Extracted info:", analysis.ExtractedInfo)
	s.logger.With(ctx).Info("ðŸ’° Potential value:", analysis.PotentialValue)
	s.logger.With(ctx).Info("ðŸŽ¯ Confidence:", analysis.Confidence)
	s.logger.With(ctx).Info("ðŸ”€ Transfer type:", analysis.TransferType)
	s.logger.With(ctx).Info("ðŸŽ¯ Target pipeline:", analysis.TargetPipeline)

	if phoneNumber == "" {
		s.logger.With(ctx).Info("âš ï¸ No phone number provided, cannot progress lead")
		return nil
	}

	// Find contact by phone number
	contact, err := s.contactService.GetContactByIdentifier(ctx, phoneNumber)
	if err != nil {
		s.logger.With(ctx).Info("âš ï¸ Contact not found for phone number:", phoneNumber, "Error:", err)
		return nil // Don't fail the whole process if contact not found
	}

	// Get platform ID from contact for human agent lookup
	platformID := contact.IDPlatform

	// Find unassigned lead by contact ID (only unresolved leads)
	lead, err := s.leadService.GetUnassignedLeadByIDContact(ctx, contact.ID)
	if err != nil {
		s.logger.With(ctx).Info("âš ï¸ Unassigned lead not found for contact:", contact.ID, "Error:", err)
		return nil // Don't fail the whole process if lead not found
	}

	// Check if lead has a stage assigned
	if lead.IDStage == nil {
		s.logger.With(ctx).Info("âš ï¸ Lead has no stage assigned, cannot progress")
		return nil
	}

	// Get current stage
	currentStage, err := s.stagesService.GetByID(ctx, *lead.IDStage)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to get current stage:", err)
		return err
	}

	var nextStage *entity.Stage
	var targetPipelineID uuid.UUID

	// Handle pipeline transfer vs next stage transfer
	if analysis.TransferType == "pipeline" && analysis.TargetPipeline != "" {
		// Pipeline transfer: find the target pipeline and its first stage
		s.logger.With(ctx).Info("ðŸ”€ Processing pipeline transfer to:", analysis.TargetPipeline)

		// Get all pipelines to find the target pipeline by name
		pipelines, err := s.pipelineService.GetAllPipeline(ctx, 0, 1000) // Get up to 1000 pipelines
		if err != nil {
			s.logger.With(ctx).Error("âŒ Failed to get pipelines:", err)
			return err
		}

		var targetPipeline *entity.Pipelines
		for _, pipeline := range pipelines {
			if pipeline.Name == analysis.TargetPipeline {
				targetPipeline = &pipeline.Pipelines
				targetPipelineID = pipeline.ID
				break
			}
		}

		if targetPipeline == nil {
			s.logger.With(ctx).Error("âŒ Target pipeline not found:", analysis.TargetPipeline)
			return fmt.Errorf("target pipeline not found: %s", analysis.TargetPipeline)
		}

		// Get the first stage of the target pipeline
		stages, err := s.stagesService.GetByPipeline(ctx, targetPipeline.ID)
		if err != nil {
			s.logger.With(ctx).Error("âŒ Failed to get stages in target pipeline:", err)
			return err
		}

		// Find the first stage (lowest order)
		for _, stage := range stages {
			if nextStage == nil || stage.StageOrder < nextStage.StageOrder {
				nextStage = &stage
			}
		}

		if nextStage == nil {
			s.logger.With(ctx).Error("âŒ No stages found in target pipeline:", analysis.TargetPipeline)
			return fmt.Errorf("no stages found in target pipeline: %s", analysis.TargetPipeline)
		}

		s.logger.With(ctx).Info("ðŸŽ¯ Target stage found:", nextStage.Name, "in pipeline:", targetPipeline.Name)
	} else {
		// Next stage transfer: find the next stage in the current pipeline
		s.logger.With(ctx).Info("âž¡ï¸ Processing next stage transfer")
		targetPipelineID = currentStage.IDPipeline

		// Get all stages in the current pipeline to find the next one
		stages, err := s.stagesService.GetByPipeline(ctx, currentStage.IDPipeline)
		if err != nil {
			s.logger.With(ctx).Error("âŒ Failed to get stages in pipeline:", err)
			return err
		}

		// Find the next stage by order
		for _, stage := range stages {
			if stage.StageOrder == currentStage.StageOrder+1 {
				nextStage = &stage
				break
			}
		}

		if nextStage == nil {
			s.logger.With(ctx).Info("â„¹ï¸ Lead is already at the final stage")
			return nil
		}
	}

	// Prepare updated notes (append to existing notes)
	updatedNotes := lead.Notes
	if analysis.ExtractedInfo != "" {
		timestamp := time.Now().Format("2006-01-02 15:04:05")
		newNote := fmt.Sprintf("\n[%s] Transfer to %s: %s", timestamp, nextStage.Name, analysis.ExtractedInfo)
		if updatedNotes == "" {
			updatedNotes = strings.TrimPrefix(newNote, "\n")
		} else {
			updatedNotes += newNote
		}
	}

	// Parse and update potential value if provided
	updatedPotentialValue := lead.PotentialValue
	if analysis.PotentialValue > 0 {
		// PotentialValue is now a float64, so we can directly convert it
		updatedPotentialValue = float32(analysis.PotentialValue)
		s.logger.With(ctx).Info("ðŸ’° Updating potential value from", lead.PotentialValue, "to", updatedPotentialValue)
	}

	// Determine the assigned agent - check if this is a human agent transfer request
	var assignedAgent *uuid.UUID = nextStage.IDAgent // Default to next stage's agent

	// Check if the transfer reason indicates a request to speak to a human agent
	if analysis.Reason != "" {
		reasonLower := strings.ToLower(analysis.Reason)
		humanRequestKeywords := []string{
			"human agent", "speak with human", "talk to human", "human representative",
			"customer service", "manager", "supervisor", "real person",
			"human assistance", "human support", "live agent", "human help",
		}

		isHumanRequest := false
		for _, keyword := range humanRequestKeywords {
			if strings.Contains(reasonLower, keyword) {
				isHumanRequest = true
				break
			}
		}

		if isHumanRequest {
			s.logger.With(ctx).Info("ðŸ‘¤ Human agent transfer requested, looking for human agent mapped to platform:", platformID)

			// Get platform mappings to find human agents
			if s.platformMappingRepo != nil {
				platformMappings, err := s.platformMappingRepo.GetByIDPlatformInbox(db, ctx, platformID)
				if err != nil {
					s.logger.With(ctx).Errorf("Failed to get platform mappings for platform %s: %v", platformID, err)
				} else {
					// Find the first active human agent mapping
					for _, mapping := range platformMappings {
						if mapping.IsActive && mapping.AgentTypes == "Human" {
							assignedAgent = &mapping.IDAgent
							s.logger.With(ctx).Infof("âœ… Found human agent %s mapped to platform %s, assigning lead", mapping.IDAgent, platformID)
							break
						}
					}
					if assignedAgent == nil || (nextStage.IDAgent != nil && *assignedAgent == *nextStage.IDAgent) {
						s.logger.With(ctx).Infof("âš ï¸ No active human agent found for platform %s, using next stage agent", platformID)
						assignedAgent = nextStage.IDAgent
					}
				}
			} else {
				s.logger.With(ctx).Info("âš ï¸ Platform mapping repository not available, using next stage agent")
			}
		}
	}

	// Update lead with new stage, notes, potential value, assigned agent, and pipeline (if changed)
	// Create the update request using the imported lead package types
	// NOTE: Do NOT update the Name field to preserve the original lead name
	updateReq := struct {
		Name           *string            `json:"name,omitempty"`
		PotentialValue *float32           `json:"potential_value,omitempty"`
		Notes          *string            `json:"notes,omitempty"`
		AssignedTo     *uuid.UUID         `json:"assigned_to,omitempty"`
		IDPipeline     *uuid.UUID         `json:"id_pipeline,omitempty"`
		IDStage        *uuid.UUID         `json:"id_stage,omitempty"`
		MovedBy        *entity.AgentType  `json:"moved_by,omitempty"`
		Status         *entity.StatusLead `json:"status,omitempty"`
	}{
		IDStage:        &nextStage.ID,
		IDPipeline:     &targetPipelineID, // Update pipeline ID (same for next stage, different for pipeline transfer)
		Notes:          &updatedNotes,
		PotentialValue: &updatedPotentialValue,
		AssignedTo:     assignedAgent, // Assign lead to human agent if requested, otherwise next stage's agent
		// Name is intentionally omitted to preserve the original lead name
	}

	// Actually update the lead using the service interface
	err = s.leadService.UpdateLead(ctx, lead.ID, updateReq)
	if err != nil {
		s.logger.With(ctx).Error("âŒ Failed to update lead:", err)
		return err
	}

	s.logger.With(ctx).Info("âœ… Lead successfully progressed from stage", currentStage.Name, "to", nextStage.Name)
	s.logger.With(ctx).Info("ðŸ“ Extracted info:", analysis.ExtractedInfo)
	s.logger.With(ctx).Info("ðŸ’° Updated potential value:", updatedPotentialValue)
	s.logger.With(ctx).Info("ðŸ“‹ Updated notes:", updatedNotes)
	if assignedAgent != nil {
		s.logger.With(ctx).Info("ðŸ‘¤ Lead assigned to agent:", *assignedAgent)
	} else {
		s.logger.With(ctx).Info("ðŸ‘¤ Lead not assigned to any specific agent")
	}

	return nil
}
